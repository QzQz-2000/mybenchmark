# py-openmessaging-benchmark 项目详细文档

## 目录
1. [项目概述](#1-项目概述)
2. [架构设计](#2-架构设计)
3. [目录结构详解](#3-目录结构详解)
4. [核心组件详解](#4-核心组件详解)
5. [驱动系统](#5-驱动系统)
6. [工作流程](#6-工作流程)
7. [配置系统](#7-配置系统)
8. [类与函数完整参考](#8-类与函数完整参考)
9. [使用示例](#9-使用示例)
10. [关键技术决策](#10-关键技术决策)

---

## 1. 项目概述

### 1.1 项目目标
**py-openmessaging-benchmark** 是一个完整的 Python 实现的 OpenMessaging 基准测试框架，专门用于测试 Python Kafka 客户端和其他消息系统的性能。这是从原 Java 框架完全转换为 Python 原生解决方案的实现，特别针对数字孪生场景和 IoT 工作负载进行了优化。

### 1.2 核心特性
- **Python 客户端优化**: 支持 kafka-python、confluent-kafka、aiokafka 三种客户端
- **分布式架构**: 支持多节点测试，采用 Coordinator-Worker 模式
- **高精度延迟测量**: 使用 HdrHistogram 进行微秒级精确延迟测量
- **实时系统监控**: 集成 CPU、内存、网络、磁盘监控
- **框架兼容**: 兼容 OpenMessaging Benchmark 的配置格式
- **数字孪生优化**: 针对 IoT 场景的特殊配置优化

### 1.3 技术栈
- **语言**: Python 3.8+
- **异步框架**: asyncio, aiohttp
- **Web 框架**: FastAPI (Worker API)
- **Kafka 客户端**: confluent-kafka (主要), kafka-python, aiokafka
- **配置管理**: Pydantic, PyYAML
- **监控**: psutil
- **数据分析**: numpy, pandas
- **可视化**: matplotlib, rich

---

## 2. 架构设计

### 2.1 总体架构

```
┌─────────────────────────────────────────────────────────┐
│                   Coordinator 协调器                      │
│  - 测试编排和任务分发                                      │
│  - Worker 健康检查                                        │
│  - 任务分配（轮询策略）                                    │
│  - 结果聚合                                               │
│  - Topic 生命周期管理                                     │
│  - HTTP 客户端 (aiohttp)                                 │
└──────────────┬──────────────────────────────────────────┘
               │ REST API (HTTP)
    ┌──────────┼────────────┬──────────────┐
    │          │            │              │
┌───▼────┐ ┌──▼──────┐ ┌──▼──────┐ ┌────▼────┐
│Worker 1│ │Worker 2 │ │Worker 3 │ │Worker N │
│FastAPI │ │FastAPI  │ │FastAPI  │ │FastAPI  │
│Kafka   │ │Kafka    │ │Kafka    │ │Kafka    │
│Driver  │ │Driver   │ │Driver   │ │Driver   │
└───┬────┘ └────┬────┘ └────┬────┘ └────┬────┘
    │           │            │            │
    └───────────┴────────────┴────────────┘
                │
     ┌──────────▼───────────┐
     │    Kafka Cluster      │
     │   Topics/Partitions   │
     └───────────────────────┘
```

### 2.2 核心设计模式

#### 2.2.1 Coordinator-Worker 模式
- **Coordinator**: 中央协调器，负责任务编排和结果聚合
- **Worker**: 分布式工作节点，执行实际的生产/消费任务
- **通信**: REST API (HTTP) 进行通信

#### 2.2.2 驱动抽象层
```
AbstractDriver (抽象驱动)
├─ AbstractProducer (抽象生产者)
├─ AbstractConsumer (抽象消费者)
└─ AbstractTopicManager (抽象 Topic 管理器)
    │
    └─ KafkaDriver (Kafka 实现)
       ├─ KafkaProducer
       ├─ KafkaConsumer
       └─ KafkaTopicManager
```

#### 2.2.3 任务分发策略
- **轮询分发**: 任务按轮询方式分配到各个 Worker
- **并发执行**: 每个 Worker 并发执行多个任务
- **Consumer 优先**: Consumer 任务先启动，等待 5 秒后再启动 Producer

---

## 3. 目录结构详解

```
py-openmessaging-benchmark/
├── benchmark/                    # 核心框架包
│   ├── __init__.py              # 包初始化，版本信息
│   ├── cli.py                   # 命令行接口 (Click)
│   ├── coordinator.py           # 备用协调器入口
│   │
│   ├── core/                    # 核心组件
│   │   ├── __init__.py         # 核心导出
│   │   ├── config.py           # 配置模型 (Pydantic)
│   │   ├── coordinator.py      # 协调器实现
│   │   ├── worker.py           # Worker 基类
│   │   ├── results.py          # 结果模型和聚合
│   │   └── monitoring.py       # 系统监控
│   │
│   ├── drivers/                 # 驱动抽象层
│   │   ├── base.py             # 抽象基类
│   │   └── kafka/              # Kafka 驱动实现
│   │       ├── __init__.py
│   │       ├── kafka_driver.py      # Kafka 驱动
│   │       ├── kafka_producer.py    # Kafka 生产者
│   │       ├── kafka_consumer.py    # Kafka 消费者
│   │       └── kafka_topic_manager.py  # Kafka Topic 管理
│   │
│   ├── utils/                   # 工具模块
│   │   ├── __init__.py
│   │   ├── latency_recorder.py      # 延迟记录器 (HdrHistogram)
│   │   ├── rate_limiter.py          # 速率限制器
│   │   ├── logging.py               # 日志工具
│   │   ├── config_validator.py      # 配置验证
│   │   ├── parallel_sender.py       # 并行发送器
│   │   └── enhanced_benchmark.py    # 增强基准测试
│   │
│   └── api/                     # Worker API
│       └── worker_api.py        # FastAPI 实现
│
├── workers/                     # Worker 实现
│   ├── __init__.py
│   └── kafka_worker.py          # Kafka Worker
│
├── configs/                     # 驱动配置文件
│   ├── kafka-latency.yaml      # 低延迟配置
│   ├── kafka-throughput.yaml   # 高吞吐配置
│   ├── kafka-max-throughput.yaml  # 最大吞吐配置
│   └── kafka-digital-twin.yaml    # 数字孪生优化配置
│
├── workloads/                   # 工作负载配置文件
│   ├── quick-test.yaml         # 快速测试
│   ├── latency-test-100b.yaml  # 延迟测试
│   ├── throughput-test-*.yaml  # 吞吐量测试
│   ├── digital-twin-*.yaml     # 数字孪生场景
│   └── ...                     # 共 18 个预定义工作负载
│
├── scripts/                     # 脚本工具
│   ├── run_benchmark.py        # 运行基准测试
│   └── start_worker.py         # 启动 Worker
│
├── tests/                       # 单元测试
│   ├── __init__.py
│   ├── test_config.py          # 配置测试
│   └── test_results.py         # 结果测试
│
├── examples/                    # 示例代码
│   └── quick_start.py          # 快速开始示例
│
├── docs/                        # 文档
├── results/                     # 测试结果输出
├── pyproject.toml              # 项目配置
├── requirements.txt            # 依赖项
├── Dockerfile                  # Docker 镜像
├── docker-compose.yml          # Docker Compose 配置
├── run_test.sh                 # 测试运行脚本
└── run_worker.sh               # Worker 运行脚本
```

---

## 4. 核心组件详解

### 4.1 `/benchmark/core/config.py` - 配置模型

#### 4.1.1 类: `WorkloadConfig` (工作负载配置)

**作用**: 定义测试场景的参数

**字段详解**:
```python
class WorkloadConfig(BaseModel):
    # === 基本信息 ===
    name: str                           # 工作负载名称

    # === Topic 配置 ===
    topics: int                         # Topic 数量 (≥1)
    partitions_per_topic: int           # 每个 Topic 的分区数 (≥1)

    # === 消息配置 ===
    message_size: int                   # 消息大小（字节）(≥1)
    payload_file: Optional[str]         # 自定义 payload 文件路径
    key_distributor: KeyDistributor     # 消息 key 分配策略
                                        # - NO_KEY: 无 key
                                        # - RANDOM: 随机 key
                                        # - ROUND_ROBIN: 轮询 key-0 ~ key-99
                                        # - ZIP_LATENT: Zipfian 分布

    # === 生产者配置 ===
    producers_per_topic: int            # 每个 Topic 的生产者数量 (≥1)
    producer_rate: int                  # 生产速率（消息/秒）(≥0, 0=无限制)

    # === 消费者配置 ===
    subscriptions_per_topic: int        # 每个 Topic 的订阅数 (≥1)
    consumer_per_subscription: int      # 每个订阅的消费者数 (≥1)

    # === 测试时长 ===
    test_duration_minutes: int          # 测试时长（分钟）(≥1)
    warmup_duration_minutes: int        # 预热时长（分钟）(≥0)

    # === 验证器 ===
    @validator('*', pre=True)
    def parse_config_string(cls, v):
        """解析 YAML 多行字符串配置，自动类型转换"""
```

**关键方法**:
- `parse_config_string()`: 解析 YAML 配置字符串，支持 bool、int、float、string 自动类型转换

---

#### 4.1.2 类: `DriverConfig` (驱动配置)

**作用**: 定义驱动连接和配置参数

**字段详解**:
```python
class DriverConfig(BaseModel):
    # === 基本信息 ===
    name: str                           # 驱动名称
    driver_class: str                   # 驱动类路径
                                        # 例: "benchmark.drivers.kafka.KafkaDriver"

    # === 配置层级 ===
    common_config: Optional[Dict]       # 通用配置（生产者和消费者共享）
                                        # 例: bootstrap.servers=localhost:9092
    producer_config: Optional[Dict]     # 生产者专用配置
                                        # 例: acks=all, batch.size=65536
    consumer_config: Optional[Dict]     # 消费者专用配置
                                        # 例: auto.offset.reset=earliest
    topic_config: Optional[Dict]        # Topic 级别配置
                                        # 例: min.insync.replicas=2

    # === Topic 管理 ===
    replication_factor: int = 1         # 副本因子 (≥1)
    reset: bool = False                 # 测试前是否重置 Topic
```

**关键方法**:
- `parse_config_string()`: 将 YAML 多行字符串转换为字典，支持类型转换

---

#### 4.1.3 类: `BenchmarkConfig` (基准测试配置)

**作用**: 主配置，包含全局设置

**字段详解**:
```python
class BenchmarkConfig(BaseModel):
    workers: List[str]                  # Worker URL 列表
                                        # 例: ["http://localhost:8001", "http://localhost:8002"]
    log_level: str = "INFO"             # 日志级别
    results_dir: str = "./results"      # 结果输出目录
    enable_monitoring: bool = True      # 是否启用系统监控
    warmup_enabled: bool = True         # 是否启用预热阶段
    cleanup_enabled: bool = True        # 测试后是否清理 Topic
```

---

#### 4.1.4 类: `ConfigLoader` (配置加载器)

**作用**: 加载和保存配置文件

**方法详解**:
```python
class ConfigLoader:
    @staticmethod
    def load_workload(file_path: str) -> WorkloadConfig:
        """加载工作负载配置 YAML 文件"""
        # 1. 读取 YAML 文件
        # 2. 解析为 WorkloadConfig 对象
        # 3. 进行 Pydantic 验证

    @staticmethod
    def load_driver(file_path: str) -> DriverConfig:
        """加载驱动配置 YAML 文件"""

    @staticmethod
    def load_benchmark(file_path: str) -> BenchmarkConfig:
        """加载基准测试配置 YAML 文件"""

    @staticmethod
    def save_config(config: BaseModel, file_path: str):
        """保存配置到 YAML 文件（camelCase 格式）"""
```

---

### 4.2 `/benchmark/core/coordinator.py` - 协调器

#### 4.2.1 类: `BenchmarkCoordinator`

**作用**: 编排分布式基准测试执行

**核心属性**:
```python
class BenchmarkCoordinator(LoggerMixin):
    config: BenchmarkConfig              # 基准测试配置
    result_collector: ResultCollector    # 结果收集器
    system_monitor: SystemMonitor        # 系统监控器
    _session: aiohttp.ClientSession      # HTTP 会话（与 Worker 通信）
    _current_test_topics: List[str]      # 当前测试的 Topic 列表
```

**核心方法详解**:

##### 1. `async run_benchmark()` - 主工作流方法

```python
async def run_benchmark(
    self,
    workload_config: WorkloadConfig,
    driver_config: DriverConfig,
    payload_data: Optional[bytes] = None
) -> BenchmarkResult:
    """
    执行完整的基准测试工作流

    工作流:
    1. 生成唯一测试 ID (name_timestamp)
    2. 创建唯一 Topic 名称 (benchmark-{test_id}-topic-{idx})
    3. 验证配置
    4. 检查 Worker 健康状态
    5. 创建 Topic
    6. 启动系统监控
    7. 运行预热阶段（如启用）
    8. 运行主测试阶段
    9. 完成结果聚合
    10. 清理 Topic（如启用）

    返回: BenchmarkResult (包含所有测试结果)
    """
```

##### 2. `async _check_worker_health()` - Worker 健康检查

```python
async def _check_worker_health(self):
    """
    并发检查所有 Worker 的健康状态

    步骤:
    1. 并发调用每个 Worker 的 /health 端点
    2. 过滤掉不健康的 Worker
    3. 更新 config.workers 为健康 Worker 列表
    4. 如果没有健康 Worker，抛出异常

    超时: 10 秒
    """
```

##### 3. `async _run_test_phase()` - 测试阶段执行

```python
async def _run_test_phase(
    self,
    result: BenchmarkResult,
    workload_config: WorkloadConfig,
    driver_config: DriverConfig,
    payload_data: Optional[bytes]
):
    """
    执行主测试阶段（核心方法）

    步骤:
    1. 计算超时时间 (test_duration + 180秒缓冲)
    2. 生成生产者任务列表
    3. 生成消费者任务列表
    4. 将任务分配到 Worker（轮询策略）

    5. **关键时序**:
       a. 先启动所有消费者任务（并发 HTTP POST /consumer/start）
       b. 等待 5 秒让消费者订阅完成
       c. 再启动所有生产者任务（并发 HTTP POST /producer/start）

    6. 等待所有生产者完成（带超时保护）
    7. 等待所有消费者完成（带超时保护）
    8. 收集所有 Worker 的结果
    9. 异常处理（记录错误但不中断）

    设计目标: 确保消费者在生产者发送消息前已准备好
    """
```

##### 4. `_generate_producer_tasks()` - 生成生产者任务

```python
def _generate_producer_tasks(
    self,
    workload_config: WorkloadConfig,
    payload_data: Optional[bytes]
) -> List[ProducerTask]:
    """
    根据工作负载配置生成生产者任务

    逻辑:
    对于每个 Topic:
        对于每个生产者 (producers_per_topic):
            1. 计算每个生产者的消息数量
            2. 计算速率限制 (producer_rate // producers_per_topic)
            3. 创建 ProducerTask:
               - task_id: producer-{topic_idx}-{producer_idx}-{test_id}
               - topic: benchmark-{test_id}-topic-{topic_idx}
               - num_messages: 计算值
               - rate_limit: 计算值
               - payload_data: 自定义或生成

    返回: ProducerTask 列表
    """
```

##### 5. `_generate_consumer_tasks()` - 生成消费者任务

```python
def _generate_consumer_tasks(
    self,
    workload_config: WorkloadConfig
) -> List[ConsumerTask]:
    """
    根据工作负载配置生成消费者任务

    逻辑:
    对于每个 Topic:
        对于每个订阅 (subscriptions_per_topic):
            对于每个消费者 (consumer_per_subscription):
                1. 创建唯一订阅名 (subscription-{idx}-{test_id})
                2. 创建 ConsumerTask:
                   - task_id: consumer-{topic_idx}-{sub_idx}-{consumer_idx}-{test_id}
                   - topics: [benchmark-{test_id}-topic-{topic_idx}]
                   - subscription_name: 订阅名（即 consumer group）
                   - test_duration_seconds: 测试时长

    返回: ConsumerTask 列表
    """
```

##### 6. `_distribute_tasks()` - 任务分发

```python
def _distribute_tasks(
    self,
    tasks: List[Any],
    num_workers: int
) -> List[List[Any]]:
    """
    使用轮询策略分配任务到 Worker

    示例:
    tasks = [T1, T2, T3, T4, T5]
    num_workers = 3

    结果:
    Worker 0: [T1, T4]
    Worker 1: [T2, T5]
    Worker 2: [T3]

    优点: 负载均衡
    """
```

##### 7. `async _setup_topics()` - 创建 Topic

```python
async def _setup_topics(
    self,
    workload_config: WorkloadConfig,
    driver_config: DriverConfig
):
    """
    为测试创建所有 Topic

    步骤:
    1. 动态导入驱动类
    2. 创建并初始化驱动
    3. 创建 Topic 管理器
    4. 为所有唯一 Topic 创建 Topic（配置的分区数）
    5. 处理"Topic 已存在"错误（忽略）
    6. 关闭驱动

    Topic 命名: benchmark-{test_id}-topic-{idx}
    目的: 幂等性，避免测试干扰
    """
```

##### 8. `async _cleanup_test_topics()` - 清理 Topic

```python
async def _cleanup_test_topics(
    self,
    driver_config: DriverConfig
):
    """
    测试后清理 Topic

    步骤:
    1. 等待 5 秒让消息落地
    2. 创建新驱动实例
    3. 删除所有测试 Topic（每个 30 秒超时）
    4. 优雅处理删除失败（记录但不抛异常）
    5. 输出需要手动清理的 Topic 列表

    目的: 保持 Kafka 集群整洁
    """
```

---

### 4.3 `/benchmark/core/worker.py` - Worker 基类

#### 4.3.1 数据类: `ProducerTask` (生产者任务)

```python
@dataclass
class ProducerTask:
    task_id: str                    # 唯一任务标识
    topic: str                      # 目标 Topic
    num_messages: int               # 发送消息数量
    message_size: int               # 消息大小（字节）
    rate_limit: int                 # 速率限制（消息/秒，0=无限制）
    payload_data: Optional[bytes]   # 自定义 payload
    key_pattern: str                # Key 分配模式（NO_KEY, RANDOM, etc.）
    properties: Dict = field(default_factory=dict)  # 额外属性
```

#### 4.3.2 数据类: `ConsumerTask` (消费者任务)

```python
@dataclass
class ConsumerTask:
    task_id: str                    # 唯一任务标识
    topics: List[str]               # 订阅的 Topic 列表
    subscription_name: str          # 订阅名（consumer group）
    test_duration_seconds: int      # 消费时长（秒）
    properties: Dict = field(default_factory=dict)  # 额外属性
```

#### 4.3.3 类: `BaseWorker` (Worker 基类)

**作用**: 定义 Worker 的抽象接口

**核心属性**:
```python
class BaseWorker(LoggerMixin, ABC):
    worker_id: str                          # Worker 唯一标识
    system_monitor: SystemMonitor           # 系统监控器
    executor: ThreadPoolExecutor            # 线程池（用于阻塞操作）
    _running_tasks: Dict[str, Future]       # 正在运行的任务
    _task_results: Dict[str, WorkerResult]  # 已完成任务的结果
    _consumer_ready_status: Dict            # 消费者就绪状态追踪
```

**核心方法**:

```python
async def start(self):
    """启动 Worker 和系统监控"""

async def stop(self):
    """停止 Worker，取消运行中的任务，关闭线程池"""

async def run_producer_tasks(
    self,
    tasks: List[ProducerTask]
) -> List[WorkerResult]:
    """
    运行多个生产者任务（并发）

    使用 asyncio.gather 并发执行所有任务
    异常处理: 创建错误结果，不中断其他任务
    """

async def run_consumer_tasks(
    self,
    tasks: List[ConsumerTask]
) -> List[WorkerResult]:
    """运行多个消费者任务（并发）"""

@abstractmethod
async def _execute_producer_task(
    self,
    task: ProducerTask
) -> Dict:
    """
    执行单个生产者任务（子类必须实现）

    返回字典格式:
    {
        'throughput': ThroughputStats,
        'latency': LatencyStats,
        'errors': ErrorStats
    }
    """

@abstractmethod
async def _execute_consumer_task(
    self,
    task: ConsumerTask
) -> Dict:
    """
    执行单个消费者任务（子类必须实现）

    返回字典格式:
    {
        'throughput': ThroughputStats,
        'errors': ErrorStats
    }
    """

def get_system_stats(self) -> Dict:
    """获取当前系统统计信息"""

def get_task_status(self, task_id: str) -> Dict:
    """获取任务状态（pending/running/completed）"""

def get_task_result(self, task_id: str) -> WorkerResult:
    """获取已完成任务的结果"""

def health_check(self) -> Dict:
    """
    健康检查

    返回:
    {
        'status': 'healthy',
        'worker_id': '...',
        'running_tasks': 5,
        'completed_tasks': 100
    }
    """
```

---

### 4.4 `/benchmark/core/results.py` - 结果模型

#### 4.4.1 数据类: `LatencyStats` (延迟统计)

```python
@dataclass
class LatencyStats:
    count: int                      # 样本数量
    min_ms: float                   # 最小延迟（毫秒）
    max_ms: float                   # 最大延迟（毫秒）
    mean_ms: float                  # 平均延迟（毫秒）
    median_ms: float                # 中位数延迟（毫秒）

    # 百分位数
    p50_ms: float                   # 50th 百分位
    p95_ms: float                   # 95th 百分位
    p99_ms: float                   # 99th 百分位
    p99_9_ms: float                 # 99.9th 百分位

    # 原始数据（用于聚合）
    histogram_data: Optional[Dict]  # HdrHistogram 原始数据
```

#### 4.4.2 数据类: `ThroughputStats` (吞吐量统计)

```python
@dataclass
class ThroughputStats:
    total_messages: int             # 总消息数
    total_bytes: int                # 总字节数
    duration_seconds: float         # 持续时间（秒）
    messages_per_second: float      # 消息吞吐量（msg/s）
    bytes_per_second: float         # 字节吞吐量（bytes/s）
    mb_per_second: float            # MB 吞吐量（MB/s）
```

#### 4.4.3 数据类: `ErrorStats` (错误统计)

```python
@dataclass
class ErrorStats:
    total_errors: int               # 总错误数
    error_rate: float               # 错误率（百分比）
    error_types: Dict[str, int]     # 错误类型分布
                                    # 例: {"TimeoutError": 5, "ConnectionError": 2}
```

#### 4.4.4 数据类: `WorkerResult` (Worker 结果)

```python
@dataclass
class WorkerResult:
    worker_id: str                  # Worker ID
    worker_url: str                 # Worker URL
    task_type: str                  # 任务类型（producer/consumer）
    start_time: float               # 开始时间（Unix 时间戳）
    end_time: float                 # 结束时间（Unix 时间戳）

    throughput: ThroughputStats     # 吞吐量统计
    latency: LatencyStats           # 延迟统计（生产者专用）
    errors: ErrorStats              # 错误统计
    metadata: Dict                  # 额外元数据
```

#### 4.4.5 数据类: `BenchmarkResult` (基准测试结果)

```python
@dataclass
class BenchmarkResult:
    test_id: str                            # 测试唯一 ID
    test_name: str                          # 测试名称
    start_time: float                       # 开始时间
    end_time: float                         # 结束时间

    # 配置快照
    workload_config: Dict                   # 工作负载配置
    driver_config: Dict                     # 驱动配置

    # 原始结果
    producer_results: List[WorkerResult]    # 所有生产者结果
    consumer_results: List[WorkerResult]    # 所有消费者结果

    # 聚合统计
    producer_stats: ThroughputStats         # 聚合生产者吞吐量
    consumer_stats: ThroughputStats         # 聚合消费者吞吐量
    latency_stats: LatencyStats             # 聚合延迟统计

    # 系统监控
    system_stats: SystemStats               # 系统资源统计

    metadata: Dict                          # 额外元数据
```

#### 4.4.6 类: `ResultCollector` (结果收集器)

**作用**: 收集和聚合基准测试结果

**核心方法**:

```python
class ResultCollector(LoggerMixin):

    def create_result(
        self,
        test_name: str,
        workload_config: WorkloadConfig,
        driver_config: DriverConfig
    ) -> BenchmarkResult:
        """
        创建新的 BenchmarkResult 对象

        步骤:
        1. 生成唯一 test_id (name_timestamp)
        2. 记录 start_time
        3. 存储配置快照
        4. 返回空结果对象
        """

    def add_worker_result(
        self,
        benchmark_result: BenchmarkResult,
        worker_result: WorkerResult
    ):
        """
        添加 Worker 结果到基准测试结果

        根据 task_type 添加到:
        - producer_results (如果是 producer)
        - consumer_results (如果是 consumer)
        """

    def finalize_result(
        self,
        benchmark_result: BenchmarkResult,
        system_stats: SystemStats
    ):
        """
        完成结果聚合

        步骤:
        1. 设置 end_time
        2. 聚合生产者吞吐量统计
        3. 聚合消费者吞吐量统计
        4. 聚合延迟统计（尝试合并 HdrHistogram）
        5. 存储系统监控统计
        """

    def _aggregate_throughput_stats(
        self,
        stats_list: List[ThroughputStats]
    ) -> ThroughputStats:
        """
        聚合吞吐量统计

        逻辑:
        1. 求和 total_messages 和 total_bytes
        2. 使用最大 duration（注意：这是已知限制）
        3. 计算聚合吞吐量

        已知问题: 应使用实际并发时间窗口，而非最大 duration
        """

    def _aggregate_latency_stats(
        self,
        stats_list: List[LatencyStats]
    ) -> LatencyStats:
        """
        聚合延迟统计

        优先策略:
        1. 如果 histogram_data 可用，尝试合并 HdrHistogram（最准确）
        2. 如果合并失败，回退到加权聚合（基于样本数）

        加权聚合逻辑:
        - 加权平均: mean = Σ(count_i * mean_i) / Σ(count_i)
        - 加权中位数、百分位数: 类似逻辑
        - 最小值: 取所有最小值的最小
        - 最大值: 取所有最大值的最大

        注意: 回退方法精度低于 HdrHistogram 合并
        """

    def save_result(
        self,
        result: BenchmarkResult,
        file_path: str
    ):
        """保存结果到 JSON 文件"""

    def load_result(
        self,
        file_path: str
    ) -> BenchmarkResult:
        """从 JSON 文件加载结果"""

    def export_csv(
        self,
        result: BenchmarkResult,
        file_path: str
    ):
        """
        导出摘要到 CSV 文件

        包含字段:
        - 测试信息
        - 生产者吞吐量
        - 消费者吞吐量
        - 延迟百分位数
        - 系统资源统计
        """

    def generate_comparison_report(
        self,
        results: List[BenchmarkResult]
    ) -> str:
        """
        生成多个测试结果的对比报告

        格式: Markdown 表格
        包含: 吞吐量、延迟、资源使用对比
        """
```

---

### 4.5 `/benchmark/core/monitoring.py` - 系统监控

#### 4.5.1 数据类: `SystemMetrics` (系统指标)

```python
@dataclass
class SystemMetrics:
    timestamp: float                # 时间戳
    cpu_percent: float              # CPU 使用率（%）
    memory_percent: float           # 内存使用率（%）
    network_sent_bytes: int         # 网络发送字节数
    network_recv_bytes: int         # 网络接收字节数
    disk_read_bytes: int            # 磁盘读取字节数
    disk_write_bytes: int           # 磁盘写入字节数
```

#### 4.5.2 数据类: `SystemStats` (系统统计)

```python
@dataclass
class SystemStats:
    cpu: Dict[str, float]           # CPU 统计
                                    # {'avg': 45.2, 'max': 78.5, 'min': 12.3, 'p95': 68.0, 'p99': 75.0}
    memory: Dict[str, float]        # 内存统计
                                    # {'avg': 60.5, 'max': 85.2, 'min': 50.1}
    network: Dict[str, float]       # 网络统计
                                    # {'sent_mb_per_sec_avg': 12.5, 'sent_mb_per_sec_max': 25.0,
                                    #  'recv_mb_per_sec_avg': 8.3, 'total_sent_mb': 7500.0, ...}
    disk: Dict[str, float]          # 磁盘统计
                                    # {'read_mb_per_sec_avg': 3.2, 'write_mb_per_sec_avg': 5.1, ...}
```

#### 4.5.3 类: `SystemMonitor` (系统监控器)

**作用**: 实时监控系统资源

**核心属性**:
```python
class SystemMonitor:
    interval: float = 1.0           # 监控间隔（秒）
    metrics: List[SystemMetrics]    # 收集的指标数据点
    _running: bool                  # 运行状态
    _stop_event: threading.Event    # 停止事件
    _monitor_thread: threading.Thread  # 监控线程
```

**核心方法**:

```python
def start(self):
    """
    启动监控线程

    后台线程每 interval 秒收集一次系统指标
    """

def stop(self):
    """
    停止监控线程

    设置停止事件，等待线程结束
    """

def _monitor_loop(self):
    """
    监控循环（在独立线程中运行）

    每个循环:
    1. 使用 psutil 收集 CPU 使用率
    2. 收集内存使用率
    3. 收集网络统计（sent/recv bytes）
    4. 收集磁盘 I/O 统计（read/write bytes）
    5. 创建 SystemMetrics 对象并存储
    6. 休眠 interval 秒
    """

def get_stats(self) -> SystemStats:
    """
    计算聚合统计信息

    对于 CPU:
    - avg: 平均使用率
    - max: 最大使用率
    - min: 最小使用率
    - p95: 95th 百分位
    - p99: 99th 百分位

    对于内存:
    - avg, max, min

    对于网络:
    - sent/recv MB/s (avg, max)
    - total sent/recv MB

    对于磁盘:
    - read/write MB/s (avg, max)
    - total read/write MB
    """

def plot_metrics(self, save_path: str) -> str:
    """
    生成监控图表

    使用 matplotlib 生成 4 个子图:
    1. CPU 使用率随时间变化
    2. 内存使用率随时间变化
    3. 网络吞吐量随时间变化
    4. 磁盘 I/O 随时间变化

    保存为 PNG 文件
    """

def export_raw_data(self, file_path: str) -> str:
    """
    导出原始监控数据到 CSV

    列: timestamp, cpu_percent, memory_percent,
        network_sent_bytes, network_recv_bytes,
        disk_read_bytes, disk_write_bytes
    """
```

---

## 5. 驱动系统

### 5.1 `/benchmark/drivers/base.py` - 驱动抽象层

#### 5.1.1 数据类

```python
@dataclass
class Message:
    """消息结构"""
    key: Optional[bytes]            # 消息 key
    value: bytes                    # 消息 value
    headers: Optional[Dict]         # 消息头
    timestamp: Optional[int]        # 时间戳（毫秒）

@dataclass
class ProducedMessage:
    """已发送的消息（带元数据）"""
    message: Message                # 原始消息
    send_time: float                # 发送时间
    partition: int                  # 目标分区
    offset: int                     # 偏移量

@dataclass
class ConsumedMessage:
    """已消费的消息（带元数据）"""
    message: Message                # 原始消息
    topic: str                      # Topic 名称
    partition: int                  # 分区
    offset: int                     # 偏移量
    receive_time: float             # 接收时间
```

#### 5.1.2 抽象类: `AbstractProducer`

```python
class AbstractProducer(ABC):
    """生产者抽象接口"""

    @abstractmethod
    async def send_message(
        self,
        topic: str,
        message: Message
    ) -> ProducedMessage:
        """发送单条消息"""

    @abstractmethod
    async def send_batch(
        self,
        topic: str,
        messages: List[Message]
    ) -> List[ProducedMessage]:
        """批量发送消息"""

    @abstractmethod
    async def flush(self):
        """刷新缓冲区，确保所有消息已发送"""

    @abstractmethod
    async def close(self):
        """关闭生产者"""
```

#### 5.1.3 抽象类: `AbstractConsumer`

```python
class AbstractConsumer(ABC):
    """消费者抽象接口"""

    @abstractmethod
    async def subscribe(
        self,
        topics: List[str],
        subscription_name: str
    ):
        """订阅 Topic"""

    @abstractmethod
    async def consume_messages(
        self,
        timeout_seconds: int
    ) -> AsyncIterator[ConsumedMessage]:
        """消费消息（异步迭代器）"""

    @abstractmethod
    async def commit(self):
        """提交偏移量"""

    @abstractmethod
    async def close(self):
        """关闭消费者"""
```

#### 5.1.4 抽象类: `AbstractTopicManager`

```python
class AbstractTopicManager(ABC):
    """Topic 管理器抽象接口"""

    @abstractmethod
    async def create_topic(
        self,
        name: str,
        partitions: int,
        replication_factor: int,
        config: Optional[Dict] = None
    ):
        """创建 Topic"""

    @abstractmethod
    async def delete_topic(self, name: str):
        """删除 Topic"""

    @abstractmethod
    async def list_topics(self) -> List[str]:
        """列出所有 Topic"""

    @abstractmethod
    async def topic_exists(self, name: str) -> bool:
        """检查 Topic 是否存在"""
```

#### 5.1.5 抽象类: `AbstractDriver`

```python
class AbstractDriver(LoggerMixin, ABC):
    """驱动抽象接口"""

    @abstractmethod
    async def initialize(self):
        """初始化驱动"""

    @abstractmethod
    async def cleanup(self):
        """清理驱动资源"""

    @abstractmethod
    def create_producer(
        self,
        config: Dict
    ) -> AbstractProducer:
        """创建生产者"""

    @abstractmethod
    def create_consumer(
        self,
        config: Dict
    ) -> AbstractConsumer:
        """创建消费者"""

    @abstractmethod
    def create_topic_manager(self) -> AbstractTopicManager:
        """创建 Topic 管理器"""
```

#### 5.1.6 工具类: `DriverUtils`

```python
class DriverUtils:
    """驱动工具类"""

    @staticmethod
    def calculate_throughput_stats(
        total_messages: int,
        total_bytes: int,
        start_time: float,
        end_time: float
    ) -> ThroughputStats:
        """计算吞吐量统计"""

    @staticmethod
    def calculate_latency_stats(
        latencies_ms: List[float]
    ) -> LatencyStats:
        """
        计算延迟统计

        使用 numpy 计算百分位数
        """

    @staticmethod
    def create_error_stats(
        errors: List[Exception]
    ) -> ErrorStats:
        """创建错误统计"""

    @staticmethod
    def generate_message_key(
        pattern: str,
        message_index: int,
        total_messages: int
    ) -> Optional[bytes]:
        """
        生成消息 key

        模式:
        - NO_KEY: 返回 None
        - RANDOM: 随机 UUID
        - ROUND_ROBIN: key-{index % 100}
        - ZIP_LATENT: Zipfian 分布
        """

    @staticmethod
    def create_test_payload(
        size_bytes: int,
        payload_data: Optional[bytes] = None
    ) -> bytes:
        """
        创建测试 payload

        如果提供 payload_data:
            重复或截断到目标大小
        否则:
            生成 'x' * size_bytes
        """
```

---

### 5.2 Kafka 驱动实现

#### 5.2.1 `/benchmark/drivers/kafka/kafka_driver.py` - Kafka 驱动

```python
class KafkaDriver(AbstractDriver):
    """
    Kafka 驱动实现（使用 confluent-kafka）
    """

    def __init__(self, driver_config: DriverConfig):
        """
        初始化驱动

        参数:
            driver_config: 驱动配置
        """
        self.driver_config = driver_config
        self.client_type = "confluent-kafka"
        self._topic_manager = None

    async def initialize(self):
        """
        初始化驱动

        步骤:
        1. 创建 Topic 管理器
        2. 如果 reset=True，删除并重新创建 Topic
        """

    async def cleanup(self):
        """清理驱动资源"""
        await self._topic_manager.close()

    def create_producer(self, config: Dict) -> KafkaProducer:
        """
        创建 Kafka 生产者

        合并配置: common_config + producer_config + config
        """

    def create_consumer(self, config: Dict) -> KafkaConsumer:
        """
        创建 Kafka 消费者

        合并配置: common_config + consumer_config + config
        """

    def create_topic_manager(self) -> KafkaTopicManager:
        """创建 Topic 管理器"""

    def _get_bootstrap_servers(self) -> str:
        """从 common_config 提取 bootstrap.servers"""

    def get_client_info(self) -> Dict:
        """返回驱动元数据"""
```

---

#### 5.2.2 `/benchmark/drivers/kafka/kafka_producer.py` - Kafka 生产者

**关键设计**: 回调式延迟测量

```python
class KafkaProducer(AbstractProducer, LoggerMixin):
    """
    Confluent Kafka 生产者（针对数字孪生场景优化）
    """

    def __init__(
        self,
        bootstrap_servers: str,
        config: Dict,
        common_config: Optional[Dict] = None
    ):
        """
        初始化生产者

        关键初始化:
        1. 合并配置（应用数字孪生默认值）
        2. 创建 LatencyRecorder（HdrHistogram）
        3. 初始化 confluent_kafka.Producer
        """
        self.bootstrap_servers = bootstrap_servers
        self.config = config
        self.common_config = common_config or {}

        # 性能配置
        self._producer: Optional[confluent_kafka.Producer] = None
        self._delivery_reports: Dict = {}
        self._pending_messages: int = 0
        self._max_pending_messages: int = 10000  # 背压限制

        # 延迟测量
        self._latency_recorder = LatencyRecorder()
        self._message_send_times: Dict = {}

    def _merge_configs(self) -> Dict:
        """
        合并配置并应用数字孪生默认值

        数字孪生优化配置:
        - batch.size=65536 (64KB 批次)
        - linger.ms=5 (5ms 延迟，平衡延迟和吞吐量)
        - compression.type=lz4 (快速压缩)
        - acks=all (可靠性)
        - enable.idempotence=true (精确一次)

        注意: 所有值转换为字符串（confluent-kafka 要求）
        """

    def _delivery_callback(self, err, msg):
        """
        交付回调（关键方法）

        被 confluent-kafka 调用，当消息交付完成时

        步骤:
        1. 从 key 或 _track_id header 提取 message_id
        2. 从 _message_send_times 获取 send_time
        3. 计算延迟 (ack_time - send_time)
        4. 记录延迟到 _latency_recorder
        5. 存储交付报告
        6. _pending_messages -= 1

        这是精确延迟测量的核心
        """

    async def send_message(
        self,
        topic: str,
        message: Message
    ) -> ProducedMessage:
        """
        发送单条消息（非阻塞）

        步骤:
        1. 背压控制（如果 pending >= max，等待）
        2. 生成 message_id（从 key 或创建 _track_id header）
        3. 记录 send_time
        4. 调用 producer.produce（非阻塞，带回调）
        5. 调用 producer.poll(0) 触发回调
        6. _pending_messages += 1

        重要: 这是非阻塞的，实际发送在后台完成
               回调稍后执行
        """

    async def send_batch(
        self,
        topic: str,
        messages: List[Message]
    ) -> List[ProducedMessage]:
        """
        批量发送消息

        使用 semaphore 限制并发（最多 100）
        每条消息调用 send_message
        """

    async def flush(self):
        """
        刷新生产者

        调用阻塞 producer.flush(timeout=30) 在 executor 中
        确保所有消息已发送
        """

    async def close(self):
        """关闭生产者"""
        await self.flush()
        # 清理资源

    def get_latency_snapshot(self) -> LatencySnapshot:
        """
        获取延迟快照

        从 _latency_recorder 获取当前统计

        关键: 必须在 wait_for_delivery 之后调用
        """

    async def wait_for_delivery(
        self,
        timeout_seconds: int = 60
    ) -> Dict:
        """
        等待所有消息交付（重要方法）

        步骤:
        1. 循环调用 producer.poll(0.1)
        2. 检查 _pending_messages 是否为 0
        3. 超时保护

        目的: 确保所有回调执行完成，才能获取准确的延迟统计

        返回: {'status': 'success', 'pending': 0}
        """
```

**关键延迟测量流程**:
```
1. send_message() 记录 send_time
     ↓
2. producer.produce() 非阻塞发送
     ↓
3. ... (异步发送到 Kafka) ...
     ↓
4. Kafka broker 确认
     ↓
5. _delivery_callback() 被调用
     ↓
6. 计算延迟 (ack_time - send_time)
     ↓
7. 记录到 HdrHistogram
     ↓
8. wait_for_delivery() 等待所有回调完成
     ↓
9. get_latency_snapshot() 获取统计
```

---

#### 5.2.3 `/benchmark/drivers/kafka/kafka_consumer.py` - Kafka 消费者

```python
class KafkaConsumer(AbstractConsumer, LoggerMixin):
    """
    Confluent Kafka 消费者（性能测试优化）
    """

    def __init__(
        self,
        bootstrap_servers: str,
        config: Dict,
        common_config: Optional[Dict] = None
    ):
        """初始化消费者"""
        self.bootstrap_servers = bootstrap_servers
        self.config = config
        self.common_config = common_config or {}

        self._consumer: Optional[confluent_kafka.Consumer] = None
        self._subscribed_topics: List[str] = []
        self._running: bool = False
        self._executor = ThreadPoolExecutor(max_workers=2)

    def _merge_configs(self) -> Dict:
        """
        合并配置并应用性能测试默认值

        性能测试配置:
        - enable.auto.commit=false (手动提交，精确控制)
        - auto.offset.reset=latest (从最新偏移量开始)
        - session.timeout.ms=30000
        - fetch.min.bytes=1 (立即获取)

        注意问题: auto.offset.reset=latest 可能导致消息丢失
                  应该使用 earliest
        """

    async def subscribe(
        self,
        topics: List[str],
        subscription_name: str
    ):
        """
        订阅 Topic

        步骤:
        1. 设置 group.id = subscription_name
        2. 在 executor 中调用 consumer.subscribe(topics)

        注意: 不等待分区分配完成（异步）
        """

    async def consume_messages(
        self,
        timeout_seconds: int
    ) -> AsyncIterator[ConsumedMessage]:
        """
        消费消息（异步迭代器）

        步骤:
        1. 在 executor 中运行阻塞 poll 循环
        2. 每次 poll(0.1) 获取消息
        3. 转换为 ConsumedMessage
        4. 每 100 条消息提交一次偏移量
        5. 达到 timeout 时停止
        6. yield 所有消费的消息

        返回: 异步迭代器
        """

    async def commit_offsets(self):
        """提交当前偏移量"""

    async def commit(self):
        """提交偏移量（别名）"""

    async def close(self):
        """
        关闭消费者

        步骤:
        1. 最后提交偏移量
        2. 关闭 consumer
        3. 关闭 executor
        """
```

---

#### 5.2.4 `/benchmark/drivers/kafka/kafka_topic_manager.py` - Kafka Topic 管理器

```python
class KafkaTopicManager(AbstractTopicManager, LoggerMixin):
    """
    Kafka Topic 管理器（支持多种 Python 客户端）
    """

    def __init__(self, config: DriverConfig):
        """初始化 Topic 管理器"""
        self.config = config
        self.client_type = "confluent-kafka"  # 或 kafka-python, aiokafka
        self._admin_client = None
        self.bootstrap_servers = self._get_bootstrap_servers()

    async def _initialize_admin_client(self):
        """
        初始化管理客户端

        根据 client_type 创建相应的 admin client:
        - kafka-python: KafkaAdminClient
        - confluent-kafka: AdminClient
        - aiokafka: AIOKafkaAdminClient
        """

    async def _init_confluent_kafka_admin(self):
        """
        初始化 confluent-kafka AdminClient

        注意: 过滤不支持的参数
        """

    async def create_topic(
        self,
        name: str,
        partitions: int,
        replication_factor: int,
        config: Optional[Dict] = None
    ):
        """
        创建 Topic

        步骤:
        1. 创建 NewTopic 对象（带配置）
        2. 在 executor 中调用 admin client 创建方法
        3. 优雅处理"Topic 已存在"错误（忽略）

        超时: 30 秒
        """

    async def delete_topic(self, name: str):
        """
        删除 Topic

        步骤:
        1. 在 executor 中调用 admin client 删除方法
        2. 优雅处理"Topic 不存在"错误（忽略）

        超时: 30 秒
        """

    async def list_topics(self) -> List[str]:
        """
        列出所有 Topic

        返回: Topic 名称列表（排除内部 Topic）
        """

    async def topic_exists(self, name: str) -> bool:
        """检查 Topic 是否存在"""

    async def close(self):
        """关闭 admin client"""
```

---

### 5.3 `/benchmark/utils/latency_recorder.py` - 延迟记录器

#### 5.3.1 数据类: `LatencySnapshot`

```python
@dataclass
class LatencySnapshot:
    """延迟快照"""
    count: int                      # 样本数
    min_ms: float                   # 最小延迟
    max_ms: float                   # 最大延迟
    mean_ms: float                  # 平均延迟
    stddev_ms: float                # 标准差

    # 百分位数
    p50_ms: float
    p75_ms: float
    p95_ms: float
    p99_ms: float
    p99_9_ms: float
    p99_99_ms: float
```

#### 5.3.2 类: `LatencyRecorder`

**作用**: 高精度延迟记录（使用 HdrHistogram）

```python
class LatencyRecorder:
    """
    延迟记录器（使用 HdrHistogram）
    """

    def __init__(
        self,
        lowest_trackable_value: int = 1,          # 最小值: 1µs
        highest_trackable_value: int = 3600000,   # 最大值: 1 小时
        significant_figures: int = 3,             # 精度: 3 位有效数字
        use_hdr: bool = True                      # 是否使用 HdrHistogram
    ):
        """
        初始化延迟记录器

        如果 HdrHistogram 可用:
            创建 HdrHistogram（1µs 到 1小时 范围）
        否则:
            回退到列表存储
        """
        self.use_hdr = use_hdr and HAS_HDR_HISTOGRAM

        if self.use_hdr:
            self._histogram = HdrHistogram(
                lowest_trackable_value,
                highest_trackable_value,
                significant_figures
            )
        else:
            self._values = []

        # 基本统计
        self._count = 0
        self._sum = 0.0
        self._sum_squares = 0.0
        self._min = float('inf')
        self._max = float('-inf')

    def record_latency(self, latency_ms: float):
        """
        记录延迟样本

        步骤:
        1. 更新基本统计（count, sum, min, max）
        2. 如果使用 HdrHistogram:
               记录到 histogram（转换为微秒）
           否则:
               添加到 _values 列表
        """

    def get_snapshot(self) -> LatencySnapshot:
        """
        获取延迟快照

        步骤:
        1. 从基本统计计算 mean, stddev
        2. 如果使用 HdrHistogram:
               从 histogram 获取百分位数
           否则:
               使用 numpy 计算百分位数
        3. 返回 LatencySnapshot
        """

    def export_histogram(self) -> Optional[Dict]:
        """
        导出 histogram 数据（用于聚合）

        如果使用 HdrHistogram:
            导出 base64 编码的 histogram
        否则:
            返回 None

        关键: 用于多 Worker 延迟聚合
        """

    def reset(self):
        """重置所有统计"""

    def merge(self, other: 'LatencyRecorder'):
        """
        合并另一个记录器

        如果两者都使用 HdrHistogram:
            使用 HdrHistogram.add() 合并
        否则:
            合并基本统计和值列表
        """
```

#### 5.3.3 类: `EndToEndLatencyRecorder`

```python
class EndToEndLatencyRecorder(LatencyRecorder):
    """端到端延迟记录器（生产者到消费者）"""

    def record_from_timestamp(self, send_timestamp_ms: float):
        """
        从发送时间戳记录延迟

        步骤:
        1. 获取当前时间
        2. 计算延迟 (current_time - send_timestamp)
        3. 调用 record_latency()

        用途: 从消息 header 中的 send_timestamp 计算端到端延迟
        """
```

#### 5.3.4 函数: `snapshot_to_legacy_stats`

```python
def snapshot_to_legacy_stats(
    snapshot: LatencySnapshot,
    histogram_data: Optional[Dict] = None
) -> LatencyStats:
    """
    将 LatencySnapshot 转换为 benchmark.core.results.LatencyStats

    用途: 适配不同的延迟统计格式
    """
```

**HdrHistogram 优势**:
1. **高精度**: 支持微秒级精度
2. **低内存**: 固定内存占用，不随样本数增长
3. **准确聚合**: 支持 histogram 合并，保持精度
4. **性能**: O(1) 记录时间

---

### 5.4 `/benchmark/utils/rate_limiter.py` - 速率限制器

#### 5.4.1 枚举: `RateLimiterType`

```python
class RateLimiterType(Enum):
    SMOOTH = "smooth"       # 平滑速率限制（均匀间隔）
    BURSTY = "bursty"       # 突发速率限制（允许突发，最多 1 秒）
```

#### 5.4.2 类: `AsyncRateLimiter`

**作用**: 异步速率限制器（类似 Guava RateLimiter）

```python
class AsyncRateLimiter:
    """
    异步速率限制器（令牌桶算法）
    """

    def __init__(
        self,
        permits_per_second: float,
        limiter_type: RateLimiterType = RateLimiterType.SMOOTH
    ):
        """
        初始化速率限制器

        参数:
            permits_per_second: 目标速率（许可/秒）
            limiter_type: SMOOTH 或 BURSTY
        """
        self.permits_per_second = permits_per_second
        self.limiter_type = limiter_type
        self._interval = 1_000_000 / permits_per_second  # 微秒
        self._next_free_ticket_micros = 0
        self._lock = asyncio.Lock()

        # BURSTY 模式专用
        if limiter_type == RateLimiterType.BURSTY:
            self._stored_permits = 0
            self._max_permits = int(permits_per_second)  # 最多存储 1 秒的许可

    async def acquire(self, permits: int = 1) -> float:
        """
        获取许可（阻塞直到可用）

        返回: 等待时间（秒）

        步骤:
        1. 计算需要等待的时间
        2. 预留许可
        3. 如果需要等待，asyncio.sleep
        4. 返回等待时间
        """
        async with self._lock:
            wait_micros = self._reserve_and_get_wait_length(permits)

        if wait_micros > 0:
            await asyncio.sleep(wait_micros / 1_000_000)

        return wait_micros / 1_000_000

    async def try_acquire(
        self,
        permits: int = 1,
        timeout_seconds: float = 0
    ) -> bool:
        """
        尝试获取许可（带超时）

        返回: True 如果成功，False 如果超时
        """
        async with self._lock:
            wait_micros = self._reserve_and_get_wait_length(permits)

        if wait_micros > timeout_seconds * 1_000_000:
            return False

        if wait_micros > 0:
            await asyncio.sleep(wait_micros / 1_000_000)

        return True

    def _reserve_and_get_wait_length(self, permits: int) -> int:
        """
        预留许可并返回等待时间（微秒）

        根据 limiter_type 调用不同实现:
        - SMOOTH: _reserve_and_get_wait_length_smooth
        - BURSTY: _reserve_and_get_wait_length_bursty
        """
        now_micros = self._now_micros()

        if self.limiter_type == RateLimiterType.SMOOTH:
            return self._reserve_and_get_wait_length_smooth(permits, now_micros)
        else:
            return self._reserve_and_get_wait_length_bursty(permits, now_micros)

    def _reserve_and_get_wait_length_smooth(
        self,
        permits: int,
        now_micros: int
    ) -> int:
        """
        SMOOTH 模式实现

        逻辑:
        1. 等待直到 next_free_ticket
        2. 安排下一个 ticket 在 interval × permits 之后

        效果: 均匀间隔的许可分配
        """
        wait_micros = max(0, self._next_free_ticket_micros - now_micros)
        self._next_free_ticket_micros = max(now_micros, self._next_free_ticket_micros) + int(self._interval * permits)
        return wait_micros

    def _reserve_and_get_wait_length_bursty(
        self,
        permits: int,
        now_micros: int
    ) -> int:
        """
        BURSTY 模式实现

        逻辑:
        1. 根据经过的时间重新同步 stored_permits
        2. 使用 stored_permits（无需等待）
        3. 剩余部分计算等待时间

        效果: 允许突发消费（最多 1 秒的储备）
        """
        # 重新同步 stored_permits
        elapsed_micros = now_micros - self._next_free_ticket_micros
        if elapsed_micros > 0:
            new_permits = int(elapsed_micros / self._interval)
            self._stored_permits = min(self._max_permits, self._stored_permits + new_permits)
            self._next_free_ticket_micros = now_micros

        # 使用 stored_permits
        permits_to_use_from_stored = min(permits, self._stored_permits)
        self._stored_permits -= permits_to_use_from_stored
        remaining_permits = permits - permits_to_use_from_stored

        # 计算剩余部分的等待时间
        if remaining_permits > 0:
            wait_micros = int(self._interval * remaining_permits)
            self._next_free_ticket_micros += wait_micros
            return wait_micros

        return 0

    async def set_rate(self, new_permits_per_second: float):
        """动态更新速率"""

    def get_rate(self) -> float:
        """获取当前速率"""

    @staticmethod
    def _now_micros() -> int:
        """获取当前时间（微秒）"""
        return int(time.time() * 1_000_000)
```

#### 5.4.3 类: `NoOpRateLimiter`

```python
class NoOpRateLimiter:
    """无操作速率限制器（无限制）"""

    async def acquire(self, permits: int = 1) -> float:
        return 0.0

    async def try_acquire(self, permits: int = 1, timeout_seconds: float = 0) -> bool:
        return True
```

---

### 5.5 `/workers/kafka_worker.py` - Kafka Worker 实现

```python
class KafkaWorker(BaseWorker):
    """
    Kafka Worker 实现
    """

    def __init__(
        self,
        worker_id: str,
        driver_config: DriverConfig,
        use_multiprocessing: bool = True,
        num_processes: int = 4
    ):
        """
        初始化 Kafka Worker

        参数:
            worker_id: Worker 唯一标识
            driver_config: Kafka 驱动配置
            use_multiprocessing: 是否启用多进程（高吞吐量）
            num_processes: 进程数（默认 4）
        """
        super().__init__(worker_id)
        self.driver_config = driver_config
        self.client_type = "confluent-kafka"
        self._driver: Optional[KafkaDriver] = None
        self.use_multiprocessing = use_multiprocessing
        self.num_processes = num_processes

    async def start(self):
        """
        启动 Worker

        步骤:
        1. 创建 KafkaDriver
        2. 初始化驱动
        3. 调用父类 start
        """

    async def stop(self):
        """
        停止 Worker

        步骤:
        1. 清理驱动
        2. 调用父类 stop
        """

    async def _execute_producer_task(
        self,
        task: ProducerTask
    ) -> Dict:
        """
        执行生产者任务（核心方法）

        工作流:

        1. 判断执行策略:
           - 高吞吐量 (rate > 1500 msg/s): 使用 ParallelSender（多进程）
           - 中低速率 (0 < rate ≤ 1500): 使用 AsyncRateLimiter（单进程）
           - 无速率限制 (rate = 0): 批量发送（单进程）

        2. 创建生产者:
           producer = self._driver.create_producer(config)

        3. 生成 payload:
           payload = DriverUtils.create_test_payload(size, payload_data)

        4. 发送消息（根据策略）:

           策略 A - 高吞吐量（多进程）:
           - 使用 ParallelSender
           - 分配任务到多个进程
           - 每个进程独立发送

           策略 B - 中低速率（速率限制）:
           for i in range(num_messages):
               # 生成消息 key
               key = DriverUtils.generate_message_key(pattern, i, total)

               # 添加数字孪生元数据到 headers
               headers = {
                   'dt_sensor_id': f'sensor-{i % 1000}',
                   'dt_timestamp': str(int(time.time() * 1000)),
                   'send_timestamp': str(int(time.time() * 1000))
               }

               message = Message(key, payload, headers, timestamp)

               # 速率限制
               await rate_limiter.acquire()

               # 发送消息
               await producer.send_message(topic, message)

           策略 C - 无速率限制（批量发送）:
           - 创建所有消息
           - 使用 send_batch 批量发送

        5. 刷新生产者:
           await producer.flush()

        6. 等待交付完成（关键）:
           await producer.wait_for_delivery(timeout=60)

        7. 获取延迟快照:
           latency_snapshot = producer.get_latency_snapshot()

        8. 关闭生产者:
           await producer.close()

        9. 计算统计:
           throughput_stats = DriverUtils.calculate_throughput_stats(...)
           latency_stats = snapshot_to_legacy_stats(latency_snapshot)
           error_stats = DriverUtils.create_error_stats(errors)

        10. 返回结果:
            return {
                'throughput': throughput_stats,
                'latency': latency_stats,
                'errors': error_stats
            }
        """

    async def _execute_consumer_task(
        self,
        task: ConsumerTask
    ) -> Dict:
        """
        执行消费者任务

        工作流:

        1. 创建消费者:
           consumer = self._driver.create_consumer(config)

        2. 订阅 Topic:
           await consumer.subscribe(task.topics, task.subscription_name)

        3. 消费消息（直到测试时长或生产者完成）:
           messages_consumed = []
           e2e_latency_recorder = EndToEndLatencyRecorder()

           async for message in consumer.consume_messages(test_duration):
               messages_consumed.append(message)

               # 提取端到端延迟
               if 'send_timestamp' in message.headers:
                   send_ts = float(message.headers['send_timestamp'])
                   e2e_latency_recorder.record_from_timestamp(send_ts)

        4. 提交偏移量:
           await consumer.commit()

        5. 关闭消费者:
           await consumer.close()

        6. 计算统计:
           throughput_stats = DriverUtils.calculate_throughput_stats(...)
           error_stats = DriverUtils.create_error_stats(errors)

        7. 返回结果:
           return {
               'throughput': throughput_stats,
               'errors': error_stats
           }
        """
```

---

## 6. 工作流程

### 6.1 完整基准测试工作流

```
┌─────────────────────────────────────────────────────────────────┐
│ 1. 用户启动测试                                                   │
│    py-omb-coordinator --workload test.yaml --driver kafka.yaml  │
│                       --workers http://w1:8001 http://w2:8001   │
└────────────────────────────┬────────────────────────────────────┘
                             │
┌────────────────────────────▼────────────────────────────────────┐
│ 2. CLI 初始化 (cli.py)                                           │
│    - 加载 workload 配置 (ConfigLoader.load_workload)             │
│    - 加载 driver 配置 (ConfigLoader.load_driver)                 │
│    - 创建 BenchmarkConfig                                        │
│    - 创建 BenchmarkCoordinator                                   │
└────────────────────────────┬────────────────────────────────────┘
                             │
┌────────────────────────────▼────────────────────────────────────┐
│ 3. 协调器编排 (BenchmarkCoordinator.run_benchmark)              │
│    ├─ 生成唯一 test_id (name_timestamp)                         │
│    ├─ 创建唯一 Topic 名称 (benchmark-{test_id}-topic-{idx})     │
│    ├─ 验证配置                                                   │
│    └─ 检查 Worker 健康状态                                       │
│       (并发 HTTP GET /health 到所有 Worker)                      │
└────────────────────────────┬────────────────────────────────────┘
                             │
┌────────────────────────────▼────────────────────────────────────┐
│ 4. 创建 Topic (_setup_topics)                                   │
│    ├─ 动态导入驱动类                                             │
│    ├─ 创建并初始化驱动                                           │
│    ├─ 创建 Topic 管理器                                          │
│    └─ 创建所有唯一 Topic（配置的分区数）                         │
└────────────────────────────┬────────────────────────────────────┘
                             │
┌────────────────────────────▼────────────────────────────────────┐
│ 5. 启动系统监控 (SystemMonitor.start)                           │
│    - 后台线程每秒收集 CPU、内存、网络、磁盘统计                  │
└────────────────────────────┬────────────────────────────────────┘
                             │
┌────────────────────────────▼────────────────────────────────────┐
│ 6. 预热阶段（如启用 warmup_enabled）                             │
│    ├─ 创建预热配置（相同参数，较短时长）                         │
│    ├─ 运行测试阶段（使用预热配置）                               │
│    └─ 丢弃预热结果                                               │
└────────────────────────────┬────────────────────────────────────┘
                             │
┌────────────────────────────▼────────────────────────────────────┐
│ 7. 主测试阶段 (_run_test_phase) ⭐ 核心流程                      │
│                                                                  │
│    7.1 生成任务                                                  │
│    ├─ 生成生产者任务 (_generate_producer_tasks)                 │
│    │   对于每个 Topic × producers_per_topic:                     │
│    │      创建 ProducerTask (task_id, topic, num_messages, ...)│
│    │                                                             │
│    └─ 生成消费者任务 (_generate_consumer_tasks)                 │
│        对于每个 Topic × subscriptions × consumers:               │
│           创建 ConsumerTask (task_id, topics, subscription, ...)│
│                                                                  │
│    7.2 分配任务                                                  │
│    └─ 将任务分配到 Worker (_distribute_tasks)                   │
│        使用轮询策略均衡分配                                      │
│                                                                  │
│    7.3 启动任务 ⭐ 关键时序                                      │
│    ├─ 先启动所有消费者任务（并发）                               │
│    │   for worker_url, tasks in zip(workers, consumer_tasks):   │
│    │       consumer_futures.append(                             │
│    │           _run_worker_consumer_tasks(worker_url, tasks)    │
│    │       )                                                     │
│    │                                                             │
│    ├─ 等待 5 秒（让消费者订阅完成）⏱                            │
│    │   await asyncio.sleep(5)                                   │
│    │                                                             │
│    └─ 再启动所有生产者任务（并发）                               │
│        for worker_url, tasks in zip(workers, producer_tasks):   │
│            producer_futures.append(                             │
│                _run_worker_producer_tasks(worker_url, tasks)    │
│            )                                                     │
│                                                                  │
│    7.4 等待任务完成                                              │
│    ├─ 等待所有生产者完成（带超时保护）                           │
│    │   await asyncio.wait_for(                                  │
│    │       asyncio.gather(*producer_futures),                   │
│    │       timeout=test_duration + 180                          │
│    │   )                                                         │
│    │                                                             │
│    └─ 等待所有消费者完成（带超时保护）                           │
│        await asyncio.wait_for(                                  │
│            asyncio.gather(*consumer_futures),                   │
│            timeout=test_duration + 180                          │
│        )                                                         │
│                                                                  │
│    7.5 收集结果                                                  │
│    └─ 从所有 Worker 收集 WorkerResult                           │
└────────────────────────────┬────────────────────────────────────┘
                             │
┌────────────────────────────▼────────────────────────────────────┐
│ 8. Worker 执行任务 (KafkaWorker)                                │
│                                                                  │
│    8.1 生产者任务 (_execute_producer_task)                      │
│    ├─ HTTP POST /producer/start                                 │
│    ├─ 创建 Kafka 生产者                                          │
│    ├─ 判断执行策略（根据速率）                                   │
│    ├─ 发送消息（带 Digital Twin headers）                       │
│    ├─ 刷新生产者                                                 │
│    ├─ 等待交付完成（wait_for_delivery）⭐                       │
│    ├─ 获取延迟快照（get_latency_snapshot）                      │
│    └─ 返回 WorkerResult                                          │
│                                                                  │
│    8.2 消费者任务 (_execute_consumer_task)                      │
│    ├─ HTTP POST /consumer/start                                 │
│    ├─ 创建 Kafka 消费者                                          │
│    ├─ 订阅 Topic（consumer group）                              │
│    ├─ 消费消息（直到测试时长）                                   │
│    ├─ 提取端到端延迟（从 send_timestamp header）                │
│    ├─ 提交偏移量                                                 │
│    └─ 返回 WorkerResult                                          │
└────────────────────────────┬────────────────────────────────────┘
                             │
┌────────────────────────────▼────────────────────────────────────┐
│ 9. 结果聚合 (ResultCollector.finalize_result)                   │
│    ├─ 停止系统监控                                               │
│    ├─ 聚合生产者吞吐量统计                                       │
│    ├─ 聚合消费者吞吐量统计                                       │
│    ├─ 聚合延迟统计（尝试合并 HdrHistogram）⭐                   │
│    ├─ 收集系统监控统计                                           │
│    └─ 创建 BenchmarkResult                                       │
└────────────────────────────┬────────────────────────────────────┘
                             │
┌────────────────────────────▼────────────────────────────────────┐
│ 10. 清理 Topic (_cleanup_test_topics)（如启用）                │
│     ├─ 等待 5 秒（让消息落地）                                   │
│     ├─ 创建新驱动实例                                            │
│     └─ 删除所有测试 Topic（每个 30 秒超时）                      │
└────────────────────────────┬────────────────────────────────────┘
                             │
┌────────────────────────────▼────────────────────────────────────┐
│ 11. 保存和展示结果 (CLI)                                        │
│     ├─ 保存到 JSON (benchmark_{test_id}.json)                   │
│     ├─ 导出到 CSV (benchmark_{test_id}.csv)                     │
│     └─ 显示摘要表格（Rich）                                      │
│         - 生产者吞吐量: XXX msg/s, XXX MB/s                     │
│         - 消费者吞吐量: XXX msg/s, XXX MB/s                     │
│         - 延迟: p50=X.XX ms, p95=X.XX ms, p99=X.XX ms           │
│         - 系统资源: CPU X%, 内存 X%                             │
└─────────────────────────────────────────────────────────────────┘
```

### 6.2 关键时序图

```
Coordinator              Worker 1              Worker 2              Kafka
    │                        │                      │                   │
    ├─ Check Health ─────────>                     │                   │
    ├─ Check Health ─────────────────────────────>│                   │
    │                        │                      │                   │
    ├─ Create Topics ────────────────────────────────────────────────>│
    │                        │                      │                   │
    ├─ Start Consumers ──────>                     │                   │
    ├─ Start Consumers ──────────────────────────>│                   │
    │                        │                      │                   │
    │                        ├─ Subscribe ─────────────────────────────>│
    │                        ├─ Subscribe ─────────────────────────────>│
    │                        │                      │                   │
    ├─ Sleep 5s ⏱           │                      │                   │
    │                        │                      │                   │
    ├─ Start Producers ──────>                     │                   │
    ├─ Start Producers ──────────────────────────>│                   │
    │                        │                      │                   │
    │                        ├─ Produce ───────────────────────────────>│
    │                        ├─ Produce ───────────────────────────────>│
    │                        │                      │                   │
    │                        │                      ├─ Consume <────────┤
    │                        │                      ├─ Consume <────────┤
    │                        │                      │                   │
    │                        ├─ Flush ─────────────────────────────────>│
    │                        ├─ Wait Delivery ─────────────────────────>│
    │                        │                      │                   │
    │<─ Producer Results ────┤                      │                   │
    │<─ Consumer Results ────────────────────────────┤                   │
    │                        │                      │                   │
    ├─ Delete Topics ────────────────────────────────────────────────>│
    │                        │                      │                   │
```

---

## 7. 配置系统

### 7.1 配置层级结构

```
基准测试配置 (BenchmarkConfig)
├─ workers: ["http://localhost:8001", "http://localhost:8002"]
├─ log_level: "INFO"
├─ results_dir: "./results"
├─ enable_monitoring: true
├─ warmup_enabled: true
└─ cleanup_enabled: true

工作负载配置 (WorkloadConfig)
├─ 基本信息
│  └─ name: "Throughput Test"
│
├─ Topic 配置
│  ├─ topics: 1
│  └─ partitions_per_topic: 16
│
├─ 消息配置
│  ├─ message_size: 1024
│  ├─ payload_file: null
│  └─ key_distributor: "NO_KEY"
│
├─ 生产者配置
│  ├─ producers_per_topic: 10
│  └─ producer_rate: 50000
│
├─ 消费者配置
│  ├─ subscriptions_per_topic: 1
│  └─ consumer_per_subscription: 4
│
└─ 测试时长
   ├─ test_duration_minutes: 15
   └─ warmup_duration_minutes: 1

驱动配置 (DriverConfig)
├─ 基本信息
│  ├─ name: "Kafka"
│  └─ driver_class: "benchmark.drivers.kafka.KafkaDriver"
│
├─ Topic 管理
│  ├─ replication_factor: 3
│  └─ reset: false
│
├─ 通用配置 (common_config)
│  └─ bootstrap.servers: "localhost:9092"
│
├─ 生产者配置 (producer_config)
│  ├─ acks: "all"
│  ├─ batch.size: "65536"
│  ├─ linger.ms: "5"
│  ├─ compression.type: "lz4"
│  └─ enable.idempotence: "true"
│
├─ 消费者配置 (consumer_config)
│  ├─ auto.offset.reset: "latest"  ⚠️ 问题
│  ├─ enable.auto.commit: "false"
│  └─ session.timeout.ms: "30000"
│
└─ Topic 配置 (topic_config)
   └─ min.insync.replicas: "2"
```

### 7.2 配置文件示例

#### 工作负载配置 (workloads/throughput-test-1kb.yaml)

```yaml
name: Throughput Test 1KB
topics: 1
partitionsPerTopic: 16
messageSize: 1024
keyDistributor: NO_KEY
producersPerTopic: 10
producerRate: 50000
subscriptionsPerTopic: 1
consumerPerSubscription: 4
testDurationMinutes: 15
warmupDurationMinutes: 1
```

#### 驱动配置 (configs/kafka-digital-twin.yaml)

```yaml
name: Kafka Digital Twin
driverClass: benchmark.drivers.kafka.KafkaDriver
replicationFactor: 3
reset: false

commonConfig: |
  bootstrap.servers=localhost:9092

producerConfig: |
  acks=all
  batch.size=65536
  linger.ms=5
  compression.type=lz4
  enable.idempotence=true
  max.in.flight.requests.per.connection=5

consumerConfig: |
  auto.offset.reset=earliest
  enable.auto.commit=false
  session.timeout.ms=30000
  fetch.min.bytes=1

topicConfig: |
  min.insync.replicas=2
  retention.ms=86400000
```

### 7.3 配置加载和验证流程

```
1. YAML 文件加载
   ├─ PyYAML 读取文件
   └─ 解析为 Python 字典

2. Pydantic 验证
   ├─ 字段类型验证（int, str, bool, etc.）
   ├─ 范围验证（topics ≥ 1, producer_rate ≥ 0, etc.）
   └─ 自定义验证器（parse_config_string）

3. 类型转换
   ├─ camelCase → snake_case（自动）
   ├─ 多行字符串 → Dict（parse_config_string）
   └─ 所有 Kafka 配置值 → 字符串（confluent-kafka 要求）

4. 配置合并
   ├─ common_config + producer_config → 生产者最终配置
   ├─ common_config + consumer_config → 消费者最终配置
   └─ 应用驱动默认值（数字孪生优化）

5. 配置注入
   ├─ BenchmarkCoordinator 接收所有配置
   ├─ 分发到 Worker
   └─ Worker 创建驱动和客户端
```

---

## 8. 类与函数完整参考

### 8.1 核心类总览

| 类名 | 文件 | 作用 | 关键方法 |
|------|------|------|----------|
| **WorkloadConfig** | core/config.py | 工作负载配置 | parse_config_string |
| **DriverConfig** | core/config.py | 驱动配置 | parse_config_string |
| **BenchmarkConfig** | core/config.py | 基准测试配置 | - |
| **ConfigLoader** | core/config.py | 配置加载器 | load_workload, load_driver, load_benchmark |
| **BenchmarkCoordinator** | core/coordinator.py | 协调器 | run_benchmark, _run_test_phase, _check_worker_health |
| **ProducerTask** | core/worker.py | 生产者任务 | - (dataclass) |
| **ConsumerTask** | core/worker.py | 消费者任务 | - (dataclass) |
| **BaseWorker** | core/worker.py | Worker 基类 | run_producer_tasks, run_consumer_tasks, _execute_producer_task, _execute_consumer_task |
| **LatencyStats** | core/results.py | 延迟统计 | - (dataclass) |
| **ThroughputStats** | core/results.py | 吞吐量统计 | - (dataclass) |
| **ErrorStats** | core/results.py | 错误统计 | - (dataclass) |
| **WorkerResult** | core/results.py | Worker 结果 | - (dataclass) |
| **BenchmarkResult** | core/results.py | 基准测试结果 | to_dict, to_json |
| **ResultCollector** | core/results.py | 结果收集器 | create_result, finalize_result, _aggregate_throughput_stats, _aggregate_latency_stats |
| **SystemMetrics** | core/monitoring.py | 系统指标 | - (dataclass) |
| **SystemStats** | core/monitoring.py | 系统统计 | - (dataclass) |
| **SystemMonitor** | core/monitoring.py | 系统监控器 | start, stop, get_stats, plot_metrics |
| **Message** | drivers/base.py | 消息结构 | - (dataclass) |
| **ProducedMessage** | drivers/base.py | 已发送消息 | - (dataclass) |
| **ConsumedMessage** | drivers/base.py | 已消费消息 | - (dataclass) |
| **AbstractProducer** | drivers/base.py | 生产者接口 | send_message, send_batch, flush, close |
| **AbstractConsumer** | drivers/base.py | 消费者接口 | subscribe, consume_messages, commit, close |
| **AbstractTopicManager** | drivers/base.py | Topic 管理器接口 | create_topic, delete_topic, list_topics |
| **AbstractDriver** | drivers/base.py | 驱动接口 | initialize, cleanup, create_producer, create_consumer, create_topic_manager |
| **DriverUtils** | drivers/base.py | 驱动工具 | calculate_throughput_stats, calculate_latency_stats, generate_message_key, create_test_payload |
| **KafkaDriver** | drivers/kafka/kafka_driver.py | Kafka 驱动 | initialize, create_producer, create_consumer, create_topic_manager |
| **KafkaProducer** | drivers/kafka/kafka_producer.py | Kafka 生产者 | send_message, flush, wait_for_delivery, get_latency_snapshot, _delivery_callback |
| **KafkaConsumer** | drivers/kafka/kafka_consumer.py | Kafka 消费者 | subscribe, consume_messages, commit, close |
| **KafkaTopicManager** | drivers/kafka/kafka_topic_manager.py | Kafka Topic 管理器 | create_topic, delete_topic, list_topics, topic_exists |
| **LatencySnapshot** | utils/latency_recorder.py | 延迟快照 | - (dataclass) |
| **LatencyRecorder** | utils/latency_recorder.py | 延迟记录器 | record_latency, get_snapshot, export_histogram, merge |
| **EndToEndLatencyRecorder** | utils/latency_recorder.py | 端到端延迟记录器 | record_from_timestamp |
| **AsyncRateLimiter** | utils/rate_limiter.py | 速率限制器 | acquire, try_acquire, set_rate |
| **NoOpRateLimiter** | utils/rate_limiter.py | 无操作速率限制器 | acquire, try_acquire |
| **KafkaWorker** | workers/kafka_worker.py | Kafka Worker | start, stop, _execute_producer_task, _execute_consumer_task |

### 8.2 关键函数总览

| 函数名 | 文件 | 作用 |
|--------|------|------|
| **load_env_config** | core/config.py | 从环境变量加载配置 |
| **merge_configs** | core/config.py | 合并两个 BenchmarkConfig |
| **snapshot_to_legacy_stats** | utils/latency_recorder.py | 转换延迟快照格式 |
| **create_rate_limiter** | utils/rate_limiter.py | 创建速率限制器 |
| **cli** | cli.py | 主命令行入口 |
| **run** | cli.py | 运行基准测试 |
| **validate** | cli.py | 验证配置文件 |
| **check_clients** | cli.py | 检查 Kafka 客户端可用性 |

---

## 9. 使用示例

### 9.1 快速开始

#### 启动 Worker

```bash
# 终端 1: 启动 Worker 1
python -m benchmark.api.worker_api \
    --worker-id worker-1 \
    --host 0.0.0.0 \
    --port 8001 \
    --driver-config configs/kafka-digital-twin.yaml

# 终端 2: 启动 Worker 2
python -m benchmark.api.worker_api \
    --worker-id worker-2 \
    --host 0.0.0.0 \
    --port 8002 \
    --driver-config configs/kafka-digital-twin.yaml
```

#### 运行基准测试

```bash
# 运行吞吐量测试
py-omb-coordinator \
    --workload workloads/throughput-test-1kb.yaml \
    --driver configs/kafka-digital-twin.yaml \
    --workers http://localhost:8001 http://localhost:8002 \
    --output-dir ./results

# 运行延迟测试
py-omb-coordinator \
    --workload workloads/latency-test-100b.yaml \
    --driver configs/kafka-latency.yaml \
    --workers http://localhost:8001 \
    --output-dir ./results
```

### 9.2 自定义工作负载

```yaml
# my-workload.yaml
name: My Custom Test
topics: 3
partitionsPerTopic: 8
messageSize: 512
keyDistributor: ROUND_ROBIN
producersPerTopic: 5
producerRate: 10000
subscriptionsPerTopic: 2
consumerPerSubscription: 2
testDurationMinutes: 10
warmupDurationMinutes: 2
```

### 9.3 编程方式使用

```python
import asyncio
from benchmark.core.config import ConfigLoader
from benchmark.core.coordinator import BenchmarkCoordinator

async def run_custom_benchmark():
    # 加载配置
    workload_config = ConfigLoader.load_workload("workloads/throughput-test-1kb.yaml")
    driver_config = ConfigLoader.load_driver("configs/kafka-digital-twin.yaml")

    # 创建基准测试配置
    from benchmark.core.config import BenchmarkConfig
    benchmark_config = BenchmarkConfig(
        workers=["http://localhost:8001", "http://localhost:8002"],
        log_level="INFO",
        results_dir="./results",
        enable_monitoring=True,
        warmup_enabled=True,
        cleanup_enabled=True
    )

    # 创建协调器
    coordinator = BenchmarkCoordinator(benchmark_config)

    # 运行基准测试
    async with coordinator:
        result = await coordinator.run_benchmark(
            workload_config=workload_config,
            driver_config=driver_config,
            payload_data=None
        )

    # 处理结果
    print(f"生产者吞吐量: {result.producer_stats.messages_per_second:.2f} msg/s")
    print(f"消费者吞吐量: {result.consumer_stats.messages_per_second:.2f} msg/s")
    print(f"延迟 p99: {result.latency_stats.p99_ms:.2f} ms")

if __name__ == "__main__":
    asyncio.run(run_custom_benchmark())
```

### 9.4 Docker Compose 部署

```yaml
# docker-compose.yml
version: '3.8'

services:
  # Kafka 集群
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    depends_on:
      - zookeeper
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  # Worker 节点
  worker-1:
    build: .
    command: >
      python -m benchmark.api.worker_api
      --worker-id worker-1
      --host 0.0.0.0
      --port 8001
      --driver-config /app/configs/kafka-digital-twin.yaml
    depends_on:
      - kafka
    ports:
      - "8001:8001"

  worker-2:
    build: .
    command: >
      python -m benchmark.api.worker_api
      --worker-id worker-2
      --host 0.0.0.0
      --port 8001
      --driver-config /app/configs/kafka-digital-twin.yaml
    depends_on:
      - kafka
    ports:
      - "8002:8001"

  # 协调器（手动运行测试）
  coordinator:
    build: .
    depends_on:
      - worker-1
      - worker-2
    volumes:
      - ./results:/app/results
    command: >
      py-omb-coordinator
      --workload /app/workloads/throughput-test-1kb.yaml
      --driver /app/configs/kafka-digital-twin.yaml
      --workers http://worker-1:8001 http://worker-2:8001
      --output-dir /app/results
```

启动:
```bash
docker-compose up -d
docker-compose logs -f coordinator
```

---

## 10. 关键技术决策

### 10.1 为什么选择 confluent-kafka？

**对比三种客户端**:

| 特性 | kafka-python | confluent-kafka | aiokafka |
|------|--------------|-----------------|----------|
| **性能** | 中等 | 最高 | 高 |
| **实现** | 纯 Python | C/C++ (librdkafka) | 纯 Python |
| **异步支持** | 否 | 部分（需封装） | 原生 |
| **延迟测量** | 基本 | 高精度（回调） | 基本 |
| **稳定性** | 稳定 | 非常稳定 | 稳定 |
| **生态** | 成熟 | 最成熟 | 新兴 |

**选择 confluent-kafka 原因**:
1. **最佳性能**: 基于 librdkafka，C 实现，吞吐量最高
2. **精确延迟**: 回调机制可精确测量发送到确认的延迟
3. **生产级**: 被广泛用于生产环境
4. **功能完整**: 支持所有 Kafka 特性

### 10.2 为什么使用 HdrHistogram？

**传统方法问题**:
- 存储所有样本 → 内存爆炸
- 排序计算百分位 → O(n log n) 时间复杂度
- 多 Worker 聚合 → 无法准确合并

**HdrHistogram 优势**:
1. **固定内存**: 不随样本数增长
2. **O(1) 记录**: 常数时间复杂度
3. **准确聚合**: 支持 histogram 合并，保持精度
4. **微秒精度**: 支持 1µs 到 1 小时范围
5. **高精度**: 3 位有效数字

**使用场景**:
```python
# 1. 生产者记录发送延迟
latency_recorder.record_latency(latency_ms)

# 2. 获取统计
snapshot = latency_recorder.get_snapshot()
print(f"p99: {snapshot.p99_ms} ms")

# 3. 导出用于聚合
histogram_data = latency_recorder.export_histogram()

# 4. 多 Worker 合并
merged_histogram = merge_histograms([hist1, hist2, hist3])
```

### 10.3 为什么使用回调式延迟测量？

**对比方法**:

| 方法 | 延迟定义 | 精度 | 问题 |
|------|----------|------|------|
| **同步等待** | send() 返回时间 | 高 | 阻塞，性能低 |
| **批次平均** | 批次总时间/消息数 | 低 | 不准确 |
| **回调测量** | 发送→确认时间 | 最高 | 复杂度高 |

**回调式优势**:
1. **精确**: 测量实际发送到 broker 确认的时间
2. **非阻塞**: 不影响发送性能
3. **单消息粒度**: 每条消息独立测量

**实现细节**:
```python
# 1. 发送时记录时间
send_time = time.time()
message_send_times[message_id] = send_time

# 2. 非阻塞发送
producer.produce(topic, value, callback=delivery_callback)

# 3. 回调中计算延迟
def delivery_callback(err, msg):
    ack_time = time.time()
    message_id = extract_message_id(msg)
    send_time = message_send_times[message_id]
    latency_ms = (ack_time - send_time) * 1000
    latency_recorder.record_latency(latency_ms)

# 4. 确保所有回调完成
await producer.wait_for_delivery()
```

### 10.4 为什么 Consumer 先启动，等待 5 秒？

**问题**: 如果 Producer 和 Consumer 同时启动，会发生什么？

```
时间轴:
0s:  Producer 开始发送消息
0s:  Consumer 开始订阅
1s:  Producer 已发送 10000 条消息
2s:  Consumer 订阅完成（分区分配）
     → Consumer 错过前 2 秒的消息！
```

**解决方案**: Consumer 优先启动 + 等待

```python
# 1. 先启动所有 Consumer
for worker in workers:
    await start_consumer_tasks(worker)

# 2. 等待 5 秒（让 Consumer 订阅完成）
await asyncio.sleep(5)

# 3. 再启动所有 Producer
for worker in workers:
    await start_producer_tasks(worker)
```

**为什么是 5 秒？**
- **分区分配**: 需要时间进行 consumer group rebalance
- **网络延迟**: Worker 远程部署时需要更多时间
- **安全裕度**: 宁可多等，不能丢消息

**更好的方案**（未实现）:
- 实现 Consumer 就绪状态轮询
- Worker 报告订阅完成
- Coordinator 等待所有 Consumer 就绪再启动 Producer

### 10.5 为什么使用轮询任务分配？

**对比策略**:

| 策略 | 负载均衡 | 容错性 | 复杂度 |
|------|----------|--------|--------|
| **全部分配** | 差 | 好 | 低 |
| **随机分配** | 中 | 中 | 低 |
| **轮询分配** | 好 | 中 | 低 |
| **智能分配** | 最好 | 好 | 高 |

**轮询分配优势**:
1. **负载均衡**: 任务均匀分配
2. **简单**: 实现简单，易于调试
3. **可预测**: 分配结果确定

**示例**:
```python
tasks = [T1, T2, T3, T4, T5, T6, T7]
workers = [W1, W2, W3]

# 轮询分配
W1: [T1, T4, T7]
W2: [T2, T5]
W3: [T3, T6]
```

### 10.6 已知问题和限制

#### 问题 1: `auto.offset.reset=latest`

**问题**: 消费者从最新偏移量开始，错过测试开始前的消息

**影响**: 消费消息数 < 生产消息数

**解决方案**: 修改为 `auto.offset.reset=earliest`

```yaml
# configs/kafka-digital-twin.yaml
consumerConfig: |
  auto.offset.reset=earliest  # 修改这里
  enable.auto.commit=false
```

#### 问题 2: 吞吐量聚合使用最大 duration

**问题**: 使用 `max(duration)` 而非实际并发时间窗口

**影响**: 如果 Worker 完成时间不一致，吞吐量计算不准确

**示例**:
```
Worker 1: 10000 msg, 100s
Worker 2: 10000 msg, 120s  (最慢)

当前计算: (10000 + 10000) / 120 = 166.7 msg/s
正确计算: (10000 + 10000) / 110 = 181.8 msg/s  (假设平均 110s)
```

**解决方案**: 使用所有 Worker 的实际并发时间窗口

```python
def _aggregate_throughput_stats(self, stats_list):
    # 找到最早开始时间和最晚结束时间
    min_start = min(s.start_time for s in worker_results)
    max_end = max(s.end_time for s in worker_results)
    actual_duration = max_end - min_start

    # 使用实际并发时间计算吞吐量
    total_messages = sum(s.total_messages for s in stats_list)
    throughput = total_messages / actual_duration
```

#### 问题 3: 延迟聚合回退方法精度低

**问题**: 如果 HdrHistogram 合并失败，回退到加权平均

**影响**: 多 Worker 聚合的延迟百分位不够准确

**解决方案**: 确保所有 Worker 使用 HdrHistogram

```python
# 检查 HdrHistogram 是否可用
from hdrh.histogram import HdrHistogram
print("HdrHistogram available:", HdrHistogram is not None)
```

#### 问题 4: 5 秒等待是硬编码

**问题**: 不同部署环境可能需要不同等待时间

**解决方案**:
- 配置化等待时间
- 或实现 Consumer 就绪状态确认机制

```python
# 配置化
class BenchmarkConfig(BaseModel):
    consumer_ready_wait_seconds: int = 5

# 就绪确认机制
async def wait_for_consumers_ready(self):
    for worker in workers:
        while not await worker.check_consumer_ready():
            await asyncio.sleep(1)
```

---

## 总结

**py-openmessaging-benchmark** 是一个架构清晰、功能完整的分布式消息系统基准测试框架。它的核心优势包括:

1. **分布式架构**: Coordinator-Worker 模式，支持水平扩展
2. **高精度测量**: HdrHistogram + 回调式延迟测量
3. **灵活配置**: Pydantic 验证 + YAML 配置
4. **生产级实现**: confluent-kafka + 数字孪生优化
5. **全面监控**: CPU、内存、网络、磁盘实时监控
6. **易于扩展**: 驱动抽象层，可支持其他消息系统

该框架特别适合:
- **Python Kafka 客户端性能测试**
- **数字孪生/IoT 场景基准测试**
- **消息系统对比评估**
- **容量规划和性能调优**

通过本文档，您应该能够:
1. 理解项目的整体架构和设计理念
2. 掌握各个组件的功能和实现细节
3. 了解关键工作流程和时序
4. 能够配置、部署和运行基准测试
5. 能够扩展框架支持新的驱动或功能
