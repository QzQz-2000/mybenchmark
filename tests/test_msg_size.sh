#!/bin/bash

# ========== åŸºæœ¬å‚æ•° ==========
BASE_NAME="Message Size Test"
TOPICS=1
PARTITIONS_PER_TOPIC=16
PRODUCERS_PER_TOPIC=4
PRODUCER_RATE=30000
SUBSCRIPTIONS_PER_TOPIC=1
CONSUMER_PER_SUBSCRIPTION=4
TEST_DURATION_MINUTES=1
WARMUP_DURATION_MINUTES=0
CONSUMER_BACKLOG_SIZE_GB=0

# ========== æµ‹è¯•å‚æ•° ==========
ITERATIONS=1        # æ¯ä¸ªæ¶ˆæ¯å¤§å°è¿è¡Œ10æ¬¡
RESULTS_BASE_DIR="results_$(date +%Y%m%d_%H%M%S)"  # ç»“æœæ ¹ç›®å½•

# ========== Kafka Docker å®¹å™¨åç§° ==========
KAFKA_CONTAINER_NAME="kafka"  # è¯·æ ¹æ®å®é™…å®¹å™¨åç§°ä¿®æ”¹

# ========== èµ·å§‹ä¸æœ€å¤§å¤§å°ï¼ˆå­—èŠ‚ï¼‰==========
SIZE=8              # èµ·å§‹å¤§å° 8B
MAX_SIZE=$((128 * 1024))
# MAX_SIZE=$((128 * 1024 * 1024))  # 128MB

# ========== é¡¹ç›®æ ¹ç›®å½• ==========
# è„šæœ¬åœ¨ tests ç›®å½•ä¸­ï¼Œé¡¹ç›®æ ¹ç›®å½•åœ¨ä¸Šä¸€çº§
PROJECT_ROOT="$(cd "$(dirname "$0")/.." && pwd)"
WORKLOADS_DIR="${PROJECT_ROOT}/workloads/msg-size-tests"
DRIVER_CONFIG="${PROJECT_ROOT}/examples/kafka-driver-max-throughput.yaml"

# ========== æ£€æŸ¥ Kafka é…ç½®æç¤º ==========
echo "=============================="
echo " Kafka Configuration Check"
echo "=============================="
echo "âš ï¸  é‡è¦æç¤ºï¼šæµ‹è¯•æœ€å¤§æ¶ˆæ¯å¤§å°ä¸º 128MB"
echo "è¯·ç¡®ä¿ Kafka é…ç½®æ”¯æŒå¤§æ¶ˆæ¯ä¼ è¾“ï¼Œéœ€è¦è®¾ç½®ï¼š"
echo "  - message.max.bytes >= 134217728 (128MB)"
echo "  - replica.fetch.max.bytes >= 134217728"
echo "  - max.request.size >= 134217728 (producer)"
echo "  - fetch.max.bytes >= 134217728 (consumer)"
echo ""
read -p "æ˜¯å¦å·²ç»é…ç½®å®Œæˆï¼Ÿ(y/n): " confirm
if [[ $confirm != [yY] ]]; then
    echo "è¯·å…ˆé…ç½® Kafka åå†è¿è¡Œæµ‹è¯•"
    exit 1
fi

# ========== åˆ›å»º workloads ç›®å½•å’Œç»“æœæ ¹ç›®å½• ==========
mkdir -p "$WORKLOADS_DIR"
mkdir -p "$RESULTS_BASE_DIR"
echo "âœ… åˆ›å»ºç»“æœç›®å½•: $RESULTS_BASE_DIR"
echo "âœ… å·¥ä½œè´Ÿè½½ç›®å½•: $WORKLOADS_DIR"
echo ""

# ========== æ£€æŸ¥ Kafka å®¹å™¨ ==========
echo "=============================="
echo " Checking Kafka Container"
echo "=============================="
if ! docker ps --format '{{.Names}}' | grep -q "^${KAFKA_CONTAINER_NAME}$"; then
    echo "âš ï¸  è­¦å‘Šï¼šæœªæ‰¾åˆ°åä¸º '${KAFKA_CONTAINER_NAME}' çš„è¿è¡Œä¸­ Kafka å®¹å™¨"
    echo "å¯ç”¨çš„å®¹å™¨ï¼š"
    docker ps --format 'table {{.Names}}\t{{.Image}}'
    echo ""
    read -p "è¯·è¾“å…¥æ­£ç¡®çš„ Kafka å®¹å™¨åç§°ï¼ˆç•™ç©ºè·³è¿‡ç›‘æ§ï¼‰: " input_name
    if [ -n "$input_name" ]; then
        KAFKA_CONTAINER_NAME="$input_name"
    else
        echo "âš ï¸  å°†è·³è¿‡ Kafka èµ„æºç›‘æ§"
        KAFKA_CONTAINER_NAME=""
    fi
else
    echo "âœ… æ‰¾åˆ° Kafka å®¹å™¨: ${KAFKA_CONTAINER_NAME}"
fi
echo ""

# ========== èµ„æºç›‘æ§å‡½æ•° ==========
# å¯åŠ¨èµ„æºç›‘æ§
start_monitoring() {
    local log_file=$1
    local container_name=$2

    if [ -z "$container_name" ]; then
        return
    fi

    # ç›´æ¥åœ¨åå°å¯åŠ¨ç›‘æ§ï¼Œä½¿ç”¨ nohup ç¡®ä¿å®Œå…¨ç‹¬ç«‹
    nohup bash -c "
        echo 'Timestamp,CPU%,Memory%' > '$log_file'
        while true; do
            stats=\$(docker stats '$container_name' --no-stream --format '{{.CPUPerc}},{{.MemPerc}}' 2>/dev/null)
            if [ \$? -eq 0 ]; then
                timestamp=\$(date +%s)
                echo \"\$timestamp,\$stats\" >> '$log_file'
            fi
            sleep 5
        done
    " > /dev/null 2>&1 &

    local pid=$!

    echo $pid  # è¿”å›ç›‘æ§è¿›ç¨‹çš„PID
}

# åœæ­¢èµ„æºç›‘æ§
stop_monitoring() {
    local monitor_pid=$1
    if [ -n "$monitor_pid" ] && kill -0 "$monitor_pid" 2>/dev/null; then
        kill "$monitor_pid" 2>/dev/null
        wait "$monitor_pid" 2>/dev/null
    fi
}

# ========== ä¸»æµ‹è¯•å¾ªç¯ ==========
while [ $SIZE -le $MAX_SIZE ]
do
    # ä¸ºå½“å‰æ¶ˆæ¯å¤§å°åˆ›å»ºç»“æœç›®å½•
    SIZE_DIR="${RESULTS_BASE_DIR}/size_${SIZE}B"
    mkdir -p "$SIZE_DIR"

    echo "=============================="
    echo " Testing Message Size: ${SIZE}B"
    echo "=============================="
    echo "ç»“æœç›®å½•: $SIZE_DIR"
    echo ""

    # è¿è¡Œ10æ¬¡è¿­ä»£
    for iteration in $(seq 1 $ITERATIONS)
    do
        NAME="${BASE_NAME} - ${SIZE}B - Run ${iteration}"

        echo "------------------------------"
        echo " Run ${iteration}/${ITERATIONS}"
        echo "------------------------------"

        # åˆ›å»ºæœ¬æ¬¡æµ‹è¯•çš„é…ç½®æ–‡ä»¶ï¼ˆæ”¾åœ¨ workloads ç›®å½•ä¸­ï¼‰
        CONFIG_FILE_NAME="msg_size_${SIZE}B_run${iteration}.yaml"
        CONFIG_FILE="${WORKLOADS_DIR}/${CONFIG_FILE_NAME}"

        cat > $CONFIG_FILE <<EOF
name: ${NAME}

topics: ${TOPICS}
partitionsPerTopic: ${PARTITIONS_PER_TOPIC}
messageSize: ${SIZE}

producersPerTopic: ${PRODUCERS_PER_TOPIC}
producerRate: ${PRODUCER_RATE}
subscriptionsPerTopic: ${SUBSCRIPTIONS_PER_TOPIC}
consumerPerSubscription: ${CONSUMER_PER_SUBSCRIPTION}

testDurationMinutes: ${TEST_DURATION_MINUTES}
warmupDurationMinutes: ${WARMUP_DURATION_MINUTES}

consumerBacklogSizeGB: ${CONSUMER_BACKLOG_SIZE_GB}
EOF

        echo "âœ… ç”Ÿæˆé…ç½®æ–‡ä»¶: ${CONFIG_FILE_NAME}"

        # å‡†å¤‡è¾“å‡ºæ–‡ä»¶
        # JSON ç»“æœä¿å­˜åœ¨æ¯ä¸ª size çš„å­ç›®å½•ä¸­ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„ï¼‰
        OUTPUT_FILE_NAME="result_run${iteration}.json"
        OUTPUT_FILE_RELATIVE="tests/${SIZE_DIR}/${OUTPUT_FILE_NAME}"
        MONITOR_LOG="$(pwd)/${SIZE_DIR}/monitor_run${iteration}.csv"
        LOG_FILE="$(pwd)/${SIZE_DIR}/log_run${iteration}.txt"

        # å¯åŠ¨èµ„æºç›‘æ§
        MONITOR_PID=""
        if [ -n "$KAFKA_CONTAINER_NAME" ]; then
            MONITOR_PID=$(start_monitoring "$MONITOR_LOG" "$KAFKA_CONTAINER_NAME")
            echo "âœ… å¯åŠ¨èµ„æºç›‘æ§ (PID: $MONITOR_PID)"
        fi

        # ========== è¿è¡Œ OpenMessaging Benchmark ==========
        echo "ğŸš€ å¼€å§‹æµ‹è¯•..."
        echo "Driver: $DRIVER_CONFIG"
        echo "Workload: $CONFIG_FILE"
        echo "Output: $OUTPUT_FILE_RELATIVE"
        echo ""

        # åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ benchmarkï¼ŒæŒ‡å®šè¾“å‡ºæ–‡ä»¶ä½ç½®ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
        (cd "$PROJECT_ROOT" && python -m benchmark -d "$DRIVER_CONFIG" -o "$OUTPUT_FILE_RELATIVE" "$CONFIG_FILE") 2>&1 | tee "$LOG_FILE"
        BENCHMARK_EXIT_CODE=$?

        # åœæ­¢èµ„æºç›‘æ§
        if [ -n "$MONITOR_PID" ]; then
            stop_monitoring "$MONITOR_PID"
            echo "âœ… åœæ­¢èµ„æºç›‘æ§"
        fi

        if [ $BENCHMARK_EXIT_CODE -eq 0 ]; then
            echo "âœ… Run ${iteration} å®Œæˆ"
        else
            echo "âŒ Run ${iteration} å¤±è´¥ (é€€å‡ºç : $BENCHMARK_EXIT_CODE)"
            echo "æŸ¥çœ‹æ—¥å¿—: $LOG_FILE"
        fi
        echo ""

        # åœ¨è¿­ä»£ä¹‹é—´çŸ­æš‚ä¼‘æ¯ï¼Œè®©ç³»ç»Ÿæ¢å¤
        if [ $iteration -lt $ITERATIONS ]; then
            echo "â¸  ä¼‘æ¯ 10 ç§’..."
            sleep 10
        fi
    done

    echo "âœ… æ¶ˆæ¯å¤§å° ${SIZE}B çš„æ‰€æœ‰æµ‹è¯•å®Œæˆ"
    echo ""

    # ========== ä¸‹ä¸€è½®ï¼ˆä¹˜ 4ï¼‰==========
    SIZE=$((SIZE * 4))
done

echo "=============================="
echo "âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼"
echo "=============================="
echo "ç»“æœä¿å­˜åœ¨: $RESULTS_BASE_DIR"
echo ""

# ========== ç”Ÿæˆæ±‡æ€»åˆ†æè„šæœ¬ï¼ˆæ–°ç‰ˆï¼‰ ==========
ANALYSIS_SCRIPT="${RESULTS_BASE_DIR}/analyze_results.py"
cat > "$ANALYSIS_SCRIPT" <<'ANALYSIS_EOF'
#!/usr/bin/env python3
#!/usr/bin/env python3
"""
ç»“æœåˆ†æè„šæœ¬ï¼ˆæ–°ç‰ˆï¼‰
ç»Ÿè®¡æ¯ä¸ªæ¶ˆæ¯å¤§å°çš„ End-to-End å»¶è¿Ÿå„åˆ†ä½ã€Producer/Consumer é€Ÿç‡ã€Producer/Consumer ååé‡ï¼Œä»¥åŠ CPU/Memory å¹³å‡å€¼
"""

import json
import csv
from pathlib import Path
import statistics

def analyze_results(base_dir):
    results = {}

    for size_dir in sorted(Path(base_dir).glob("size_*")):
        size_name = size_dir.name
        message_size = size_name.replace("size_", "").replace("B", "")

        latencies = {'50': [], '75': [], '95': [], '99': []}
        producer_rates = []
        consumer_rates = []
        producer_throughput = []
        consumer_throughput = []
        cpu_usages = []
        mem_usages = []

        # éå† JSON æ–‡ä»¶
        for result_file in sorted(size_dir.glob("result_run*.json")):
            with open(result_file, 'r') as f:
                data = json.load(f)
                for p in latencies.keys():
                    key = f'aggregatedEndToEndLatency{p}pct'
                    if key in data:
                        latencies[p].append(data[key])
                if 'aggregatedPublishRateAvg' in data:
                    producer_rates.append(data['aggregatedPublishRateAvg'])
                if 'aggregatedConsumeRateAvg' in data:
                    consumer_rates.append(data['aggregatedConsumeRateAvg'])
                if 'aggregatedPublishThroughputAvg' in data:
                    producer_throughput.append(data['aggregatedPublishThroughputAvg'])
                if 'aggregatedConsumeThroughputAvg' in data:
                    consumer_throughput.append(data['aggregatedConsumeThroughputAvg'])

        # éå† CSV æ–‡ä»¶è·å– CPU/Memory
        for monitor_file in sorted(size_dir.glob("monitor_run*.csv")):
            with open(monitor_file, 'r') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    cpu_usages.append(float(row['CPU%'].replace('%','')))
                    mem_usages.append(float(row['Memory%'].replace('%','')))

        # ç»Ÿè®¡å¹³å‡å€¼å’Œæ ‡å‡†å·®
        results[message_size] = {}
        for p in latencies.keys():
            vals = latencies[p]
            results[message_size][f'latency_{p}_avg'] = statistics.mean(vals) if vals else None
            results[message_size][f'latency_{p}_std'] = statistics.stdev(vals) if len(vals) > 1 else 0

        results[message_size]['producer_rate_avg'] = statistics.mean(producer_rates) if producer_rates else None
        results[message_size]['producer_rate_std'] = statistics.stdev(producer_rates) if len(producer_rates) > 1 else 0
        results[message_size]['consumer_rate_avg'] = statistics.mean(consumer_rates) if consumer_rates else None
        results[message_size]['consumer_rate_std'] = statistics.stdev(consumer_rates) if len(consumer_rates) > 1 else 0

        results[message_size]['producer_throughput_avg'] = statistics.mean(producer_throughput) if producer_throughput else None
        results[message_size]['producer_throughput_std'] = statistics.stdev(producer_throughput) if len(producer_throughput) > 1 else 0
        results[message_size]['consumer_throughput_avg'] = statistics.mean(consumer_throughput) if consumer_throughput else None
        results[message_size]['consumer_throughput_std'] = statistics.stdev(consumer_throughput) if len(consumer_throughput) > 1 else 0

        # CPU å’Œå†…å­˜åªå–å¹³å‡å€¼
        results[message_size]['cpu_avg'] = statistics.mean(cpu_usages) if cpu_usages else None
        results[message_size]['mem_avg'] = statistics.mean(mem_usages) if mem_usages else None
        results[message_size]['iterations'] = len(producer_rates)

    return results

def print_summary(results):
    print("\n" + "="*140)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*140)
    header = f"{'æ¶ˆæ¯å¤§å°':<10} {'Latency50(ms)':<18} {'Latency75(ms)':<18} {'Latency95(ms)':<18} {'Latency99(ms)':<18} {'ProdRate':<12} {'ConsRate':<12} {'ProdThr(MB/s)':<15} {'ConsThr(MB/s)':<15} {'CPU%':<10} {'Memory%':<10}"
    print(header)
    print("-"*140)

    for size in sorted(results.keys(), key=lambda x: int(x)):
        data = results[size]
        row = f"{size+'B':<10} "
        for p in ['50','75','95','99']:
            avg = data[f'latency_{p}_avg']
            std = data[f'latency_{p}_std']
            row += f"{avg:.2f}Â±{std:.2f}" if avg is not None else "N/A"
            row += " " * (18 - len(f"{avg:.2f}Â±{std:.2f}"))
        row += f"{data['producer_rate_avg']:.1f}Â±{data['producer_rate_std']:.1f}".ljust(12)
        row += f"{data['consumer_rate_avg']:.1f}Â±{data['consumer_rate_std']:.1f}".ljust(12)
        row += f"{data['producer_throughput_avg']:.2f}Â±{data['producer_throughput_std']:.2f}".ljust(15)
        row += f"{data['consumer_throughput_avg']:.2f}Â±{data['consumer_throughput_std']:.2f}".ljust(15)
        row += f"{data['cpu_avg']:.1f}".ljust(10)
        row += f"{data['mem_avg']:.1f}".ljust(10)
        print(row)
    print("="*140)

def save_to_csv(results, output_file):
    with open(output_file, 'w', newline='') as f:
        writer = csv.writer(f)
        header = ['MessageSize(B)',
                  'Latency50_Avg(ms)','Latency50_Std(ms)',
                  'Latency75_Avg(ms)','Latency75_Std(ms)',
                  'Latency95_Avg(ms)','Latency95_Std(ms)',
                  'Latency99_Avg(ms)','Latency99_Std(ms)',
                  'ProducerRate_Avg','ProducerRate_Std',
                  'ConsumerRate_Avg','ConsumerRate_Std',
                  'ProducerThroughput_Avg(MB/s)','ProducerThroughput_Std(MB/s)',
                  'ConsumerThroughput_Avg(MB/s)','ConsumerThroughput_Std(MB/s)',
                  'CPU_Avg','Memory_Avg','Iterations']
        writer.writerow(header)

        for size in sorted(results.keys(), key=lambda x: int(x)):
            data = results[size]
            writer.writerow([
                size,
                data['latency_50_avg'], data['latency_50_std'],
                data['latency_75_avg'], data['latency_75_std'],
                data['latency_95_avg'], data['latency_95_std'],
                data['latency_99_avg'], data['latency_99_std'],
                data['producer_rate_avg'], data['producer_rate_std'],
                data['consumer_rate_avg'], data['consumer_rate_std'],
                data['producer_throughput_avg'], data['producer_throughput_std'],
                data['consumer_throughput_avg'], data['consumer_throughput_std'],
                data['cpu_avg'], data['mem_avg'],
                data['iterations']
            ])
    print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

if __name__ == '__main__':
    base_dir = Path(__file__).parent
    results = analyze_results(base_dir)
    if results:
        print_summary(results)
        save_to_csv(results, base_dir / 'summary.csv')
    else:
        print("æœªæ‰¾åˆ°æµ‹è¯•ç»“æœ")

ANALYSIS_EOF

chmod +x "$ANALYSIS_SCRIPT"
echo "=============================="
echo "ğŸ“Š åˆ†æè„šæœ¬å·²ç”Ÿæˆï¼ˆæ–°ç‰ˆ End-to-End å»¶è¿Ÿ & Producer/Consumer rateï¼‰"
echo "=============================="
echo "è¿è¡Œä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹ç»“æœæ±‡æ€»ï¼š"
echo "  python3 ${ANALYSIS_SCRIPT}"
echo ""
echo "æˆ–ç›´æ¥æ‰§è¡Œï¼š"
echo "  ${ANALYSIS_SCRIPT}"
echo ""