#!/usr/bin/env python3
"""
æµ‹è¯•å¤šè¿›ç¨‹ Worker å®ç°

æ¯ä¸ª producer/consumer è¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ï¼ŒçœŸå®æ¨¡æ‹Ÿå¤š agent è´Ÿè½½ã€‚
"""

import asyncio
import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from benchmark.core.coordinator import BenchmarkCoordinator
from benchmark.core.config import ConfigLoader, BenchmarkConfig


async def test_multiprocess_producers(num_producers: int):
    """æµ‹è¯•æŒ‡å®šæ•°é‡çš„ producer"""

    print(f"\n{'='*80}")
    print(f"æµ‹è¯•åœºæ™¯ï¼š{num_producers} ä¸ª Producerï¼ˆæ¯ä¸ªç‹¬ç«‹è¿›ç¨‹ï¼‰")
    print(f"{'='*80}\n")

    # åŠ è½½é…ç½®
    workload_config = ConfigLoader.load_workload(
        f"workloads/test-{num_producers}-producers.yaml"
    )
    driver_config = ConfigLoader.load_driver("configs/kafka-digital-twin.yaml")

    # åˆ›å»º Coordinator
    benchmark_config = BenchmarkConfig(
        workers=["http://localhost:8001"],
        results_dir="./results",
        enable_monitoring=True,
        warmup_enabled=False,  # ä¸ºäº†å¿«é€Ÿæµ‹è¯•
        cleanup_enabled=True
    )

    coordinator = BenchmarkCoordinator(benchmark_config)

    # è¿è¡Œæµ‹è¯•
    async with coordinator:
        result = await coordinator.run_benchmark(
            workload_config,
            driver_config,
            payload_data=None
        )

    # æ‰“å°ç»“æœ
    print(f"\n{'='*80}")
    print(f"æµ‹è¯•ç»“æœï¼š{num_producers} ä¸ª Producer")
    print(f"{'='*80}")
    print(f"Producer ååé‡: {result.producer_stats.messages_per_second:.2f} msg/s")
    print(f"Producer æ€»æ¶ˆæ¯: {result.producer_stats.total_messages}")
    print(f"Consumer ååé‡: {result.consumer_stats.messages_per_second:.2f} msg/s")
    print(f"Consumer æ€»æ¶ˆæ¯: {result.consumer_stats.total_messages}")
    print(f"å»¶è¿Ÿ p50: {result.latency_stats.p50_ms:.2f} ms")
    print(f"å»¶è¿Ÿ p95: {result.latency_stats.p95_ms:.2f} ms")
    print(f"å»¶è¿Ÿ p99: {result.latency_stats.p99_ms:.2f} ms")
    print(f"CPU å¹³å‡: {result.system_stats.cpu['avg']:.1f}%")
    print(f"CPU æœ€å¤§: {result.system_stats.cpu['max']:.1f}%")
    print(f"å†…å­˜å¹³å‡: {result.system_stats.memory['avg']:.1f}%")
    print(f"{'='*80}\n")

    return result


async def run_scaling_test():
    """è¿è¡Œæ‰©å±•æ€§æµ‹è¯•"""

    print("\n" + "="*80)
    print("Multi-Process Worker æ‰©å±•æ€§æµ‹è¯•")
    print("æ¯ä¸ª producer è¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ï¼Œæµ‹è¯•æ‰©å±•æ€§")
    print("="*80)

    results = {}

    # æµ‹è¯•ä¸åŒæ•°é‡çš„ producer
    for num_producers in [1, 5, 10]:
        try:
            result = await test_multiprocess_producers(num_producers)
            results[num_producers] = result
        except Exception as e:
            print(f"âŒ æµ‹è¯• {num_producers} ä¸ª producer å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    # å¯¹æ¯”åˆ†æ
    print("\n" + "="*80)
    print("æ‰©å±•æ€§åˆ†æå¯¹æ¯”")
    print("="*80)
    print(f"{'Producers':<12} {'ååé‡(msg/s)':<20} {'å»¶è¿Ÿp99(ms)':<15} {'CPUå¹³å‡(%)':<15}")
    print("-"*80)

    for num_producers in [1, 5, 10]:
        if num_producers in results:
            r = results[num_producers]
            print(
                f"{num_producers:<12} "
                f"{r.producer_stats.messages_per_second:<20.2f} "
                f"{r.latency_stats.p99_ms:<15.2f} "
                f"{r.system_stats.cpu['avg']:<15.1f}"
            )

    print("="*80)

    # è®¡ç®—æ‰©å±•æ•ˆç‡
    if 1 in results and 10 in results:
        baseline = results[1].producer_stats.messages_per_second
        scaled = results[10].producer_stats.messages_per_second
        efficiency = (scaled / baseline / 10) * 100

        print(f"\næ‰©å±•æ•ˆç‡:")
        print(f"  1 producer: {baseline:.2f} msg/s")
        print(f"  10 producers: {scaled:.2f} msg/s")
        print(f"  ç†æƒ³å€¼: {baseline * 10:.2f} msg/s (10x)")
        print(f"  å®é™…æ‰©å±•: {scaled / baseline:.2f}x")
        print(f"  æ‰©å±•æ•ˆç‡: {efficiency:.1f}%")

        if efficiency > 90:
            print("  âœ… æ‰©å±•æ€§ä¼˜ç§€ï¼æ¥è¿‘çº¿æ€§æ‰©å±•")
        elif efficiency > 70:
            print("  ğŸ‘ æ‰©å±•æ€§è‰¯å¥½")
        else:
            print("  âš ï¸ æ‰©å±•æ€§ä¸€èˆ¬ï¼Œå¯èƒ½å­˜åœ¨ç“¶é¢ˆ")


if __name__ == "__main__":
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                Multi-Process Worker æµ‹è¯•å·¥å…·                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ä½¿ç”¨å‰å‡†å¤‡:
1. å¯åŠ¨ Kafka:
   docker-compose up -d kafka zookeeper

2. å¯åŠ¨ Multi-Process Worker:
   python workers/kafka_worker_multiprocess.py \\
       --worker-id worker-1 \\
       --port 8001 \\
       --driver-config configs/kafka-digital-twin.yaml

3. åˆ›å»ºæµ‹è¯•å·¥ä½œè´Ÿè½½é…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰

ç°åœ¨å¼€å§‹æµ‹è¯•...
    """)

    try:
        asyncio.run(run_scaling_test())
    except KeyboardInterrupt:
        print("\n\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
