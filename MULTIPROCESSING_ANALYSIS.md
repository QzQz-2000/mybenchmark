# Python å¤šè¿›ç¨‹å®ç°åˆ†æ - Agent æ¨¡æ‹Ÿ

## ğŸ¯ ä½ çš„è®¾è®¡æ„å›¾

> **ç›®æ ‡**: ä½¿ç”¨å¤šè¿›ç¨‹æ¨¡æ‹Ÿå¤šä¸ª agent åŒæ—¶è¿è¡Œ

è¿™æ˜¯ä¸€ä¸ª**å®Œå…¨åˆç†**çš„è®¾è®¡ï¼è®©æˆ‘åˆ†æå½“å‰å®ç°çš„é—®é¢˜å’Œæ”¹è¿›æ–¹å‘ã€‚

---

## ğŸ“Š å½“å‰å®ç°çŠ¶æ€

### Java ç‰ˆæœ¬ - å¤šçº¿ç¨‹æ¨¡æ‹Ÿ

```java
public class LocalWorker {
    private final ExecutorService executor =
        Executors.newCachedThreadPool();  // âœ“ çº¿ç¨‹æ± 

    @Override
    public void startLoad(ProducerWorkAssignment assignment) {
        int processors = Runtime.getRuntime().availableProcessors();  // âœ“ CPU æ ¸æ•°

        // âœ“ å°† producers åˆ†é…åˆ°ä¸åŒçš„ "processor"
        Map<Integer, List<BenchmarkProducer>> processorAssignment = new TreeMap<>();
        int processorIdx = 0;
        for (BenchmarkProducer p : producers) {
            processorAssignment
                .computeIfAbsent(processorIdx, x -> new ArrayList<>())
                .add(p);
            processorIdx = (processorIdx + 1) % processors;  // è½®è¯¢åˆ†é…
        }

        // âœ“ æ¯ä¸ª "processor" ä¸€ä¸ªçº¿ç¨‹ï¼Œå†…éƒ¨å¤„ç†å¤šä¸ª producers
        processorAssignment.values().forEach(producers ->
            submitProducersToExecutor(producers, keyDistributor, payloads)
        );
    }

    private void submitProducersToExecutor(
            List<BenchmarkProducer> producers, ...) {
        executor.submit(() -> {  // âœ“ æäº¤ä¸€ä¸ªä»»åŠ¡åˆ°çº¿ç¨‹æ± 
            while (!testCompleted) {
                producers.forEach(p ->  // âœ“ å¾ªç¯æ‰€æœ‰ producer
                    messageProducer.sendMessage(p, key, payload)
                );
            }
        });
    }
}
```

**Java ç‰ˆæœ¬çš„è®¾è®¡**:
1. âœ… æ ¹æ® CPU æ ¸æ•°åˆ†é… producer
2. âœ… æ¯ä¸ªæ ¸ä¸€ä¸ªçº¿ç¨‹ = **æ¨¡æ‹Ÿå¤šä¸ª agent**
3. âœ… æ¯ä¸ªçº¿ç¨‹å†…å¾ªç¯å¤„ç†å¤šä¸ª producer
4. âœ… ä½¿ç”¨ `CachedThreadPool` ç®¡ç†çº¿ç¨‹

---

### Python ç‰ˆæœ¬ - å½“å‰å®ç°ï¼ˆæœ‰é—®é¢˜ï¼‰

```python
class LocalWorker:
    def start_load(self, producer_work_assignment):
        # âŒ é—®é¢˜ï¼šæ¯ä¸ª producer ä¸€ä¸ªçº¿ç¨‹ï¼Œè€Œä¸æ˜¯æ¯ä¸ª CPU æ ¸ä¸€ä¸ª
        self.producer_threads = []
        for i, producer in enumerate(self.producers):
            thread = threading.Thread(
                target=self._producer_worker,
                args=(producer, i, per_producer_rate),
                daemon=True
            )
            thread.start()
            self.producer_threads.append(thread)

    def _producer_worker(self, producer, producer_index, publish_rate):
        """ä¸€ä¸ªçº¿ç¨‹å¤„ç†ä¸€ä¸ª producer"""  # âŒ é”™è¯¯è®¾è®¡
        rate_limiter = UniformRateLimiter(publish_rate)
        message_producer = MessageProducer(rate_limiter, self.stats)

        while not self.stop_producing.is_set():
            # åªå¤„ç†è¿™ä¸€ä¸ª producer
            message_producer.send_message(producer, key, payload)
```

**Python ç‰ˆæœ¬çš„é—®é¢˜**:
1. âŒ **æ²¡æœ‰æŒ‰ CPU æ ¸æ•°åˆ†é…**
2. âŒ æ¯ä¸ª producer ä¸€ä¸ªçº¿ç¨‹ï¼ˆå¦‚æœæœ‰ 100 ä¸ª producer = 100 ä¸ªçº¿ç¨‹ï¼‰
3. âŒ æ²¡æœ‰å®ç°"å¤š agent æ¨¡æ‹Ÿ"çš„æ¦‚å¿µ
4. âŒ æœªä½¿ç”¨ `_producer_worker_func`ï¼ˆè¿›ç¨‹ç‰ˆæœ¬ï¼‰

---

## ğŸ”§ æ­£ç¡®çš„å¤šè¿›ç¨‹å®ç°

### æ–¹æ¡ˆ A: å®Œå…¨å¯¹åº” Java ç‰ˆæœ¬ï¼ˆæ¨èï¼‰

```python
import multiprocessing
import random
from typing import List

class LocalWorker:
    def __init__(self):
        self.benchmark_driver = None
        self.producers = []
        self.consumers = []
        self.stats = WorkerStats()
        self.test_completed = multiprocessing.Event()
        self.producer_processes = []  # âœ“ è¿›ç¨‹åˆ—è¡¨

    def start_load(self, producer_work_assignment):
        """æ¨¡æ‹Ÿå¤šä¸ª agent (è¿›ç¨‹)"""
        cpu_count = multiprocessing.cpu_count()  # âœ“ è·å– CPU æ ¸æ•°

        logger.info(f"Starting load with {cpu_count} agent processes")

        # âœ“ å°† producers åˆ†é…åˆ°ä¸åŒçš„ "agent" (è¿›ç¨‹)
        processor_assignment = {}
        processor_idx = 0
        for i, producer in enumerate(self.producers):
            if processor_idx not in processor_assignment:
                processor_assignment[processor_idx] = []

            # ä¿å­˜ producer ä¿¡æ¯ï¼ˆtopic + propertiesï¼‰
            processor_assignment[processor_idx].append({
                'topic': producer.topic,
                'index': i
            })

            processor_idx = (processor_idx + 1) % cpu_count  # è½®è¯¢åˆ†é…

        # âœ“ ä¸ºæ¯ä¸ª CPU æ ¸å¯åŠ¨ä¸€ä¸ªè¿›ç¨‹ï¼ˆæ¨¡æ‹Ÿä¸€ä¸ª agentï¼‰
        producer_properties = self.benchmark_driver.producer_properties.copy()

        for proc_id, producer_infos in processor_assignment.items():
            process = multiprocessing.Process(
                target=_agent_worker_func,  # âœ“ å…¨å±€å‡½æ•°
                args=(
                    proc_id,                          # agent ID
                    producer_infos,                   # åˆ†é…çš„ producers
                    producer_properties,              # Kafka é…ç½®
                    producer_work_assignment,         # å·¥ä½œè´Ÿè½½
                    self.test_completed,              # åœæ­¢ä¿¡å·
                    self.stats                        # å…±äº«ç»Ÿè®¡ï¼ˆéœ€è¦æ”¹è¿›ï¼‰
                ),
                name=f"agent-{proc_id}",
                daemon=True
            )
            process.start()
            self.producer_processes.append(process)

        logger.info(f"Started {len(self.producer_processes)} agent processes")


def _agent_worker_func(agent_id, producer_infos, producer_properties,
                       work_assignment, stop_event, stats):
    """
    å…¨å±€å‡½æ•°ï¼šæ¨¡æ‹Ÿä¸€ä¸ª agent è¿›ç¨‹
    ä¸€ä¸ª agent å¤„ç†å¤šä¸ª producersï¼ˆå¯¹åº” Java çš„ä¸€ä¸ªçº¿ç¨‹ï¼‰
    """
    import random
    import logging
    from benchmark.utils.uniform_rate_limiter import UniformRateLimiter
    from benchmark.worker.message_producer import MessageProducer
    from benchmark.worker.worker_stats import WorkerStats
    from benchmark.driver_kafka.kafka_benchmark_producer import KafkaBenchmarkProducer

    logger = logging.getLogger(__name__)
    logger.info(f"Agent {agent_id} started with {len(producer_infos)} producers")

    # âœ“ åœ¨è¿›ç¨‹å†…åˆ›å»ºæ‰€æœ‰ producers
    producers = []
    for info in producer_infos:
        producer = KafkaBenchmarkProducer(
            info['topic'],
            producer_properties.copy()
        )
        producers.append({
            'producer': producer,
            'index': info['index']
        })

    # âœ“ åˆ›å»ºç‹¬ç«‹çš„ stats å’Œ rate limiter
    local_stats = WorkerStats()  # æ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹ç»Ÿè®¡ï¼ˆåç»­éœ€è¦æ±‡æ€»ï¼‰

    # è®¡ç®—æ­¤ agent çš„é€Ÿç‡ï¼ˆæ€»é€Ÿç‡ / agent æ•°é‡ï¼‰
    total_rate = work_assignment.publish_rate
    # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–äº†ï¼Œå®é™…åº”è¯¥æ ¹æ® producer æ•°é‡åŠ¨æ€è°ƒæ•´

    rate_limiter = UniformRateLimiter(total_rate / len(producer_infos))
    message_producer = MessageProducer(rate_limiter, local_stats)

    # è·å– payload
    payload = (work_assignment.payload_data[0]
               if work_assignment.payload_data
               else bytes(1024))

    try:
        # âœ“ ä¸»å¾ªç¯ï¼šåƒ Java ä¸€æ ·è½®è¯¢æ‰€æœ‰ producers
        while not stop_event.is_set():
            for producer_info in producers:
                producer = producer_info['producer']
                index = producer_info['index']

                # é€‰æ‹© key
                key = None
                if work_assignment.key_distributor_type:
                    if hasattr(work_assignment.key_distributor_type, 'name'):
                        if work_assignment.key_distributor_type.name == 'RANDOM':
                            key = str(random.randint(0, 1000000))
                        elif work_assignment.key_distributor_type.name == 'ROUND_ROBIN':
                            key = str(index)

                # âœ“ å‘é€æ¶ˆæ¯ï¼ˆå¸¦é€Ÿç‡é™åˆ¶ï¼‰
                try:
                    message_producer.send_message(producer, key, payload)
                except Exception as e:
                    logger.error(f"Agent {agent_id} send error: {e}")

    finally:
        # æ¸…ç†
        for producer_info in producers:
            try:
                producer_info['producer'].close()
            except:
                pass

        logger.info(f"Agent {agent_id} stopped")
```

**è¿™ä¸ªå®ç°çš„ä¼˜åŠ¿**:
1. âœ… **å®Œå…¨å¯¹åº” Java ç‰ˆæœ¬çš„è®¾è®¡**
2. âœ… æ ¹æ® CPU æ ¸æ•°åˆ›å»ºè¿›ç¨‹ï¼ˆçœŸæ­£çš„å¤š agent æ¨¡æ‹Ÿï¼‰
3. âœ… æ¯ä¸ª agent å¤„ç†å¤šä¸ª producersï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
4. âœ… çœŸæ­£çš„å¹¶è¡Œï¼ˆæ—  GIL é™åˆ¶ï¼‰
5. âœ… æ›´æ¥è¿‘çœŸå®çš„åˆ†å¸ƒå¼åœºæ™¯

---

### æ–¹æ¡ˆ B: æ··åˆæ¶æ„ï¼ˆè¿›ç¨‹ + çº¿ç¨‹ï¼‰

```python
def _agent_worker_func(agent_id, producer_infos, producer_properties,
                       work_assignment, stop_event):
    """
    æ¯ä¸ª agent è¿›ç¨‹å†…å†åˆ›å»ºå¤šä¸ªçº¿ç¨‹
    è¿›ä¸€æ­¥æå‡å¹¶å‘æ€§èƒ½
    """
    import threading
    from concurrent.futures import ThreadPoolExecutor

    logger.info(f"Agent {agent_id}: starting {len(producer_infos)} producer threads")

    # åœ¨è¿›ç¨‹å†…åˆ›å»º producers
    producers = [...]  # åŒä¸Š

    # âœ“ ä½¿ç”¨çº¿ç¨‹æ± ç®¡ç† producersï¼ˆè¿›ç¨‹å†…ï¼‰
    with ThreadPoolExecutor(max_workers=min(4, len(producers))) as executor:
        # å°† producers åˆ†ç»„
        producers_per_thread = len(producers) // 4 + 1

        for i in range(0, len(producers), producers_per_thread):
            thread_producers = producers[i:i + producers_per_thread]

            executor.submit(
                _producer_thread_func,
                agent_id,
                thread_producers,
                work_assignment,
                stop_event
            )

def _producer_thread_func(agent_id, producers, work_assignment, stop_event):
    """çº¿ç¨‹å‡½æ•°ï¼šå¤„ç†ä¸€ç»„ producers"""
    # ... å¾ªç¯å‘é€é€»è¾‘
```

**æ··åˆæ¶æ„çš„ä¼˜åŠ¿**:
- âœ… è¿›ç¨‹çº§å¹¶è¡Œï¼ˆè·¨ CPU æ ¸ï¼‰
- âœ… çº¿ç¨‹çº§å¹¶è¡Œï¼ˆå•æ ¸å†…ï¼‰
- âœ… æœ€å¤§åŒ–ååé‡

---

## ğŸ› å½“å‰å®ç°çš„é—®é¢˜

### é—®é¢˜ 1: æ²¡æœ‰å®ç°å¤š agent æ¨¡æ‹Ÿ

**Java**:
```java
// å‡è®¾ 8 æ ¸ CPUï¼Œ100 ä¸ª producers
// ç»“æœï¼š8 ä¸ªçº¿ç¨‹ï¼Œæ¯ä¸ªçº¿ç¨‹å¤„ç† 12-13 ä¸ª producers
```

**Python å½“å‰**:
```python
# 100 ä¸ª producers
# ç»“æœï¼š100 ä¸ªçº¿ç¨‹ï¼ˆâŒ é”™è¯¯ï¼ï¼‰
for producer in self.producers:  # 100 æ¬¡å¾ªç¯
    thread = threading.Thread(...)
```

**åº”è¯¥æ˜¯**:
```python
# 100 ä¸ª producersï¼Œ8 æ ¸ CPU
# ç»“æœï¼š8 ä¸ªè¿›ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹å¤„ç† 12-13 ä¸ª producers
cpu_count = 8
for proc_id in range(cpu_count):  # 8 ä¸ªè¿›ç¨‹
    producers_for_this_agent = ...  # åˆ†é… 12-13 ä¸ª
    process = multiprocessing.Process(...)
```

---

### é—®é¢˜ 2: ç»Ÿè®¡æ•°æ®æ— æ³•æ±‡æ€»

**å½“å‰é—®é¢˜**:
```python
def _agent_worker_func(..., stats):  # âŒ WorkerStats ä¸èƒ½è·¨è¿›ç¨‹å…±äº«
    # æ¯ä¸ªè¿›ç¨‹çš„ç»Ÿè®¡æ•°æ®ç‹¬ç«‹
    # ä¸»è¿›ç¨‹çœ‹ä¸åˆ°å­è¿›ç¨‹çš„æ•°æ®
```

**è§£å†³æ–¹æ¡ˆ A: ä½¿ç”¨ Queue æ±‡æ€»**:
```python
def _agent_worker_func(agent_id, ..., stats_queue):
    local_stats = WorkerStats()

    # å®šæœŸå‘é€ç»Ÿè®¡åˆ°ä¸»è¿›ç¨‹
    last_report = time.time()

    while not stop_event.is_set():
        # ... å‘é€æ¶ˆæ¯ ...

        # æ¯ç§’æ±‡æŠ¥ä¸€æ¬¡
        if time.time() - last_report > 1.0:
            counters = local_stats.to_counters_stats()
            stats_queue.put({
                'agent_id': agent_id,
                'messages_sent': counters.messages_sent,
                'messages_received': counters.messages_received,
                'errors': counters.message_send_errors
            })
            last_report = time.time()

# ä¸»è¿›ç¨‹æ”¶é›†ç»Ÿè®¡
def _stats_collector_thread(stats_queue, global_stats):
    while True:
        try:
            agent_stats = stats_queue.get(timeout=1.0)
            # æ±‡æ€»åˆ°å…¨å±€ç»Ÿè®¡
            global_stats.merge(agent_stats)
        except queue.Empty:
            continue
```

**è§£å†³æ–¹æ¡ˆ B: ä½¿ç”¨ Manager å…±äº«å¯¹è±¡**:
```python
from multiprocessing import Manager

class LocalWorker:
    def __init__(self):
        self.manager = Manager()
        self.shared_counters = self.manager.dict({
            'messages_sent': 0,
            'messages_received': 0,
            'errors': 0
        })
        self.counter_lock = self.manager.Lock()

def _agent_worker_func(agent_id, ..., shared_counters, counter_lock):
    while not stop_event.is_set():
        # å‘é€æ¶ˆæ¯
        success = send_message(...)

        # æ›´æ–°å…±äº«è®¡æ•°å™¨
        with counter_lock:
            if success:
                shared_counters['messages_sent'] += 1
            else:
                shared_counters['errors'] += 1
```

---

### é—®é¢˜ 3: Consumer å’Œ Producer æ¶æ„ä¸ä¸€è‡´

**å½“å‰çŠ¶æ€**:
- Consumer: âœ… ä½¿ç”¨ multiprocessing.Process
- Producer: âŒ ä½¿ç”¨ threading.Thread

**é—®é¢˜**:
- ä¸ç¬¦åˆ"å¤š agent æ¨¡æ‹Ÿ"çš„è®¾è®¡æ„å›¾
- Consumer æ˜¯è¿›ç¨‹ï¼ŒProducer æ˜¯çº¿ç¨‹ï¼Œæ¦‚å¿µæ··ä¹±

**ç»Ÿä¸€æ–¹æ¡ˆ**:
```python
class LocalWorker:
    def create_consumers(self, assignment):
        """ä¸ºæ¯ä¸ª CPU æ ¸åˆ›å»ºä¸€ä¸ª Consumer agent"""
        cpu_count = multiprocessing.cpu_count()

        # å°† consumers åˆ†é…åˆ°ä¸åŒçš„ agent
        for agent_id in range(min(cpu_count, len(consumers))):
            consumers_for_agent = ...

            process = multiprocessing.Process(
                target=_consumer_agent_func,
                args=(agent_id, consumers_for_agent, ...)
            )
            process.start()

    def start_load(self, assignment):
        """ä¸ºæ¯ä¸ª CPU æ ¸åˆ›å»ºä¸€ä¸ª Producer agent"""
        cpu_count = multiprocessing.cpu_count()

        for agent_id in range(cpu_count):
            producers_for_agent = ...

            process = multiprocessing.Process(
                target=_producer_agent_func,
                args=(agent_id, producers_for_agent, ...)
            )
            process.start()
```

---

## ğŸ“ å®ç°æµç¨‹å¯¹æ¯”

### Java ç‰ˆæœ¬æµç¨‹

```
1. è·å– CPU æ ¸æ•° (processors)
   â””â”€> Runtime.getRuntime().availableProcessors()

2. åˆ†é… Producers åˆ°å„ä¸ª "processor"
   â””â”€> TreeMap<Integer, List<Producer>>
   â””â”€> è½®è¯¢åˆ†é…ï¼ˆRound-Robinï¼‰

3. ä¸ºæ¯ä¸ª processor åˆ›å»ºä¸€ä¸ªçº¿ç¨‹
   â””â”€> executor.submit(...)
   â””â”€> çº¿ç¨‹å†…å¾ªç¯å¤„ç†å¤šä¸ª producers

4. çº¿ç¨‹å¾ªç¯
   â””â”€> while (!testCompleted)
       â””â”€> forEach(producer -> send)

5. ç»Ÿè®¡æ”¶é›†
   â””â”€> æ‰€æœ‰çº¿ç¨‹å…±äº« WorkerStats
   â””â”€> ä½¿ç”¨ synchronized/atomic ä¿è¯çº¿ç¨‹å®‰å…¨
```

### Python å½“å‰ç‰ˆæœ¬æµç¨‹ï¼ˆé”™è¯¯ï¼‰

```
1. âŒ æ²¡æœ‰è·å– CPU æ ¸æ•°

2. âŒ æ²¡æœ‰åˆ†é…é€»è¾‘
   â””â”€> ç›´æ¥éå†æ‰€æœ‰ producers

3. âŒ ä¸ºæ¯ä¸ª producer åˆ›å»ºä¸€ä¸ªçº¿ç¨‹
   â””â”€> threading.Thread(...)
   â””â”€> 100 ä¸ª producer = 100 ä¸ªçº¿ç¨‹

4. çº¿ç¨‹å¾ªç¯
   â””â”€> while not stop_producing.is_set()
       â””â”€> åªå¤„ç†ä¸€ä¸ª producer

5. ç»Ÿè®¡æ”¶é›†
   â””â”€> æ‰€æœ‰çº¿ç¨‹å…±äº« WorkerStats
   â””â”€> ä½¿ç”¨ multiprocessing.Lock
```

### Python æ­£ç¡®ç‰ˆæœ¬æµç¨‹ï¼ˆæ¨èï¼‰

```
1. âœ“ è·å– CPU æ ¸æ•°
   â””â”€> multiprocessing.cpu_count()

2. âœ“ åˆ†é… Producers åˆ°å„ä¸ª agent
   â””â”€> dict<int, List[ProducerInfo]>
   â””â”€> è½®è¯¢åˆ†é…ï¼ˆRound-Robinï¼‰

3. âœ“ ä¸ºæ¯ä¸ª agent åˆ›å»ºä¸€ä¸ªè¿›ç¨‹
   â””â”€> multiprocessing.Process(...)
   â””â”€> è¿›ç¨‹å†…åˆ›å»ºåˆ†é…çš„ producers

4. âœ“ è¿›ç¨‹å¾ªç¯
   â””â”€> while not stop_event.is_set()
       â””â”€> for producer in producers:
           â””â”€> send_message(...)

5. âœ“ ç»Ÿè®¡æ”¶é›†ï¼ˆéœ€è¦æ”¹è¿›ï¼‰
   æ–¹æ¡ˆ A: Queue æ±‡æ€»
   â””â”€> stats_queue.put(local_stats)
   â””â”€> ä¸»è¿›ç¨‹æ”¶é›†å™¨çº¿ç¨‹

   æ–¹æ¡ˆ B: Manager å…±äº«
   â””â”€> manager.dict() å…±äº«è®¡æ•°å™¨
   â””â”€> manager.Lock() ä¿æŠ¤
```

---

## ğŸ¯ æ¨èçš„å®Œæ•´å®ç°

### å®Œæ•´ä»£ç ç¤ºä¾‹

```python
import multiprocessing
import threading
import queue
import time
import logging
from typing import List, Dict

logger = logging.getLogger(__name__)


class LocalWorker(Worker):
    def __init__(self, stats_logger=None):
        self.benchmark_driver = None
        self.producers = []
        self.consumers = []
        self.stats = WorkerStats(stats_logger)

        # å¤šè¿›ç¨‹ç®¡ç†
        self.test_completed = multiprocessing.Event()
        self.producer_processes = []
        self.consumer_processes = []

        # ç»Ÿè®¡æ±‡æ€»
        self.stats_queue = multiprocessing.Queue()
        self.stats_collector_thread = None

    def start_load(self, producer_work_assignment):
        """å¯åŠ¨è´Ÿè½½ - å¤š agent æ¨¡å¼"""
        cpu_count = multiprocessing.cpu_count()

        logger.info(f"Starting {cpu_count} producer agents (processes)")

        # åˆ†é… producers åˆ°å„ä¸ª agent
        agent_assignments = self._assign_producers_to_agents(cpu_count)

        # è·å– producer é…ç½®
        producer_properties = self.benchmark_driver.producer_properties.copy()

        # å¯åŠ¨ç»Ÿè®¡æ”¶é›†å™¨
        self._start_stats_collector()

        # ä¸ºæ¯ä¸ª agent å¯åŠ¨ä¸€ä¸ªè¿›ç¨‹
        for agent_id, producer_infos in agent_assignments.items():
            process = multiprocessing.Process(
                target=_producer_agent_worker,
                args=(
                    agent_id,
                    producer_infos,
                    producer_properties,
                    producer_work_assignment,
                    self.test_completed,
                    self.stats_queue
                ),
                name=f"producer-agent-{agent_id}",
                daemon=False  # é daemonï¼Œç¡®ä¿æ­£å¸¸é€€å‡º
            )
            process.start()
            self.producer_processes.append(process)

        logger.info(f"Started {len(self.producer_processes)} producer agent processes")

    def _assign_producers_to_agents(self, num_agents: int) -> Dict[int, List]:
        """å°† producers åˆ†é…åˆ°å„ä¸ª agent"""
        assignments = {i: [] for i in range(num_agents)}

        for idx, producer in enumerate(self.producers):
            agent_id = idx % num_agents  # è½®è¯¢åˆ†é…
            assignments[agent_id].append({
                'topic': producer.topic,
                'index': idx
            })

        # æ‰“å°åˆ†é…ä¿¡æ¯
        for agent_id, infos in assignments.items():
            logger.info(f"Agent {agent_id}: {len(infos)} producers")

        return assignments

    def _start_stats_collector(self):
        """å¯åŠ¨ç»Ÿè®¡æ”¶é›†å™¨çº¿ç¨‹"""
        def collector_loop():
            while not self.test_completed.is_set():
                try:
                    stats_update = self.stats_queue.get(timeout=0.5)

                    # æ±‡æ€»åˆ°å…¨å±€ç»Ÿè®¡
                    self.stats.messages_sent.add(stats_update['messages_sent'])
                    self.stats.message_send_errors.add(stats_update['errors'])

                except queue.Empty:
                    continue
                except Exception as e:
                    logger.error(f"Stats collector error: {e}")

        self.stats_collector_thread = threading.Thread(
            target=collector_loop,
            daemon=True,
            name="stats-collector"
        )
        self.stats_collector_thread.start()

    def stop_all(self):
        """åœæ­¢æ‰€æœ‰ agents"""
        logger.info("Stopping all agents...")

        # è®¾ç½®åœæ­¢ä¿¡å·
        self.test_completed.set()

        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹é€€å‡º
        for process in self.producer_processes:
            process.join(timeout=5.0)
            if process.is_alive():
                logger.warning(f"Force terminating {process.name}")
                process.terminate()
                process.join(timeout=1.0)

        self.producer_processes.clear()

        # åœæ­¢ç»Ÿè®¡æ”¶é›†å™¨
        if self.stats_collector_thread:
            self.stats_collector_thread.join(timeout=2.0)

        logger.info("All agents stopped")


def _producer_agent_worker(agent_id, producer_infos, producer_properties,
                           work_assignment, stop_event, stats_queue):
    """
    Producer Agent å·¥ä½œå‡½æ•°ï¼ˆå…¨å±€å‡½æ•°ï¼Œæ”¯æŒ multiprocessingï¼‰

    æ¨¡æ‹Ÿä¸€ä¸ªç‹¬ç«‹çš„ agentï¼Œå¤„ç†åˆ†é…ç»™å®ƒçš„æ‰€æœ‰ producers
    """
    import random
    import time
    import logging
    from benchmark.utils.uniform_rate_limiter import UniformRateLimiter
    from benchmark.worker.message_producer import MessageProducer
    from benchmark.worker.worker_stats import WorkerStats
    from benchmark.driver_kafka.kafka_benchmark_producer import KafkaBenchmarkProducer

    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(f"agent-{agent_id}")

    logger.info(f"Agent {agent_id} starting with {len(producer_infos)} producers")

    try:
        # 1. åœ¨è¿›ç¨‹å†…åˆ›å»º producers
        producers = []
        for info in producer_infos:
            producer = KafkaBenchmarkProducer(
                info['topic'],
                producer_properties.copy()
            )
            producers.append({
                'producer': producer,
                'index': info['index']
            })

        # 2. åˆ›å»ºæœ¬åœ°ç»Ÿè®¡å’Œé€Ÿç‡é™åˆ¶å™¨
        local_stats = WorkerStats()

        # è®¡ç®—æ­¤ agent çš„æ€»é€Ÿç‡
        # æ³¨æ„ï¼šæ€»é€Ÿç‡å·²ç»è¢«åˆ†é…äº†ï¼Œè¿™é‡Œæ˜¯æ¯ä¸ª producer çš„é€Ÿç‡
        total_rate = work_assignment.publish_rate
        num_total_producers = len(producer_infos)  # ç®€åŒ–ï¼šå‡è®¾å¹³å‡åˆ†é…
        per_producer_rate = total_rate / num_total_producers if num_total_producers > 0 else 1.0

        rate_limiter = UniformRateLimiter(per_producer_rate)
        message_producer = MessageProducer(rate_limiter, local_stats)

        # 3. å‡†å¤‡ payload
        payload = (work_assignment.payload_data[0]
                   if work_assignment.payload_data
                   else bytes(1024))

        # 4. ä¸»å¾ªç¯ï¼šè½®è¯¢æ‰€æœ‰ producers å‘é€æ¶ˆæ¯
        last_stats_report = time.time()
        messages_sent_since_last_report = 0

        while not stop_event.is_set():
            for producer_info in producers:
                if stop_event.is_set():
                    break

                producer = producer_info['producer']
                index = producer_info['index']

                # é€‰æ‹© key
                key = None
                if work_assignment.key_distributor_type:
                    if hasattr(work_assignment.key_distributor_type, 'name'):
                        dist_type = work_assignment.key_distributor_type.name
                        if dist_type == 'RANDOM':
                            key = str(random.randint(0, 1000000))
                        elif dist_type == 'ROUND_ROBIN':
                            key = str(index)

                # å‘é€æ¶ˆæ¯ï¼ˆå¸¦é€Ÿç‡é™åˆ¶ï¼‰
                try:
                    message_producer.send_message(producer, key, payload)
                    messages_sent_since_last_report += 1
                except Exception as e:
                    logger.error(f"Send error: {e}")

            # 5. å®šæœŸæ±‡æŠ¥ç»Ÿè®¡ï¼ˆæ¯ç§’ï¼‰
            now = time.time()
            if now - last_stats_report >= 1.0:
                counters = local_stats.to_counters_stats()
                stats_queue.put({
                    'agent_id': agent_id,
                    'messages_sent': messages_sent_since_last_report,
                    'errors': counters.message_send_errors
                })

                logger.debug(f"Agent {agent_id}: sent {messages_sent_since_last_report} msgs/s")

                messages_sent_since_last_report = 0
                last_stats_report = now

    except Exception as e:
        logger.error(f"Agent {agent_id} fatal error: {e}", exc_info=True)

    finally:
        # 6. æ¸…ç†èµ„æº
        logger.info(f"Agent {agent_id} shutting down...")
        for producer_info in producers:
            try:
                producer_info['producer'].close()
            except Exception as e:
                logger.error(f"Error closing producer: {e}")

        logger.info(f"Agent {agent_id} stopped")
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### Java å¤šçº¿ç¨‹

| åœºæ™¯ | çº¿ç¨‹æ•° | è¯´æ˜ |
|------|--------|------|
| 8 æ ¸ CPU, 100 producers | 8 | æ¯æ ¸ä¸€ä¸ªçº¿ç¨‹ |
| 16 æ ¸ CPU, 100 producers | 16 | æ¯æ ¸ä¸€ä¸ªçº¿ç¨‹ |
| 8 æ ¸ CPU, 10 producers | 8 | éƒ¨åˆ†çº¿ç¨‹ç©ºé—² |

**ä¼˜ç‚¹**:
- âœ… ç®€å•ï¼Œæ˜“äºç†è§£
- âœ… å…±äº«å†…å­˜ï¼Œç»Ÿè®¡æ”¶é›†ç®€å•

**ç¼ºç‚¹**:
- âŒ å— GIL é™åˆ¶ï¼ˆPython ä¸­ï¼‰
- âŒ ä¸èƒ½çœŸæ­£å¹¶è¡Œï¼ˆPython ä¸­ï¼‰

### Python å¤šè¿›ç¨‹ï¼ˆæ¨èï¼‰

| åœºæ™¯ | è¿›ç¨‹æ•° | è¯´æ˜ |
|------|--------|------|
| 8 æ ¸ CPU, 100 producers | 8 | æ¯æ ¸ä¸€ä¸ªè¿›ç¨‹ï¼ŒçœŸæ­£å¹¶è¡Œ |
| 16 æ ¸ CPU, 100 producers | 16 | æ¯æ ¸ä¸€ä¸ªè¿›ç¨‹ |
| 8 æ ¸ CPU, 10 producers | 8 | éƒ¨åˆ†è¿›ç¨‹å¤„ç† 1-2 ä¸ª |

**ä¼˜ç‚¹**:
- âœ… **çœŸæ­£å¹¶è¡Œ**ï¼ˆæ—  GILï¼‰
- âœ… **æ€§èƒ½æ›´é«˜**
- âœ… æ›´æ¥è¿‘çœŸå®åˆ†å¸ƒå¼åœºæ™¯

**ç¼ºç‚¹**:
- âš ï¸ ç»Ÿè®¡æ±‡æ€»å¤æ‚
- âš ï¸ éœ€è¦åºåˆ—åŒ–ï¼ˆpickleï¼‰

---

## âœ… æ€»ç»“ä¸å»ºè®®

### å½“å‰å®ç°çš„æ ¹æœ¬é—®é¢˜

1. **âŒ æ²¡æœ‰å®ç°å¤š agent æ¨¡æ‹Ÿ**
   - åº”è¯¥ï¼šCPU æ ¸æ•°ä¸ªè¿›ç¨‹
   - å®é™…ï¼šproducer æ•°é‡ä¸ªçº¿ç¨‹

2. **âŒ æ²¡æœ‰è´Ÿè½½å‡è¡¡**
   - åº”è¯¥ï¼šè½®è¯¢åˆ†é… producers
   - å®é™…ï¼šæ¯ä¸ª producer ä¸€ä¸ªçº¿ç¨‹

3. **âŒ æ¶æ„ä¸ä¸€è‡´**
   - Consumer: è¿›ç¨‹
   - Producer: çº¿ç¨‹ï¼ˆé”™è¯¯ï¼‰

### æ¨èæ”¹è¿›æ–¹æ¡ˆ

1. **âœ… å®ç°çœŸæ­£çš„å¤š agent æ¨¡æ‹Ÿ**
   ```python
   cpu_count = multiprocessing.cpu_count()
   # åˆ›å»º cpu_count ä¸ªè¿›ç¨‹ï¼Œæ¯ä¸ªä»£è¡¨ä¸€ä¸ª agent
   ```

2. **âœ… ä½¿ç”¨è´Ÿè½½å‡è¡¡åˆ†é…**
   ```python
   # Round-Robin åˆ†é… producers åˆ°å„ä¸ª agent
   agent_id = producer_index % cpu_count
   ```

3. **âœ… ç»Ÿä¸€ä½¿ç”¨è¿›ç¨‹**
   ```python
   # Producer agents: multiprocessing.Process
   # Consumer agents: multiprocessing.Process
   ```

4. **âœ… å®ç°ç»Ÿè®¡æ±‡æ€»**
   ```python
   # æ–¹æ¡ˆ A: Queue + collector thread
   # æ–¹æ¡ˆ B: Manager.dict() + Lock
   ```

ä½ çš„è®¾è®¡æ„å›¾æ˜¯**å®Œå…¨æ­£ç¡®**çš„ï¼åªæ˜¯å½“å‰å®ç°åç¦»äº†è¿™ä¸ªç›®æ ‡ã€‚æŒ‰ç…§ä¸Šè¿°æ–¹æ¡ˆä¿®æ”¹åï¼Œå°±èƒ½çœŸæ­£å®ç°"å¤š agent å¹¶è¡Œæ¨¡æ‹Ÿ"ã€‚

---

**æ–‡æ¡£ç”Ÿæˆæ—¶é—´**: 2025-10-03
**åˆ†æè€…**: Claude (Anthropic)
