# OpenMessaging Benchmark é¡¹ç›®è¯¦è§£æ–‡æ¡£

> è¿™ä»½æ–‡æ¡£ä¼šè¯¦ç»†è§£é‡Šè¿™ä¸ªé¡¹ç›®çš„æ¯ä¸ªéƒ¨åˆ†ï¼Œå¸®åŠ©æ‚¨è½»æ¾ç†è§£æ•´ä¸ªç³»ç»Ÿã€‚

---

## ğŸ“š ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [æ•´ä½“æ¶æ„](#æ•´ä½“æ¶æ„)
3. [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
4. [ä»£ç æ‰§è¡Œæµç¨‹](#ä»£ç æ‰§è¡Œæµç¨‹)
5. [å„æ¨¡å—è¯¦è§£](#å„æ¨¡å—è¯¦è§£)
6. [æ–‡ä»¶ç»“æ„å¯¼èˆª](#æ–‡ä»¶ç»“æ„å¯¼èˆª)

---

## é¡¹ç›®æ¦‚è¿°

### ğŸ¯ è¿™ä¸ªé¡¹ç›®æ˜¯å¹²ä»€ä¹ˆçš„ï¼Ÿ

è¿™æ˜¯ä¸€ä¸ª**æ¶ˆæ¯ç³»ç»Ÿæ€§èƒ½æµ‹è¯•å·¥å…·**ï¼Œå¯ä»¥æµ‹è¯• Kafka ç­‰æ¶ˆæ¯é˜Ÿåˆ—çš„æ€§èƒ½ã€‚

**æ‰“ä¸ªæ¯”æ–¹ï¼š**
- å°±åƒæ±½è½¦å‚è¦æµ‹è¯•æ±½è½¦çš„æ€§èƒ½ï¼ˆæœ€é«˜æ—¶é€Ÿã€æ²¹è€—ç­‰ï¼‰
- è¿™ä¸ªå·¥å…·å°±æ˜¯æµ‹è¯•æ¶ˆæ¯ç³»ç»Ÿçš„"æ€§èƒ½"ï¼ˆæ¯ç§’èƒ½å‘å¤šå°‘æ¶ˆæ¯ã€å»¶è¿Ÿå¤šå°‘ï¼‰

### ğŸ“Š èƒ½æµ‹ä»€ä¹ˆï¼Ÿ

1. **ååé‡**ï¼šæ¯ç§’èƒ½å‘å¤šå°‘æ¡æ¶ˆæ¯
2. **å»¶è¿Ÿ**ï¼šæ¶ˆæ¯ä»å‘é€åˆ°æ¥æ”¶è¦å¤šä¹…
3. **é”™è¯¯ç‡**ï¼šå‘é€å¤±è´¥çš„æ¯”ä¾‹
4. **ç§¯å‹å¤„ç†**ï¼šå½“æ¶ˆæ¯å †ç§¯æ—¶çš„å¤„ç†èƒ½åŠ›

### ğŸ”§ æ€ä¹ˆç”¨ï¼Ÿ

```bash
python -m benchmark \
  -d kafka-driver.yaml \      # Kafkaé…ç½®æ–‡ä»¶
  simple-workload.yaml        # æµ‹è¯•ä»»åŠ¡é…ç½®
```

---

## æ•´ä½“æ¶æ„

### ğŸ“¦ å››å±‚æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         1. ä¸»ç¨‹åºå±‚ (Benchmark)                  â”‚
â”‚    è´Ÿè´£ï¼šè¯»é…ç½®ã€å¯åŠ¨æµ‹è¯•ã€æ”¶é›†ç»“æœ               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     2. è´Ÿè½½ç”Ÿæˆå±‚ (WorkloadGenerator)            â”‚
â”‚    è´Ÿè´£ï¼šåˆ›å»ºç”Ÿäº§è€…/æ¶ˆè´¹è€…ã€æ§åˆ¶å‘é€é€Ÿç‡          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         3. Workerå±‚ (LocalWorker)               â”‚
â”‚    è´Ÿè´£ï¼šå®é™…æ‰§è¡Œå‘é€/æ¥æ”¶ã€ç»Ÿè®¡æ•°æ®              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       4. é©±åŠ¨å±‚ (KafkaBenchmarkDriver)          â”‚
â”‚    è´Ÿè´£ï¼šä¸Kafkaäº¤äº’ï¼ˆå‘æ¶ˆæ¯ã€æ”¶æ¶ˆæ¯ï¼‰            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ æ•°æ®æµå‘

```
é…ç½®æ–‡ä»¶ â†’ Benchmarkè¯»å– â†’ WorkloadGeneratoråˆ›å»ºä»»åŠ¡
  â†’ LocalWorkeræ‰§è¡Œ â†’ Kafkaé©±åŠ¨å‘é€/æ¥æ”¶
    â†’ ç»Ÿè®¡ç»“æœ â†’ ä¿å­˜JSONæ–‡ä»¶
```

---

## æ ¸å¿ƒæ¦‚å¿µ

### 1ï¸âƒ£ Workloadï¼ˆå·¥ä½œè´Ÿè½½ï¼‰

**å®šä¹‰ï¼š** æµ‹è¯•çš„å‚æ•°é…ç½®

**åŒ…å«ä»€ä¹ˆï¼š**
- `topics`: åˆ›å»ºå‡ ä¸ªä¸»é¢˜
- `partitionsPerTopic`: æ¯ä¸ªä¸»é¢˜å‡ ä¸ªåˆ†åŒº
- `messageSize`: æ¶ˆæ¯å¤§å°ï¼ˆå­—èŠ‚ï¼‰
- `producerRate`: æ¯ç§’å‘å¤šå°‘æ¶ˆæ¯ï¼ˆ0=æœ€å¤§é€Ÿç‡ï¼‰
- `testDurationMinutes`: æµ‹è¯•å¤šä¹…

**ä¸¾ä¾‹ï¼š**
```yaml
name: simple-test
topics: 1                    # åˆ›å»º1ä¸ªä¸»é¢˜
partitionsPerTopic: 1        # æ¯ä¸ªä¸»é¢˜1ä¸ªåˆ†åŒº
messageSize: 1024            # æ¶ˆæ¯1KB
producerRate: 1000           # æ¯ç§’1000æ¡æ¶ˆæ¯
testDurationMinutes: 5       # æµ‹è¯•5åˆ†é’Ÿ
```

### 2ï¸âƒ£ Driverï¼ˆé©±åŠ¨ï¼‰

**å®šä¹‰ï¼š** ä¸å…·ä½“æ¶ˆæ¯ç³»ç»Ÿï¼ˆå¦‚Kafkaï¼‰äº¤äº’çš„ä»£ç 

**èŒè´£ï¼š**
- åˆ›å»ºTopic
- åˆ›å»ºProducerï¼ˆç”Ÿäº§è€…ï¼‰
- åˆ›å»ºConsumerï¼ˆæ¶ˆè´¹è€…ï¼‰
- å‘é€æ¶ˆæ¯
- æ¥æ”¶æ¶ˆæ¯

### 3ï¸âƒ£ Workerï¼ˆå·¥ä½œèŠ‚ç‚¹ï¼‰

**å®šä¹‰ï¼š** æ‰§è¡Œå®é™…æµ‹è¯•çš„å·¥ä½œè¿›ç¨‹

**ä¸¤ç§æ¨¡å¼ï¼š**
1. **LocalWorker** - æœ¬åœ°æ¨¡å¼ï¼ˆå•æœºæµ‹è¯•ï¼‰
2. **DistributedWorker** - åˆ†å¸ƒå¼æ¨¡å¼ï¼ˆå¤šæœºæµ‹è¯•ï¼‰

### 4ï¸âƒ£ Producer & Consumer

**Producerï¼ˆç”Ÿäº§è€…ï¼‰ï¼š** å‘é€æ¶ˆæ¯çš„ç»„ä»¶
**Consumerï¼ˆæ¶ˆè´¹è€…ï¼‰ï¼š** æ¥æ”¶æ¶ˆæ¯çš„ç»„ä»¶

---

## ä»£ç æ‰§è¡Œæµç¨‹

### ğŸš€ å®Œæ•´æµç¨‹ï¼ˆä¸€æ­¥ä¸€æ­¥ï¼‰

#### ç¬¬1æ­¥ï¼šç¨‹åºå¯åŠ¨
```
ç”¨æˆ·è¿è¡Œå‘½ä»¤
  â†“
__main__.py æ¥æ”¶å‚æ•°
  â†“
è°ƒç”¨ Benchmark.main()
```

#### ç¬¬2æ­¥ï¼šè¯»å–é…ç½®
```
Benchmark.main()
  â†“
è¯»å– workload.yamlï¼ˆæµ‹è¯•é…ç½®ï¼‰
è¯»å– driver.yamlï¼ˆKafkaé…ç½®ï¼‰
è¯»å– workers.yamlï¼ˆWorkeré…ç½®ï¼Œå¯é€‰ï¼‰
```

#### ç¬¬3æ­¥ï¼šåˆ›å»ºWorker
```
å¦‚æœæœ‰workersé…ç½® â†’ åˆ›å»º DistributedWorkersEnsembleï¼ˆåˆ†å¸ƒå¼ï¼‰
å¦‚æœæ²¡æœ‰ â†’ åˆ›å»º LocalWorkerï¼ˆæœ¬åœ°ï¼‰
```

#### ç¬¬4æ­¥ï¼šåˆå§‹åŒ–Driver
```
LocalWorker.initialize_driver()
  â†“
è¯»å–driveré…ç½®æ–‡ä»¶
  â†“
åŠ¨æ€åŠ è½½ KafkaBenchmarkDriver
  â†“
è¿æ¥åˆ°Kafka
```

#### ç¬¬5æ­¥ï¼šåˆ›å»ºWorkloadGenerator
```
åˆ›å»º WorkloadGenerator å¯¹è±¡
ä¼ å…¥ï¼š
  - driveråç§°
  - workloadé…ç½®
  - workerå¯¹è±¡
```

#### ç¬¬6æ­¥ï¼šè¿è¡Œæµ‹è¯•ï¼ˆæœ€é‡è¦ï¼ï¼‰

```
WorkloadGenerator.run() {

  6.1 åˆ›å»ºTopics
      worker.create_topics()
        â†’ KafkaBenchmarkDriver.create_topics()
        â†’ åœ¨Kafkaä¸­åˆ›å»ºä¸»é¢˜

  6.2 åˆ›å»ºProducers
      _create_producers()
        â†’ ä¸ºæ¯ä¸ªtopicåˆ›å»ºå¤šä¸ªproducer
        â†’ ä¾‹å¦‚ï¼š1ä¸ªtopic Ã— 5ä¸ªproducers = 5ä¸ªproducerå®ä¾‹

  6.3 åˆ›å»ºConsumers
      _create_consumers()
        â†’ ä¸ºæ¯ä¸ªtopicåˆ›å»ºå¤šä¸ªconsumer
        â†’ ä¾‹å¦‚ï¼š1ä¸ªtopic Ã— 2ä¸ªsubscriptions Ã— 3ä¸ªconsumers = 6ä¸ªconsumerå®ä¾‹

  6.4 ç¡®ä¿Consumerå°±ç»ª
      _ensure_topics_are_ready()
        â†’ å‘é€æµ‹è¯•æ¶ˆæ¯
        â†’ ç­‰å¾…consumeræ¥æ”¶åˆ°æ¶ˆæ¯
        â†’ ç¡®ä¿consumerå·²ç»åˆ†é…åˆ°partition

  6.5 é¢„çƒ­é˜¶æ®µï¼ˆå¯é€‰ï¼‰
      å¦‚æœ warmupDurationMinutes > 0:
        â†’ å¯åŠ¨å‘é€æ¶ˆæ¯ï¼ˆé¢„çƒ­ï¼‰
        â†’ æ”¶é›†é¢„çƒ­æ•°æ®ï¼ˆä½†ä¸è®¡å…¥æœ€ç»ˆç»“æœï¼‰

  6.6 æ­£å¼æµ‹è¯•é˜¶æ®µ
      worker.start_load() {
        â†’ åˆ›å»ºå¤šä¸ªç”Ÿäº§è€…çº¿ç¨‹
        â†’ æ¯ä¸ªçº¿ç¨‹å¾ªç¯å‘é€æ¶ˆæ¯ï¼š
          while not stopped:
            1. é€Ÿç‡é™åˆ¶ï¼ˆæ§åˆ¶å‘é€é€Ÿåº¦ï¼‰
            2. é€‰æ‹©keyï¼ˆæ ¹æ®åˆ†å¸ƒç­–ç•¥ï¼‰
            3. å‘é€æ¶ˆæ¯ producer.send_async()
            4. è®°å½•ç»Ÿè®¡ï¼ˆå»¶è¿Ÿã€ååé‡ç­‰ï¼‰
      }

      åŒæ—¶ï¼ŒConsumeråœ¨åå°æ¥æ”¶æ¶ˆæ¯ï¼š
        â†’ æ¯ä¸ªconsumerç‹¬ç«‹è¿›ç¨‹pollæ¶ˆæ¯
        â†’ æ”¶åˆ°æ¶ˆæ¯åå›è°ƒ message_received()
        â†’ è®°å½•ç«¯åˆ°ç«¯å»¶è¿Ÿ

  6.7 æ”¶é›†ç»Ÿè®¡
      æ¯10ç§’æ‰§è¡Œä¸€æ¬¡ï¼š
        â†’ worker.get_period_stats()
        â†’ æ‰“å°å½“å‰æ€§èƒ½æŒ‡æ ‡ï¼š
          - å‘é€é€Ÿç‡ï¼ˆmsg/sï¼‰
          - æ¥æ”¶é€Ÿç‡ï¼ˆmsg/sï¼‰
          - å»¶è¿Ÿï¼ˆå¹³å‡ã€P50ã€P99ç­‰ï¼‰
          - ç§¯å‹æ•°é‡

  6.8 æµ‹è¯•ç»“æŸ
      â†’ worker.stop_all()
      â†’ åœæ­¢æ‰€æœ‰producerçº¿ç¨‹
      â†’ åœæ­¢æ‰€æœ‰consumerè¿›ç¨‹
      â†’ è¿”å› TestResult å¯¹è±¡
}
```

#### ç¬¬7æ­¥ï¼šä¿å­˜ç»“æœ
```
Benchmark.main()
  â†“
è·å– TestResult
  â†“
è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
  â†“
ä¿å­˜ä¸ºJSONæ–‡ä»¶ï¼ˆåŒ…å«æ‰€æœ‰æ€§èƒ½æŒ‡æ ‡ï¼‰
```

---

## å„æ¨¡å—è¯¦è§£

### æ¨¡å—1ï¼šä¸»ç¨‹åºæ¨¡å—

#### ğŸ“ `benchmark.py` - ä¸»ç¨‹åº

**æ ¸å¿ƒç±»ï¼š** `Benchmark`

**ä¸»è¦æ–¹æ³•ï¼š**

1. **`main(args)`** - ç¨‹åºå…¥å£
   ```python
   # åŠŸèƒ½ï¼š
   - è§£æå‘½ä»¤è¡Œå‚æ•°
   - è¯»å–é…ç½®æ–‡ä»¶
   - åˆ›å»ºWorker
   - æ‰§è¡Œæµ‹è¯•
   - ä¿å­˜ç»“æœ
   ```

2. **`_dict_to_workload(data)`** - è½¬æ¢é…ç½®
   ```python
   # åŠŸèƒ½ï¼š
   - æŠŠYAMLé…ç½®è½¬æˆWorkloadå¯¹è±¡
   - è®¾ç½®æµ‹è¯•å‚æ•°
   ```

3. **`_test_result_to_dict(result)`** - å¯¼å‡ºç»“æœ
   ```python
   # åŠŸèƒ½ï¼š
   - æŠŠTestResultå¯¹è±¡è½¬æˆå­—å…¸
   - æ–¹ä¾¿ä¿å­˜ä¸ºJSON
   ```

**æ‰§è¡Œé€»è¾‘ï¼š**
```
1. è§£æå‚æ•°ï¼ˆ-d driver, -wf workers, workloadæ–‡ä»¶ï¼‰
2. åŠ è½½workloadé…ç½®
3. åˆ›å»ºworkerï¼ˆæœ¬åœ°æˆ–åˆ†å¸ƒå¼ï¼‰
4. éå†æ¯ä¸ªworkloadå’Œdriverç»„åˆï¼š
   - åˆå§‹åŒ–driver
   - åˆ›å»ºWorkloadGenerator
   - è¿è¡Œæµ‹è¯•
   - ä¿å­˜ç»“æœ
5. å…³é—­worker
```

---

### æ¨¡å—2ï¼šè´Ÿè½½ç”Ÿæˆæ¨¡å—

#### ğŸ“ `workload_generator.py` - è´Ÿè½½ç”Ÿæˆå™¨

**æ ¸å¿ƒç±»ï¼š** `WorkloadGenerator`

**æ„é€ å‡½æ•°ï¼š**
```python
def __init__(self, driver_name, workload, worker):
    self.driver_name = driver_name      # é©±åŠ¨åç§°ï¼ˆå¦‚"Kafka"ï¼‰
    self.workload = workload            # æµ‹è¯•é…ç½®
    self.worker = worker                # Workerå¯¹è±¡
    self.executor = ThreadPoolExecutor  # çº¿ç¨‹æ± ï¼ˆç”¨äºåå°ä»»åŠ¡ï¼‰
    self.target_publish_rate = 0.0      # ç›®æ ‡å‘é€é€Ÿç‡
```

**ä¸»è¦æ–¹æ³•ï¼š**

1. **`run()`** - æ‰§è¡Œæµ‹è¯•ï¼ˆæœ€é‡è¦ï¼ï¼‰
   ```python
   æµç¨‹ï¼š
   1. åˆ›å»ºtopics
   2. åˆ›å»ºproducerså’Œconsumers
   3. ç¡®ä¿consumerå°±ç»ª
   4. é¢„çƒ­ï¼ˆå¯é€‰ï¼‰
   5. å¼€å§‹æ­£å¼æµ‹è¯•
   6. æ”¶é›†ç»Ÿè®¡
   7. è¿”å›ç»“æœ
   ```

2. **`_create_producers(topics)`** - åˆ›å»ºç”Ÿäº§è€…
   ```python
   # ä¸ºæ¯ä¸ªtopicåˆ›å»ºNä¸ªproducer
   # N = workload.producers_per_topic

   ä¾‹å¦‚ï¼š
   - 2ä¸ªtopics
   - producers_per_topic = 3
   - ç»“æœï¼šåˆ›å»º 2Ã—3=6 ä¸ªproducers
   ```

3. **`_create_consumers(topics)`** - åˆ›å»ºæ¶ˆè´¹è€…
   ```python
   # ä¸ºæ¯ä¸ªtopicåˆ›å»ºæ¶ˆè´¹è€…
   # æ•°é‡ = subscriptions_per_topic Ã— consumer_per_subscription

   ä¾‹å¦‚ï¼š
   - 2ä¸ªtopics
   - subscriptions_per_topic = 2
   - consumer_per_subscription = 3
   - ç»“æœï¼šåˆ›å»º 2Ã—2Ã—3=12 ä¸ªconsumers
   ```

4. **`_ensure_topics_are_ready()`** - ç¡®ä¿å‡†å¤‡å°±ç»ª
   ```python
   # ä¸ºä»€ä¹ˆéœ€è¦ï¼Ÿ
   # Kafkaçš„consumeréœ€è¦å…ˆæ”¶åˆ°æ¶ˆæ¯æ‰èƒ½åˆ†é…partition

   æµç¨‹ï¼š
   1. æ¯ä¸ªproducerå‘é€1æ¡æµ‹è¯•æ¶ˆæ¯
   2. ç­‰å¾…consumeræ”¶åˆ°æ‰€æœ‰æµ‹è¯•æ¶ˆæ¯
   3. è¶…æ—¶60ç§’åæŠ¥é”™
   ```

5. **`_print_and_collect_stats(duration)`** - æ”¶é›†ç»Ÿè®¡
   ```python
   # æ¯10ç§’æ‰§è¡Œï¼š
   1. è·å–period_statsï¼ˆå‘¨æœŸç»Ÿè®¡ï¼‰
   2. è®¡ç®—é€Ÿç‡ï¼ˆå‘é€/æ¥æ”¶ï¼‰
   3. æ‰“å°æ—¥å¿—
   4. æ·»åŠ åˆ°ç»“æœåˆ—è¡¨

   # æµ‹è¯•ç»“æŸæ—¶ï¼š
   5. è·å–cumulative_latenciesï¼ˆç´¯è®¡å»¶è¿Ÿï¼‰
   6. è®¡ç®—ç™¾åˆ†ä½æ•°ï¼ˆP50, P95, P99ç­‰ï¼‰
   7. è¿”å›TestResultå¯¹è±¡
   ```

6. **`_find_maximum_sustainable_rate()`** - è‡ªåŠ¨æ¢æµ‹æœ€å¤§é€Ÿç‡
   ```python
   # ä»€ä¹ˆæ—¶å€™ç”¨ï¼Ÿ
   # å½“ workload.producer_rate = 0 æ—¶

   # æ€ä¹ˆå·¥ä½œï¼Ÿ
   1. ä»10000 msg/så¼€å§‹
   2. æ¯3ç§’æ£€æŸ¥ä¸€æ¬¡ï¼š
      - å¦‚æœæ¶ˆè´¹é€Ÿåº¦ < ç”Ÿäº§é€Ÿåº¦ â†’ é™ä½é€Ÿç‡
      - å¦‚æœæ¶ˆè´¹é€Ÿåº¦ = ç”Ÿäº§é€Ÿåº¦ â†’ æé«˜é€Ÿç‡
   3. ä½¿ç”¨RateControlleråŠ¨æ€è°ƒæ•´
   ```

7. **`_build_and_drain_backlog()`** - ç§¯å‹æµ‹è¯•
   ```python
   # ä»€ä¹ˆæ—¶å€™ç”¨ï¼Ÿ
   # å½“ workload.consumer_backlog_size_gb > 0 æ—¶

   # æµç¨‹ï¼š
   1. æš‚åœæ‰€æœ‰consumer
   2. ç»§ç»­å‘é€æ¶ˆæ¯ï¼Œç›´åˆ°ç§¯å‹è¾¾åˆ°ç›®æ ‡å¤§å°
   3. æ¢å¤consumer
   4. ç­‰å¾…ç§¯å‹è¢«æ¶ˆè´¹å®Œ
   5. å†è¿è¡ŒæŒ‡å®šçš„æµ‹è¯•æ—¶é—´
   ```

**å…³é”®ç‚¹ï¼š**
- WorkloadGeneratoræ˜¯æµ‹è¯•çš„"æŒ‡æŒ¥å®˜"
- å®ƒåè°ƒproducerã€consumerã€ç»Ÿè®¡çš„å·¥ä½œ
- æ”¯æŒé¢„çƒ­ã€ç§¯å‹æµ‹è¯•ã€è‡ªåŠ¨é€Ÿç‡æ¢æµ‹ç­‰é«˜çº§åŠŸèƒ½

---

### æ¨¡å—3ï¼šWorkeræ¨¡å—

#### ğŸ“ `worker/worker.py` - Workeræ¥å£

**æ ¸å¿ƒç±»ï¼š** `Worker`ï¼ˆæŠ½è±¡åŸºç±»ï¼‰

**å®šä¹‰çš„æ¥å£ï¼š**
```python
initialize_driver()        # åˆå§‹åŒ–é©±åŠ¨
create_topics()           # åˆ›å»ºä¸»é¢˜
create_producers()        # åˆ›å»ºç”Ÿäº§è€…
create_consumers()        # åˆ›å»ºæ¶ˆè´¹è€…
start_load()              # å¼€å§‹å‘é€è´Ÿè½½
get_counters_stats()      # è·å–è®¡æ•°ç»Ÿè®¡
get_period_stats()        # è·å–å‘¨æœŸç»Ÿè®¡
stop_all()                # åœæ­¢æ‰€æœ‰ä»»åŠ¡
```

è¿™æ˜¯ä¸€ä¸ª**æ¥å£**ï¼ˆJavaæœ¯è¯­å«Interfaceï¼‰ï¼Œå®šä¹‰äº†Workerå¿…é¡»å®ç°çš„æ–¹æ³•ã€‚

---

#### ğŸ“ `worker/local_worker.py` - æœ¬åœ°Worker

**æ ¸å¿ƒç±»ï¼š** `LocalWorker`ï¼ˆå®ç°Workeræ¥å£ï¼‰

**ä¸»è¦å±æ€§ï¼š**
```python
self.benchmark_driver     # Kafkaé©±åŠ¨å®ä¾‹
self.producers            # ç”Ÿäº§è€…åˆ—è¡¨
self.consumers            # æ¶ˆè´¹è€…åˆ—è¡¨
self.stats                # ç»Ÿè®¡å¯¹è±¡ï¼ˆWorkerStatsï¼‰
self.producer_threads     # ç”Ÿäº§è€…çº¿ç¨‹åˆ—è¡¨
self.stop_producing       # åœæ­¢æ ‡å¿—
```

**æ ¸å¿ƒæ–¹æ³•è¯¦è§£ï¼š**

1. **`initialize_driver(config_file)`**
   ```python
   # åŠŸèƒ½ï¼šåˆå§‹åŒ–Kafkaé©±åŠ¨

   æµç¨‹ï¼š
   1. è¯»å–driveré…ç½®æ–‡ä»¶ï¼ˆYAMLï¼‰
   2. è§£æé…ç½®ï¼ˆdriverClassç­‰ï¼‰
   3. åŠ¨æ€å¯¼å…¥driverç±»
      ä¾‹å¦‚ï¼šbenchmark.drivers.kafka.kafka_benchmark_driver.KafkaBenchmarkDriver
   4. å®ä¾‹åŒ–driver
   5. è°ƒç”¨driver.initialize()
   ```

2. **`create_topics(topics_info)`**
   ```python
   # åŠŸèƒ½ï¼šåˆ›å»ºKafkaä¸»é¢˜

   æµç¨‹ï¼š
   1. ç”Ÿæˆtopicåç§°ï¼ˆæ ¼å¼ï¼štest-topic-0, test-topic-1...ï¼‰
   2. è°ƒç”¨ driver.create_topics()
   3. ç­‰å¾…åˆ›å»ºå®Œæˆ
   4. è¿”å›topicåç§°åˆ—è¡¨
   ```

3. **`create_producers(topics)`**
   ```python
   # åŠŸèƒ½ï¼šä¸ºæ¯ä¸ªtopicåˆ›å»ºproducer

   æµç¨‹ï¼š
   1. ä¸ºæ¯ä¸ªtopicåˆ›å»ºProducerInfoå¯¹è±¡
   2. è°ƒç”¨ driver.create_producers()
   3. ä¿å­˜åˆ° self.producers åˆ—è¡¨

   ä¾‹å¦‚ï¼š
   topics = ["test-topic-0", "test-topic-1"]
   â†’ åˆ›å»º2ä¸ªKafkaBenchmarkProducerå®ä¾‹
   ```

4. **`create_consumers(consumer_assignment)`**
   ```python
   # åŠŸèƒ½ï¼šåˆ›å»ºconsumers

   æµç¨‹ï¼š
   1. ä¸ºæ¯ä¸ª(topic, subscription)å¯¹åˆ›å»ºConsumerInfo
   2. ä¼ å…¥callbackï¼ˆselfï¼Œå› ä¸ºLocalWorkerå®ç°äº†ConsumerCallbackï¼‰
   3. è°ƒç”¨ driver.create_consumers()
   4. ä¿å­˜åˆ° self.consumers åˆ—è¡¨

   é‡è¦ï¼šLocalWorkeræœ¬èº«æ˜¯ConsumerCallbackï¼
   å½“consumeræ”¶åˆ°æ¶ˆæ¯æ—¶ï¼Œä¼šè°ƒç”¨ self.message_received()
   ```

5. **`start_load(producer_work_assignment)`**
   ```python
   # åŠŸèƒ½ï¼šå¼€å§‹å‘é€æ¶ˆæ¯ï¼ˆæœ€é‡è¦ï¼ï¼‰

   æµç¨‹ï¼š
   1. ä¿å­˜work_assignmentï¼ˆåŒ…å«payloadã€keyåˆ†å¸ƒç­–ç•¥ç­‰ï¼‰
   2. æ¸…é™¤stop_producingæ ‡å¿—
   3. ä¸ºæ¯ä¸ªproduceråˆ›å»ºä¸€ä¸ªçº¿ç¨‹ï¼š
      - çº¿ç¨‹åï¼šproducer-0, producer-1...
      - çº¿ç¨‹å‡½æ•°ï¼š_producer_worker_simple()
      - daemon=Trueï¼ˆå®ˆæŠ¤çº¿ç¨‹ï¼Œä¸»ç¨‹åºé€€å‡ºæ—¶è‡ªåŠ¨ç»“æŸï¼‰
   4. å¯åŠ¨æ‰€æœ‰çº¿ç¨‹

   å…³é”®ï¼šæ¯ä¸ªproducerä¸€ä¸ªçº¿ç¨‹ï¼Œç‹¬ç«‹å‘é€æ¶ˆæ¯
   ```

6. **`_producer_worker_simple(producer, producer_index)`**
   ```python
   # åŠŸèƒ½ï¼šç”Ÿäº§è€…å·¥ä½œçº¿ç¨‹ï¼ˆæ ¸å¿ƒå‘é€é€»è¾‘ï¼‰

   æµç¨‹ï¼š
   1. åˆ›å»ºç‹¬ç«‹çš„RateLimiterï¼ˆé€Ÿç‡é™åˆ¶å™¨ï¼‰
   2. åˆ›å»ºç‹¬ç«‹çš„MessageProducerï¼ˆæ¶ˆæ¯å‘é€å™¨ï¼‰
   3. è¿›å…¥æ— é™å¾ªç¯ï¼š
      while not stopped:
        a. æ ¹æ®keyåˆ†å¸ƒç­–ç•¥é€‰æ‹©key
           - NO_KEY: key = None
           - RANDOM: key = random(0, 1000000)
           - ROUND_ROBIN: key = producer_index

        b. è°ƒç”¨ message_producer.send_message()
           - é€Ÿç‡é™åˆ¶ï¼ˆç­‰å¾…åˆ°æŒ‡å®šæ—¶é—´æ‰å‘é€ï¼‰
           - è®°å½•intended_send_timeï¼ˆé¢„æœŸå‘é€æ—¶é—´ï¼‰
           - å‘é€æ¶ˆæ¯ producer.send_async()
           - è®°å½•ç»Ÿè®¡ï¼ˆå»¶è¿Ÿã€ååé‡ï¼‰

        c. å¼‚å¸¸å¤„ç†ï¼ˆå¤±è´¥åsleep 0.1ç§’ï¼‰

   å…³é”®ï¼š
   - æ¯ä¸ªçº¿ç¨‹æœ‰ç‹¬ç«‹çš„é€Ÿç‡é™åˆ¶
   - producer_rate æ˜¯"æ¯ä¸ªproducer"çš„é€Ÿç‡ï¼Œä¸æ˜¯æ€»é€Ÿç‡
   - ä¾‹å¦‚ï¼š5ä¸ªproducers Ã— 1000 msg/s = 5000 msg/sæ€»é€Ÿç‡
   ```

7. **`adjust_publish_rate(publish_rate)`**
   ```python
   # åŠŸèƒ½ï¼šåŠ¨æ€è°ƒæ•´å‘é€é€Ÿç‡

   # ç”¨äºï¼š
   - è‡ªåŠ¨é€Ÿç‡æ¢æµ‹
   - burstæµ‹è¯•

   # å®ç°ï¼š
   - æ›´æ–° shared_publish_rateï¼ˆå¤šè¿›ç¨‹å…±äº«å˜é‡ï¼‰
   - å„ä¸ªç”Ÿäº§è€…çº¿ç¨‹ä¼šå®šæœŸæ£€æŸ¥å¹¶æ›´æ–°è‡ªå·±çš„é€Ÿç‡
   ```

8. **`message_received(payload, publish_timestamp)`**
   ```python
   # åŠŸèƒ½ï¼šæ¶ˆè´¹è€…å›è°ƒï¼ˆå®ç°ConsumerCallbackæ¥å£ï¼‰

   # ä½•æ—¶è°ƒç”¨ï¼Ÿ
   - å½“KafkaBenchmarkConsumeræ”¶åˆ°æ¶ˆæ¯æ—¶

   # å‚æ•°ï¼š
   - payload: æ¶ˆæ¯å†…å®¹ï¼ˆå­—èŠ‚æ•°ç»„ï¼‰
   - publish_timestamp: å‘é€æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰

   # æµç¨‹ï¼š
   1. è·å–å½“å‰æ—¶é—´ï¼ˆreceive_timestampï¼‰
   2. è®¡ç®—ç«¯åˆ°ç«¯å»¶è¿Ÿ = receive_timestamp - publish_timestamp
   3. è½¬æ¢ä¸ºå¾®ç§’ï¼ˆä¸Javaç‰ˆæœ¬ä¸€è‡´ï¼‰
   4. è°ƒç”¨ stats.record_message_received()

   # å…³é”®ï¼š
   - è¿™ä¸ªæ–¹æ³•åœ¨consumerçš„è¿›ç¨‹ä¸­è¢«è°ƒç”¨
   - é€šè¿‡multiprocessing.Queueä¼ é€’æ¶ˆæ¯åˆ°ä¸»è¿›ç¨‹
   ```

9. **`get_period_stats()`**
   ```python
   # åŠŸèƒ½ï¼šè·å–å‘¨æœŸç»Ÿè®¡ï¼ˆè‡ªä¸Šæ¬¡è°ƒç”¨ä»¥æ¥çš„å¢é‡ï¼‰

   # è¿”å›PeriodStatså¯¹è±¡ï¼ŒåŒ…å«ï¼š
   - messages_sent: å‘é€çš„æ¶ˆæ¯æ•°
   - bytes_sent: å‘é€çš„å­—èŠ‚æ•°
   - messages_received: æ¥æ”¶çš„æ¶ˆæ¯æ•°
   - publish_latency: å‘å¸ƒå»¶è¿Ÿç›´æ–¹å›¾ï¼ˆHDR Histogramï¼‰
   - end_to_end_latency: ç«¯åˆ°ç«¯å»¶è¿Ÿç›´æ–¹å›¾

   # æ³¨æ„ï¼š
   - è°ƒç”¨åä¼šé‡ç½®å‘¨æœŸç»Ÿè®¡ï¼ˆä½†ä¿ç•™ç´¯è®¡ç»Ÿè®¡ï¼‰
   - WorkloadGeneratoræ¯10ç§’è°ƒç”¨ä¸€æ¬¡
   ```

10. **`stop_all()`**
    ```python
    # åŠŸèƒ½ï¼šåœæ­¢æ‰€æœ‰æµ‹è¯•

    æµç¨‹ï¼š
    1. è®¾ç½® stop_producing æ ‡å¿—
    2. ç­‰å¾…æ‰€æœ‰producerçº¿ç¨‹ç»“æŸï¼ˆæœ€å¤š1ç§’ï¼‰
    3. å…³é—­æ‰€æœ‰producerï¼ˆflushå¾…å‘é€æ¶ˆæ¯ï¼‰
    4. å…³é—­æ‰€æœ‰consumer
    5. æ¸…ç©ºproducerå’Œconsumeråˆ—è¡¨

    # é‡è¦ï¼š
    - ç¡®ä¿æ¶ˆæ¯éƒ½å‘é€å®Œæ¯•ï¼ˆflushï¼‰
    - é¿å…æ•°æ®ä¸¢å¤±
    ```

**æ¶æ„è®¾è®¡ï¼š**
```
LocalWorker
  â”œâ”€â”€ benchmark_driver (KafkaBenchmarkDriver)
  â”‚     â”œâ”€â”€ create_topics()
  â”‚     â”œâ”€â”€ create_producers() â†’ [Producer1, Producer2...]
  â”‚     â””â”€â”€ create_consumers() â†’ [Consumer1, Consumer2...]
  â”‚
  â”œâ”€â”€ producer_threads (å¤šçº¿ç¨‹)
  â”‚     â”œâ”€â”€ Thread-0: _producer_worker_simple(Producer1)
  â”‚     â”œâ”€â”€ Thread-1: _producer_worker_simple(Producer2)
  â”‚     â””â”€â”€ ...
  â”‚
  â”œâ”€â”€ consumers (å¤šè¿›ç¨‹)
  â”‚     â”œâ”€â”€ Process-0: KafkaBenchmarkConsumer (åå°poll)
  â”‚     â”œâ”€â”€ Process-1: KafkaBenchmarkConsumer (åå°poll)
  â”‚     â””â”€â”€ ...  â†’ æ”¶åˆ°æ¶ˆæ¯ â†’ message_received() â†’ ç»Ÿè®¡
  â”‚
  â””â”€â”€ stats (WorkerStats)
        â”œâ”€â”€ messages_sent (åŸå­è®¡æ•°å™¨)
        â”œâ”€â”€ messages_received (åŸå­è®¡æ•°å™¨)
        â”œâ”€â”€ publish_latency (HDR Histogram)
        â””â”€â”€ end_to_end_latency (HDR Histogram)
```

---

### æ¨¡å—4ï¼šKafkaé©±åŠ¨æ¨¡å—

#### ğŸ“ `driver_kafka/kafka_benchmark_driver.py`

**æ ¸å¿ƒç±»ï¼š** `KafkaBenchmarkDriver`

**ä¸»è¦å±æ€§ï¼š**
```python
self.config                # é…ç½®å¯¹è±¡
self.producer_properties   # Produceré…ç½®ï¼ˆå­—å…¸ï¼‰
self.consumer_properties   # Consumeré…ç½®ï¼ˆå­—å…¸ï¼‰
self.admin                 # Kafkaç®¡ç†å®¢æˆ·ç«¯
self.producers             # Produceråˆ—è¡¨
self.consumers             # Consumeråˆ—è¡¨
```

**æ ¸å¿ƒæ–¹æ³•ï¼š**

1. **`initialize(config_file, stats_logger)`**
   ```python
   # åŠŸèƒ½ï¼šåˆå§‹åŒ–Kafkaé©±åŠ¨

   æµç¨‹ï¼š
   1. è¯»å–YAMLé…ç½®æ–‡ä»¶
   2. è§£æé…ç½®ï¼š
      - replicationFactor: å‰¯æœ¬æ•°
      - commonConfig: å…¬å…±é…ç½®ï¼ˆå¦‚bootstrap.serversï¼‰
      - producerConfig: ç”Ÿäº§è€…é…ç½®
      - consumerConfig: æ¶ˆè´¹è€…é…ç½®
      - topicConfig: ä¸»é¢˜é…ç½®

   3. åˆå¹¶é…ç½®ï¼š
      producer_properties = commonConfig + producerConfig
      consumer_properties = commonConfig + consumerConfig

   4. åˆ›å»ºAdminClientï¼ˆç”¨äºåˆ›å»ºtopicï¼‰

   é…ç½®æ–‡ä»¶ç¤ºä¾‹ï¼š
   commonConfig: |
     bootstrap.servers=localhost:9092
   producerConfig: |
     acks=1
     linger.ms=1
   consumerConfig: |
     auto.offset.reset=earliest
     enable.auto.commit=true
   ```

2. **`create_topics(topic_infos)`**
   ```python
   # åŠŸèƒ½ï¼šåˆ›å»ºKafkaä¸»é¢˜

   æµç¨‹ï¼š
   1. ä¸ºæ¯ä¸ªtopicåˆ›å»ºNewTopicå¯¹è±¡ï¼š
      - topicåç§°
      - partitionæ•°é‡
      - å‰¯æœ¬æ•°ï¼ˆreplicationFactorï¼‰
      - topicé…ç½®ï¼ˆå¦‚retention.msï¼‰

   2. è°ƒç”¨ admin.create_topics()
   3. ç­‰å¾…åˆ›å»ºå®Œæˆï¼ˆé˜»å¡ï¼‰
   4. å¤„ç†"topicå·²å­˜åœ¨"é”™è¯¯ï¼ˆå¿½ç•¥ï¼‰

   è¿”å›ï¼šFutureå¯¹è±¡ï¼ˆå¯ä»¥.result()è·å–ç»“æœï¼‰
   ```

3. **`create_producers(producer_infos)`**
   ```python
   # åŠŸèƒ½ï¼šåˆ›å»ºå¤šä¸ªProducer

   æµç¨‹ï¼š
   1. éå†producer_infosåˆ—è¡¨
   2. ä¸ºæ¯ä¸ªinfoåˆ›å»ºKafkaBenchmarkProducerï¼š
      - ä¼ å…¥topicåç§°
      - ä¼ å…¥producer_propertieså‰¯æœ¬
   3. æ·»åŠ åˆ°self.producersåˆ—è¡¨
   4. è¿”å›Futureï¼ˆç»“æœæ˜¯producersåˆ—è¡¨ï¼‰

   æ³¨æ„ï¼š
   - æ¯ä¸ªproduceræœ‰ç‹¬ç«‹çš„Kafka Producerå®ä¾‹
   - propertiesæ˜¯å‰¯æœ¬ï¼Œäº’ä¸å½±å“
   ```

4. **`create_consumers(consumer_infos)`**
   ```python
   # åŠŸèƒ½ï¼šåˆ›å»ºå¤šä¸ªConsumer

   æµç¨‹ï¼š
   1. éå†consumer_infosåˆ—è¡¨
   2. ä¸ºæ¯ä¸ªinfoåˆ›å»ºKafkaBenchmarkConsumerï¼š
      - topic: è¦è®¢é˜…çš„ä¸»é¢˜
      - subscription_name: æ¶ˆè´¹è€…ç»„åï¼ˆgroup.idï¼‰
      - properties: consumeré…ç½®
      - callback: æ¶ˆæ¯å›è°ƒï¼ˆLocalWorkerï¼‰
   3. æ·»åŠ åˆ°self.consumersåˆ—è¡¨
   4. è¿”å›Future

   é‡è¦ï¼š
   - æ¯ä¸ªconsumerç‹¬ç«‹è¿›ç¨‹
   - åŒä¸€ä¸ªsubscription_nameçš„consumerså±äºåŒä¸€ä¸ªæ¶ˆè´¹è€…ç»„
   - ä¼šè‡ªåŠ¨è¿›è¡Œpartitionåˆ†é…
   ```

5. **`close()`**
   ```python
   # åŠŸèƒ½ï¼šæ¸…ç†èµ„æº

   æµç¨‹ï¼š
   1. å…³é—­æ‰€æœ‰producersï¼ˆflushæ¶ˆæ¯ï¼‰
   2. å…³é—­æ‰€æœ‰consumers
   3. åˆ é™¤åˆ›å»ºçš„topicsï¼ˆä¿è¯å¹‚ç­‰æ€§ï¼‰

   ä¸ºä»€ä¹ˆåˆ é™¤topicsï¼Ÿ
   - é¿å…é‡å¤è¿è¡Œæ—¶topicå†²çª
   - ä¿è¯æ¯æ¬¡æµ‹è¯•ç¯å¢ƒå¹²å‡€
   ```

---

#### ğŸ“ `driver_kafka/kafka_benchmark_producer.py`

**æ ¸å¿ƒç±»ï¼š** `KafkaBenchmarkProducer`

**ä¸»è¦å±æ€§ï¼š**
```python
self.topic      # è¦å‘é€åˆ°çš„topic
self.producer   # confluent_kafka.Producerå®ä¾‹
```

**æ ¸å¿ƒæ–¹æ³•ï¼š**

1. **`send_async(key, payload)`**
   ```python
   # åŠŸèƒ½ï¼šå¼‚æ­¥å‘é€æ¶ˆæ¯

   # å‚æ•°ï¼š
   - key: æ¶ˆæ¯keyï¼ˆå­—ç¬¦ä¸²ï¼Œå¯ä»¥ä¸ºNoneï¼‰
   - payload: æ¶ˆæ¯å†…å®¹ï¼ˆå­—èŠ‚æ•°ç»„ï¼‰

   # æµç¨‹ï¼š
   1. åˆ›å»ºFutureResultå¯¹è±¡ï¼ˆæ¨¡æ‹ŸJavaçš„Futureï¼‰
   2. å®šä¹‰delivery_callbackï¼ˆå‘é€å®Œæˆå›è°ƒï¼‰
   3. è°ƒç”¨ producer.produce()ï¼š
      - topic: ç›®æ ‡ä¸»é¢˜
      - key: è½¬ä¸ºå­—èŠ‚ï¼ˆå¦‚æœä¸ä¸ºNoneï¼‰
      - value: payload
      - callback: delivery_callback
   4. è°ƒç”¨ producer.poll(0) å¤„ç†å›è°ƒï¼ˆéé˜»å¡ï¼‰
   5. è¿”å›FutureResult

   # FutureResultçš„ä½œç”¨ï¼š
   - å¯ä»¥æ·»åŠ done_callback
   - MessageProducerç”¨å®ƒæ¥è®°å½•å»¶è¿Ÿç»Ÿè®¡

   # ä¸ºä»€ä¹ˆå¼‚æ­¥ï¼Ÿ
   - é«˜æ€§èƒ½ï¼šä¸ç­‰å¾…Kafkaç¡®è®¤å°±è¿”å›
   - æ‰¹é‡å‘é€ï¼šKafkaä¼šè‡ªåŠ¨æ‰¹é‡
   - å›è°ƒå¤„ç†ï¼šå‘é€å®Œæˆåé€šè¿‡callbacké€šçŸ¥
   ```

2. **`close()`**
   ```python
   # åŠŸèƒ½ï¼šå…³é—­producer

   # æµç¨‹ï¼š
   1. è°ƒç”¨ producer.flush(10)
      - ç­‰å¾…æ‰€æœ‰å¾…å‘é€æ¶ˆæ¯å‘é€å®Œæ¯•
      - æœ€å¤šç­‰10ç§’
   2. å¿½ç•¥å¼‚å¸¸ï¼ˆé˜²æ­¢é‡å¤å…³é—­æŠ¥é”™ï¼‰

   # ä¸ºä»€ä¹ˆè¦flushï¼Ÿ
   - ç¡®ä¿æ¶ˆæ¯ä¸ä¸¢å¤±
   - Kafka produceræœ‰å†…éƒ¨ç¼“å†²åŒº
   - ä¸flushå¯èƒ½å¯¼è‡´æ¶ˆæ¯ä¸¢å¤±
   ```

**FutureResultç±»ï¼š**
```python
# è¿™æ˜¯ä¸€ä¸ªç®€å•çš„Futureå®ç°

class FutureResult:
    def __init__(self):
        self.completed = False          # æ˜¯å¦å®Œæˆ
        self.exception_value = None     # å¼‚å¸¸
        self._result = None             # ç»“æœ
        self._callbacks = []            # å›è°ƒåˆ—è¡¨

    def set_result(self, result):
        # è®¾ç½®ç»“æœï¼Œè§¦å‘å›è°ƒ

    def set_exception(self, exc):
        # è®¾ç½®å¼‚å¸¸ï¼Œè§¦å‘å›è°ƒ

    def add_done_callback(self, fn):
        # æ·»åŠ å®Œæˆå›è°ƒ
        # MessageProducerç”¨è¿™ä¸ªæ¥è®°å½•å»¶è¿Ÿ
```

---

#### ğŸ“ `driver_kafka/kafka_benchmark_consumer.py`

**æ ¸å¿ƒç±»ï¼š** `KafkaBenchmarkConsumer`

**æ¶æ„è®¾è®¡ï¼š**
```
KafkaBenchmarkConsumer
  â”œâ”€â”€ consumer_process (ç‹¬ç«‹è¿›ç¨‹)
  â”‚     â””â”€â”€ _consumer_loop_func()
  â”‚           â”œâ”€â”€ åˆ›å»ºKafka Consumer
  â”‚           â”œâ”€â”€ è®¢é˜…topic
  â”‚           â””â”€â”€ whileå¾ªç¯ï¼š
  â”‚                 â”œâ”€â”€ pollæ¶ˆæ¯
  â”‚                 â”œâ”€â”€ æ”¾å…¥message_queue
  â”‚                 â””â”€â”€ å®šæœŸcommit offset
  â”‚
  â””â”€â”€ callback_thread (å›è°ƒçº¿ç¨‹)
        â””â”€â”€ _callback_loop()
              â”œâ”€â”€ ä»message_queueå–æ¶ˆæ¯
              â””â”€â”€ è°ƒç”¨ callback.message_received()
```

**ä¸»è¦å±æ€§ï¼š**
```python
self.topic             # è®¢é˜…çš„topic
self.properties        # Consumeré…ç½®
self.callback          # æ¶ˆæ¯å›è°ƒï¼ˆLocalWorkerï¼‰
self.closing           # å…³é—­æ ‡å¿—ï¼ˆEventï¼‰
self.paused            # æš‚åœæ ‡å¿—ï¼ˆEventï¼‰
self.message_queue     # æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆè¿›ç¨‹é—´é€šä¿¡ï¼‰
self.consumer_process  # æ¶ˆè´¹è€…è¿›ç¨‹
self.callback_thread   # å›è°ƒçº¿ç¨‹
```

**æ ¸å¿ƒæ–¹æ³•ï¼š**

1. **`__init__(topic, subscription_name, properties, callback)`**
   ```python
   # åŠŸèƒ½ï¼šåˆå§‹åŒ–consumer

   æµç¨‹ï¼š
   1. è®¾ç½® group.id = subscription_name
      - è¿™æ ·åŒä¸€ä¸ªsubscriptionçš„consumerså±äºåŒä¸€ä¸ªæ¶ˆè´¹è€…ç»„
      - Kafkaä¼šè‡ªåŠ¨åˆ†é…partition

   2. åˆ›å»ºmultiprocessing.Eventæ ‡å¿—ï¼š
      - closing: æ˜¯å¦å…³é—­
      - paused: æ˜¯å¦æš‚åœ

   3. åˆ›å»ºmessage_queueï¼ˆè¿›ç¨‹é—´æ¶ˆæ¯é˜Ÿåˆ—ï¼‰
      - maxsize=1000ï¼ˆæœ€å¤šç¼“å­˜1000æ¡æ¶ˆæ¯ï¼‰

   4. å¯åŠ¨consumer_processï¼š
      - target: _consumer_loop_func
      - args: topic, properties, queue, closing, paused
      - daemon=Trueï¼ˆå®ˆæŠ¤è¿›ç¨‹ï¼‰

   5. å¯åŠ¨callback_threadï¼š
      - target: _callback_loop
      - daemon=Trueï¼ˆå®ˆæŠ¤çº¿ç¨‹ï¼‰

   # ä¸ºä»€ä¹ˆéœ€è¦ä¸¤ä¸ªç»„ä»¶ï¼Ÿ
   - consumer_process: ç‹¬ç«‹è¿›ç¨‹poll Kafkaï¼ˆé¿å…GILå½±å“ï¼‰
   - callback_thread: ä¸»è¿›ç¨‹å¤„ç†æ¶ˆæ¯ï¼ˆè®¿é—®statsç­‰å…±äº«æ•°æ®ï¼‰
   ```

2. **`_consumer_loop_func()` ï¼ˆå…¨å±€å‡½æ•°ï¼Œåœ¨ç‹¬ç«‹è¿›ç¨‹è¿è¡Œï¼‰**
   ```python
   # åŠŸèƒ½ï¼šæ¶ˆè´¹è€…å¾ªç¯ï¼ˆç‹¬ç«‹è¿›ç¨‹ï¼‰

   æµç¨‹ï¼š
   1. åˆ›å»ºConsumerå®ä¾‹
   2. è®¢é˜…topic: consumer.subscribe([topic])
   3. è¿›å…¥å¾ªç¯ï¼š
      while not closing:
        a. æ£€æŸ¥æ˜¯å¦æš‚åœï¼š
           if paused:
             consumer.pause(æ‰€æœ‰partitions)
             sleep(0.1)
             continue
           else:
             consumer.resume(æ‰€æœ‰partitions)

        b. Pollæ¶ˆæ¯ï¼š
           msg = consumer.poll(timeout=0.1)

        c. å¤„ç†æ¶ˆæ¯ï¼š
           if msg is not None and no error:
             - æå–timestampï¼ˆæ¯«ç§’ï¼‰
             - æ”¾å…¥message_queue: (payload, timestamp)

        d. å®šæœŸcommit offsetï¼ˆæ¯100æ¡æ¶ˆæ¯ï¼‰:
           message_count += 1
           if message_count >= 100:
             consumer.commit(asynchronous=True)
             message_count = 0

   4. é€€å‡ºæ—¶final commit:
      consumer.commit(asynchronous=False)
      consumer.close()

   # å…³é”®ç‚¹ï¼š
   - timestampæ˜¯Kafkaæ¶ˆæ¯çš„åŸå§‹æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
   - å¼‚æ­¥commitæé«˜æ€§èƒ½
   - æœ€åè¦åŒæ­¥commitç¡®ä¿offsetä¿å­˜
   ```

3. **`_callback_loop()` ï¼ˆåœ¨ä¸»è¿›ç¨‹çš„å›è°ƒçº¿ç¨‹è¿è¡Œï¼‰**
   ```python
   # åŠŸèƒ½ï¼šå›è°ƒå¾ªç¯ï¼ˆä¸»è¿›ç¨‹çº¿ç¨‹ï¼‰

   æµç¨‹ï¼š
   while not closing:
     1. ä»message_queueå–æ¶ˆæ¯ï¼ˆtimeout 0.1ç§’ï¼‰
     2. å¦‚æœå–åˆ°æ¶ˆæ¯ï¼š
        payload, timestamp = queue.get()
        callback.message_received(payload, timestamp)
     3. å¼‚å¸¸å¿½ç•¥ï¼ˆqueueç©ºæˆ–è¶…æ—¶ï¼‰

   # ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªçº¿ç¨‹ï¼Ÿ
   - consumer_processåœ¨ç‹¬ç«‹è¿›ç¨‹ï¼Œæ— æ³•ç›´æ¥è®¿é—®ä¸»è¿›ç¨‹æ•°æ®
   - é€šè¿‡queueä¼ é€’æ¶ˆæ¯åˆ°ä¸»è¿›ç¨‹
   - callback_threadåœ¨ä¸»è¿›ç¨‹ï¼Œå¯ä»¥è®¿é—®statsç­‰å…±äº«æ•°æ®
   ```

4. **`pause()` / `resume()`**
   ```python
   # åŠŸèƒ½ï¼šæš‚åœ/æ¢å¤æ¶ˆè´¹

   # ç”¨äºï¼šç§¯å‹æµ‹è¯•
   - pause(): è®¾ç½®pausedæ ‡å¿—
   - resume(): æ¸…é™¤pausedæ ‡å¿—

   # consumer_processä¼šæ£€æŸ¥pausedæ ‡å¿—ï¼š
   - æš‚åœæ—¶ï¼šè°ƒç”¨Kafka consumer.pause()
   - æ¢å¤æ—¶ï¼šè°ƒç”¨Kafka consumer.resume()
   ```

5. **`close()`**
   ```python
   # åŠŸèƒ½ï¼šå…³é—­consumer

   æµç¨‹ï¼š
   1. è®¾ç½®closingæ ‡å¿—
   2. ç­‰å¾…callback_threadç»“æŸï¼ˆæœ€å¤š2ç§’ï¼‰
   3. ç­‰å¾…consumer_processç»“æŸï¼ˆæœ€å¤š5ç§’ï¼‰
   4. å¦‚æœè¿›ç¨‹æœªç»“æŸï¼Œå¼ºåˆ¶terminate

   # ä¸ºä»€ä¹ˆè¦terminateï¼Ÿ
   - æœ‰æ—¶è¿›ç¨‹å¡åœ¨pollä¸­
   - éœ€è¦å¼ºåˆ¶ç»“æŸé¿å…æ­»é”
   ```

**æ—¶é—´æˆ³å¤„ç†ï¼š**
```python
# Kafkaæ¶ˆæ¯çš„timestampæœ‰3ç§ç±»å‹ï¼š
# 0 = TIMESTAMP_NOT_AVAILABLE (æ— æ—¶é—´æˆ³)
# 1 = CREATE_TIME (æ¶ˆæ¯åˆ›å»ºæ—¶é—´)
# 2 = LOG_APPEND_TIME (å†™å…¥æ—¥å¿—æ—¶é—´)

timestamp_type, timestamp_ms = msg.timestamp()
if timestamp_type != 0:
    publish_timestamp = timestamp_ms  # ä½¿ç”¨Kafkaçš„æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
else:
    publish_timestamp = 0             # æ— æ—¶é—´æˆ³ï¼Œè®¾ä¸º0

# MessageProduceråœ¨å‘é€æ—¶ä¼šè®¾ç½®CREATE_TIME
# æ‰€ä»¥è¿™é‡Œè·å–çš„æ˜¯æ¶ˆæ¯å‘é€æ—¶çš„æ—¶é—´æˆ³
```

---

### æ¨¡å—5ï¼šç»Ÿè®¡æ¨¡å—

#### ğŸ“ `worker/worker_stats.py`

**æ ¸å¿ƒç±»ï¼š** `WorkerStats`

**ä¸»è¦å±æ€§ï¼š**
```python
# åŸå­è®¡æ•°å™¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
self.messages_sent = AtomicLong()           # å‘¨æœŸå‘é€æ¶ˆæ¯æ•°
self.total_messages_sent = AtomicLong()     # æ€»å‘é€æ¶ˆæ¯æ•°
self.messages_received = AtomicLong()       # å‘¨æœŸæ¥æ”¶æ¶ˆæ¯æ•°
self.total_messages_received = AtomicLong() # æ€»æ¥æ”¶æ¶ˆæ¯æ•°
self.bytes_sent = AtomicLong()              # å‘¨æœŸå‘é€å­—èŠ‚æ•°
self.bytes_received = AtomicLong()          # å‘¨æœŸæ¥æ”¶å­—èŠ‚æ•°
self.message_send_errors = AtomicLong()     # å‘¨æœŸå‘é€é”™è¯¯æ•°

# HDR Histogramï¼ˆé«˜æ€§èƒ½å»¶è¿Ÿç»Ÿè®¡ï¼‰
self.publish_latency_recorder           # å‘å¸ƒå»¶è¿Ÿï¼ˆå¾®ç§’ï¼‰
self.publish_delay_latency_recorder     # å‘å¸ƒå»¶è¿Ÿï¼ˆå¾®ç§’ï¼Œqueueæ—¶é—´ï¼‰
self.end_to_end_latency_recorder        # ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆå¾®ç§’ï¼‰

# ç´¯è®¡ç›´æ–¹å›¾
self.cumulative_publish_latency_recorder
self.cumulative_publish_delay_latency_recorder
self.cumulative_end_to_end_latency_recorder
```

**æ ¸å¿ƒæ–¹æ³•ï¼š**

1. **`record_producer_success(payload_len, intended, sent, acked)`**
   ```python
   # åŠŸèƒ½ï¼šè®°å½•æˆåŠŸå‘é€

   # å‚æ•°ï¼ˆéƒ½æ˜¯çº³ç§’ï¼‰ï¼š
   - payload_len: æ¶ˆæ¯å¤§å°ï¼ˆå­—èŠ‚ï¼‰
   - intended: é¢„æœŸå‘é€æ—¶é—´
   - sent: å®é™…å‘é€æ—¶é—´
   - acked: æ”¶åˆ°ç¡®è®¤æ—¶é—´

   # è®¡ç®—ï¼š
   publish_delay = sent - intended           # å»¶è¿Ÿï¼ˆç­‰å¾…æ—¶é—´ï¼‰
   publish_latency = acked - sent            # å»¶è¿Ÿï¼ˆç½‘ç»œ+Kafkaå¤„ç†ï¼‰

   # è®°å½•ï¼š
   1. messages_sent += 1
   2. bytes_sent += payload_len
   3. publish_latency_recorder.record(latency_us)
   4. publish_delay_latency_recorder.record(delay_us)
   5. åŒæ—¶è®°å½•åˆ°cumulativeç›´æ–¹å›¾

   # å•ä½è½¬æ¢ï¼š
   - çº³ç§’ â†’ å¾®ç§’ï¼šé™¤ä»¥1000
   ```

2. **`record_message_received(payload_len, e2e_latency_us)`**
   ```python
   # åŠŸèƒ½ï¼šè®°å½•æ¶ˆæ¯æ¥æ”¶

   # å‚æ•°ï¼š
   - payload_len: æ¶ˆæ¯å¤§å°
   - e2e_latency_us: ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆå¾®ç§’ï¼‰

   # è®°å½•ï¼š
   1. messages_received += 1
   2. bytes_received += payload_len
   3. end_to_end_latency_recorder.record(e2e_latency_us)
   4. cumulative_end_to_end_latency_recorder.record(e2e_latency_us)
   ```

3. **`to_period_stats()`**
   ```python
   # åŠŸèƒ½ï¼šè·å–å‘¨æœŸç»Ÿè®¡ï¼ˆå¢é‡ï¼‰

   # æµç¨‹ï¼š
   1. è·å–å½“å‰å€¼
   2. åˆ›å»ºPeriodStatså¯¹è±¡
   3. é‡ç½®å‘¨æœŸè®¡æ•°å™¨ï¼ˆä½†ä¿ç•™totalå’Œcumulativeï¼‰

   # è¿”å›ï¼šPeriodStatså¯¹è±¡
   - messages_sent: è¿™ä¸ªå‘¨æœŸå‘é€çš„æ¶ˆæ¯æ•°
   - bytes_sent: è¿™ä¸ªå‘¨æœŸå‘é€çš„å­—èŠ‚æ•°
   - messages_received: è¿™ä¸ªå‘¨æœŸæ¥æ”¶çš„æ¶ˆæ¯æ•°
   - publish_latency: å‘å¸ƒå»¶è¿Ÿç›´æ–¹å›¾ï¼ˆå‘¨æœŸï¼‰
   - end_to_end_latency: ç«¯åˆ°ç«¯å»¶è¿Ÿç›´æ–¹å›¾ï¼ˆå‘¨æœŸï¼‰

   # é‡è¦ï¼š
   - è°ƒç”¨åä¼šé‡ç½®å‘¨æœŸç»Ÿè®¡
   - WorkloadGeneratoræ¯10ç§’è°ƒç”¨ä¸€æ¬¡
   ```

4. **`to_cumulative_latencies()`**
   ```python
   # åŠŸèƒ½ï¼šè·å–ç´¯è®¡å»¶è¿Ÿç»Ÿè®¡

   # è¿”å›ï¼šCumulativeLatencieså¯¹è±¡
   - publish_latency: ç´¯è®¡å‘å¸ƒå»¶è¿Ÿç›´æ–¹å›¾
   - publish_delay_latency: ç´¯è®¡å‘å¸ƒå»¶è¿Ÿç›´æ–¹å›¾
   - end_to_end_latency: ç´¯è®¡ç«¯åˆ°ç«¯å»¶è¿Ÿç›´æ–¹å›¾

   # ç”¨é€”ï¼š
   - æµ‹è¯•ç»“æŸæ—¶è·å–æ•´ä½“ç»Ÿè®¡
   - è®¡ç®—P50, P95, P99ç­‰ç™¾åˆ†ä½æ•°
   ```

**HDR Histogram è§£é‡Šï¼š**
```python
# HDR Histogramæ˜¯ä»€ä¹ˆï¼Ÿ
# High Dynamic Range Histogramï¼ˆé«˜åŠ¨æ€èŒƒå›´ç›´æ–¹å›¾ï¼‰
# ç”¨äºé«˜ç²¾åº¦ã€ä½å†…å­˜çš„å»¶è¿Ÿç»Ÿè®¡

# ä¸ºä»€ä¹ˆç”¨å®ƒï¼Ÿ
1. ç²¾åº¦é«˜ï¼šå¯ä»¥è®°å½•çº³ç§’åˆ°å°æ—¶çº§åˆ«çš„å»¶è¿Ÿ
2. å†…å­˜å°ï¼šå›ºå®šå¤§å°ï¼Œä¸éšæ ·æœ¬æ•°å¢é•¿
3. æ€§èƒ½å¥½ï¼šè®°å½•å’ŒæŸ¥è¯¢éƒ½æ˜¯O(1)
4. ç™¾åˆ†ä½å‡†ç¡®ï¼šP99.99ä¹Ÿå¾ˆå‡†ç¡®

# ä¸»è¦æ–¹æ³•ï¼š
histogram.record_value(value_us)        # è®°å½•ä¸€ä¸ªå€¼ï¼ˆå¾®ç§’ï¼‰
histogram.get_mean_value()              # å¹³å‡å€¼
histogram.get_value_at_percentile(99)   # P99
histogram.get_max_value()               # æœ€å¤§å€¼

# ç¼–ç /è§£ç ï¼ˆç”¨äºè¿›ç¨‹é—´ä¼ è¾“ï¼‰ï¼š
encoded = histogram.encode()            # ç¼–ç ä¸ºå­—èŠ‚
histogram = HdrHistogram.decode(encoded) # è§£ç 
```

---

### æ¨¡å—6ï¼šå·¥å…·æ¨¡å—

#### ğŸ“ `utils/uniform_rate_limiter.py`

**æ ¸å¿ƒç±»ï¼š** `UniformRateLimiter`

**åŠŸèƒ½ï¼š** ç²¾ç¡®æ§åˆ¶å‘é€é€Ÿç‡

**åŸç†ï¼š**
```python
# ç›®æ ‡ï¼šæ¯ç§’å‘1000æ¡æ¶ˆæ¯
# é‚£ä¹ˆä¸¤æ¡æ¶ˆæ¯ä¹‹é—´åº”è¯¥é—´éš”ï¼š1ç§’ / 1000 = 1æ¯«ç§’

# å®ç°ï¼š
1. è®°å½•ä¸Šæ¬¡å‘é€æ—¶é—´
2. è®¡ç®—ä¸‹æ¬¡åº”è¯¥å‘é€çš„æ—¶é—´ = ä¸Šæ¬¡æ—¶é—´ + é—´éš”
3. ç­‰å¾…åˆ°ä¸‹æ¬¡å‘é€æ—¶é—´
4. å‘é€æ¶ˆæ¯
```

**ä¸»è¦æ–¹æ³•ï¼š**

1. **`__init__(rate)`**
   ```python
   # å‚æ•°ï¼šrateï¼ˆæ¯ç§’æ¶ˆæ¯æ•°ï¼‰

   # è®¡ç®—ï¼š
   self.interval_ns = 1_000_000_000 / rate  # çº³ç§’é—´éš”
   self.next_send_time_ns = time.perf_counter_ns()

   ä¾‹å¦‚ï¼šrate = 1000
   interval_ns = 1_000_000 (1æ¯«ç§’)
   ```

2. **`acquire()`**
   ```python
   # åŠŸèƒ½ï¼šè·å–ä¸‹æ¬¡å‘é€æ—¶é—´ï¼ˆçº³ç§’ï¼‰

   # æµç¨‹ï¼š
   1. è®¡ç®— next_send_time = å½“å‰æ—¶é—´ + é—´éš”
   2. æ›´æ–° self.next_send_time_ns
   3. è¿”å› next_send_time

   # ä½¿ç”¨ï¼š
   intended_time = rate_limiter.acquire()
   while time.perf_counter_ns() < intended_time:
       pass  # å¿™ç­‰å¾…ï¼ˆbusy-waitï¼‰
   send_message()

   # ä¸ºä»€ä¹ˆå¿™ç­‰å¾…ï¼Ÿ
   - sleep()ä¸å¤Ÿç²¾ç¡®ï¼ˆæœ€å°1æ¯«ç§’ï¼‰
   - é«˜é€Ÿç‡éœ€è¦å¾®ç§’çº§ç²¾åº¦
   - å¿™ç­‰å¾…å¯ä»¥è¾¾åˆ°çº³ç§’çº§ç²¾åº¦
   ```

**å…³é”®è®¾è®¡ï¼š**
```python
# é—®é¢˜ï¼šå¦‚æœå¤„ç†å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ
# ä¾‹å¦‚ï¼šåº”è¯¥æ¯1mså‘ä¸€æ¡ï¼Œä½†å¤„ç†ç”¨äº†5ms

# è§£å†³ï¼š
- acquire()ä¸ä¼š"è¡¥å¿"ï¼Œè€Œæ˜¯ç»§ç»­æŒ‰ç…§å›ºå®šé—´éš”
- next_send_time æ€»æ˜¯é€’å¢ interval_ns
- è¿™æ ·å¯ä»¥ä¿æŒé•¿æœŸé€Ÿç‡ç¨³å®š

# ç¤ºä¾‹ï¼š
t0: acquire() â†’ next_send = t0 + 1ms
t5: acquire() â†’ next_send = t0 + 2ms (å·²ç»è¿‡äº†ï¼)
    â†’ ç«‹å³å‘é€
t5: acquire() â†’ next_send = t0 + 3ms
    â†’ ç­‰åˆ° t0 + 3ms
```

---

#### ğŸ“ `worker/message_producer.py`

**æ ¸å¿ƒç±»ï¼š** `MessageProducer`

**åŠŸèƒ½ï¼š** ç»Ÿä¸€çš„æ¶ˆæ¯å‘é€æ¥å£ï¼Œé›†æˆé€Ÿç‡é™åˆ¶å’Œç»Ÿè®¡

**ä¸»è¦å±æ€§ï¼š**
```python
self.rate_limiter  # UniformRateLimiterå®ä¾‹
self.stats         # WorkerStatså®ä¾‹
```

**æ ¸å¿ƒæ–¹æ³•ï¼š**

**`send_message(producer, key, payload)`**
```python
# åŠŸèƒ½ï¼šå‘é€ä¸€æ¡æ¶ˆæ¯ï¼ˆé›†æˆé€Ÿç‡é™åˆ¶å’Œç»Ÿè®¡ï¼‰

# æµç¨‹ï¼š
1. é€Ÿç‡é™åˆ¶ï¼š
   intended_send_time_ns = rate_limiter.acquire()
   while time.perf_counter_ns() < intended_send_time_ns:
       producer.producer.poll(0)  # å¤„ç†å›è°ƒï¼Œé¿å…ç©ºè½¬

2. è®°å½•å‘é€æ—¶é—´ï¼š
   send_time_ns = time.perf_counter_ns()

3. å‘é€æ¶ˆæ¯ï¼š
   future = producer.send_async(key, payload)

4. æ·»åŠ å›è°ƒï¼ˆè®°å½•ç»Ÿè®¡ï¼‰ï¼š
   def record_stats(f):
       ack_time_ns = time.perf_counter_ns()
       if f.exception():
           stats.record_producer_failure()
       else:
           stats.record_producer_success(
               len(payload),
               intended_send_time_ns,
               send_time_ns,
               ack_time_ns
           )

   future.add_done_callback(record_stats)

# å…³é”®ç‚¹ï¼š
- intended: é¢„æœŸå‘é€æ—¶é—´ï¼ˆé€Ÿç‡é™åˆ¶ç›®æ ‡ï¼‰
- send: å®é™…å‘é€æ—¶é—´
- ack: æ”¶åˆ°Kafkaç¡®è®¤æ—¶é—´
- å¯ä»¥åˆ†æï¼š
  - é€Ÿç‡é™åˆ¶å¼€é”€ = send - intended
  - Kafkaå»¶è¿Ÿ = ack - send
```

---

### æ¨¡å—7ï¼šé…ç½®ç±»

#### ğŸ“ `workload.py`

**æ ¸å¿ƒç±»ï¼š** `Workload`

**æ‰€æœ‰å±æ€§ï¼š**
```python
self.name = None                          # æµ‹è¯•åç§°
self.topics = 0                           # topicæ•°é‡
self.partitions_per_topic = 0             # æ¯ä¸ªtopicçš„partitionæ•°
self.key_distributor = None               # keyåˆ†å¸ƒç­–ç•¥ï¼ˆNO_KEY/RANDOM/ROUND_ROBINï¼‰
self.message_size = 0                     # æ¶ˆæ¯å¤§å°ï¼ˆå­—èŠ‚ï¼‰

# éšæœºpayloadé…ç½®
self.use_randomized_payloads = False      # æ˜¯å¦ä½¿ç”¨éšæœºpayload
self.random_bytes_ratio = 0.0             # éšæœºå­—èŠ‚æ¯”ä¾‹ï¼ˆæµ‹è¯•å‹ç¼©ï¼‰
self.randomized_payload_pool_size = 0     # payloadæ± å¤§å°

self.payload_file = None                  # payloadæ–‡ä»¶è·¯å¾„

# Producer/Consumeré…ç½®
self.subscriptions_per_topic = 0          # æ¯ä¸ªtopicçš„è®¢é˜…æ•°
self.producers_per_topic = 0              # æ¯ä¸ªtopicçš„produceræ•°
self.consumer_per_subscription = 0        # æ¯ä¸ªè®¢é˜…çš„consumeræ•°

self.producer_rate = 0                    # å‘é€é€Ÿç‡ï¼ˆ0=è‡ªåŠ¨æ¢æµ‹æœ€å¤§é€Ÿç‡ï¼‰

# ç§¯å‹æµ‹è¯•é…ç½®
self.consumer_backlog_size_gb = 0         # ç§¯å‹å¤§å°ï¼ˆGBï¼‰
self.backlog_drain_ratio = 1.0            # ç§¯å‹æ¸…ç©ºæ¯”ä¾‹ï¼ˆ1.0=100%ï¼‰

# æµ‹è¯•æ—¶é•¿
self.test_duration_minutes = 0            # æµ‹è¯•æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
self.warmup_duration_minutes = 1          # é¢„çƒ­æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
```

**é…ç½®ç¤ºä¾‹ï¼š**
```yaml
name: high-throughput-test
topics: 4                        # 4ä¸ªtopics
partitionsPerTopic: 16           # æ¯ä¸ªtopic 16ä¸ªpartitions
keyDistributor: RANDOM           # éšæœºkeyåˆ†å¸ƒ
messageSize: 1024                # 1KBæ¶ˆæ¯
subscriptionsPerTopic: 1         # æ¯ä¸ªtopic 1ä¸ªè®¢é˜…
producersPerTopic: 10            # æ¯ä¸ªtopic 10ä¸ªproducers
consumerPerSubscription: 40      # æ¯ä¸ªè®¢é˜… 40ä¸ªconsumers
producerRate: 10000              # æ¯ä¸ªproducer 10000 msg/s
testDurationMinutes: 10          # æµ‹è¯•10åˆ†é’Ÿ
warmupDurationMinutes: 2         # é¢„çƒ­2åˆ†é’Ÿ

# è®¡ç®—ï¼š
# æ€»producers = 4 topics Ã— 10 = 40ä¸ª
# æ€»consumers = 4 topics Ã— 1 subscription Ã— 40 = 160ä¸ª
# æ€»å‘é€é€Ÿç‡ = 40 producers Ã— 10000 = 400000 msg/s
```

---

#### ğŸ“ `driver_configuration.py`

**æ ¸å¿ƒç±»ï¼š** `DriverConfiguration`

**å±æ€§ï¼š**
```python
self.name = None          # é©±åŠ¨åç§°ï¼ˆå¦‚"Kafka"ï¼‰
self.driver_class = None  # é©±åŠ¨ç±»è·¯å¾„
```

**é…ç½®ç¤ºä¾‹ï¼š**
```yaml
name: Kafka
driverClass: benchmark.driver_kafka.kafka_benchmark_driver.KafkaBenchmarkDriver
replicationFactor: 3
commonConfig: |
  bootstrap.servers=localhost:9092
producerConfig: |
  acks=1
  linger.ms=1
  batch.size=16384
consumerConfig: |
  auto.offset.reset=earliest
  enable.auto.commit=true
```

---

## æ–‡ä»¶ç»“æ„å¯¼èˆª

### ğŸ“‚ å®Œæ•´ç›®å½•æ ‘

```
openmessaging-benchmark/
â”‚
â”œâ”€â”€ benchmark/                          # æ ¸å¿ƒä»£ç ç›®å½•
â”‚   â”œâ”€â”€ __init__.py                     # åŒ…åˆå§‹åŒ–ï¼ˆå¯¼å‡ºæ ¸å¿ƒç±»ï¼‰
â”‚   â”œâ”€â”€ __main__.py                     # ç¨‹åºå…¥å£ï¼ˆpython -m benchmarkï¼‰
â”‚   â”œâ”€â”€ benchmark.py                    # ä¸»ç¨‹åºï¼ˆBenchmarkç±»ï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ é…ç½®ç±»
â”‚   â”œâ”€â”€ workload.py                     # å·¥ä½œè´Ÿè½½é…ç½®
â”‚   â”œâ”€â”€ driver_configuration.py         # é©±åŠ¨é…ç½®
â”‚   â”œâ”€â”€ workers.py                      # Workeré…ç½®
â”‚   â”‚
â”‚   â”œâ”€â”€ æ ¸å¿ƒç»„ä»¶
â”‚   â”œâ”€â”€ workload_generator.py           # è´Ÿè½½ç”Ÿæˆå™¨ï¼ˆæ ¸å¿ƒï¼ï¼‰
â”‚   â”œâ”€â”€ rate_controller.py              # é€Ÿç‡æ§åˆ¶å™¨
â”‚   â”œâ”€â”€ test_result.py                  # æµ‹è¯•ç»“æœç±»
â”‚   â”œâ”€â”€ results_to_csv.py               # ç»“æœè½¬CSV
â”‚   â”‚
â”‚   â”œâ”€â”€ worker/                         # Workeræ¡†æ¶
â”‚   â”‚   â”œâ”€â”€ worker.py                   # Workeræ¥å£ï¼ˆæŠ½è±¡ç±»ï¼‰
â”‚   â”‚   â”œâ”€â”€ local_worker.py             # æœ¬åœ°Workerï¼ˆæ ¸å¿ƒï¼ï¼‰
â”‚   â”‚   â”œâ”€â”€ distributed_workers_ensemble.py  # åˆ†å¸ƒå¼Worker
â”‚   â”‚   â”œâ”€â”€ http_worker_client.py       # HTTPå®¢æˆ·ç«¯
â”‚   â”‚   â”œâ”€â”€ benchmark_worker.py         # WorkeræœåŠ¡ç«¯
â”‚   â”‚   â”œâ”€â”€ worker_handler.py           # HTTPå¤„ç†å™¨
â”‚   â”‚   â”œâ”€â”€ worker_stats.py             # ç»Ÿè®¡ç±»ï¼ˆæ ¸å¿ƒï¼ï¼‰
â”‚   â”‚   â”œâ”€â”€ message_producer.py         # æ¶ˆæ¯å‘é€å™¨
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ commands/                   # å‘½ä»¤å¯¹è±¡ï¼ˆæ•°æ®ä¼ è¾“ï¼‰
â”‚   â”‚       â”œâ”€â”€ consumer_assignment.py
â”‚   â”‚       â”œâ”€â”€ producer_work_assignment.py
â”‚   â”‚       â”œâ”€â”€ counters_stats.py
â”‚   â”‚       â”œâ”€â”€ period_stats.py
â”‚   â”‚       â”œâ”€â”€ cumulative_latencies.py
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ driver/                         # é©±åŠ¨æ¥å£
â”‚   â”‚   â”œâ”€â”€ benchmark_driver.py         # é©±åŠ¨æ¥å£ï¼ˆæŠ½è±¡ç±»ï¼‰
â”‚   â”‚   â”œâ”€â”€ benchmark_producer.py       # Produceræ¥å£
â”‚   â”‚   â”œâ”€â”€ benchmark_consumer.py       # Consumeræ¥å£
â”‚   â”‚   â”œâ”€â”€ consumer_callback.py        # æ¶ˆè´¹è€…å›è°ƒæ¥å£
â”‚   â”‚   â””â”€â”€ resource_creator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ driver_kafka/                   # Kafkaé©±åŠ¨å®ç°
â”‚   â”‚   â”œâ”€â”€ kafka_benchmark_driver.py   # Kafkaé©±åŠ¨ï¼ˆæ ¸å¿ƒï¼ï¼‰
â”‚   â”‚   â”œâ”€â”€ kafka_benchmark_producer.py # Kafka Producer
â”‚   â”‚   â”œâ”€â”€ kafka_benchmark_consumer.py # Kafka Consumer
â”‚   â”‚   â””â”€â”€ config.py                   # é…ç½®ç±»
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                          # å·¥å…·ç±»
â”‚   â”‚   â”œâ”€â”€ uniform_rate_limiter.py     # é€Ÿç‡é™åˆ¶å™¨ï¼ˆæ ¸å¿ƒï¼ï¼‰
â”‚   â”‚   â”œâ”€â”€ timer.py                    # è®¡æ—¶å™¨
â”‚   â”‚   â”œâ”€â”€ random_generator.py         # éšæœºæ•°ç”Ÿæˆå™¨
â”‚   â”‚   â”œâ”€â”€ padding_decimal_format.py   # æ•°å­—æ ¼å¼åŒ–
â”‚   â”‚   â”œâ”€â”€ list_partition.py           # åˆ—è¡¨åˆ†åŒº
â”‚   â”‚   â”œâ”€â”€ env.py                      # ç¯å¢ƒå˜é‡
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ distributor/                # Keyåˆ†å¸ƒç­–ç•¥
â”‚   â”‚   â”‚   â”œâ”€â”€ key_distributor_type.py
â”‚   â”‚   â”‚   â”œâ”€â”€ no_key_distributor.py
â”‚   â”‚   â”‚   â”œâ”€â”€ key_round_robin.py
â”‚   â”‚   â”‚   â””â”€â”€ random_nano.py
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ payload/                    # Payloadå¤„ç†
â”‚   â”‚       â”œâ”€â”€ payload_reader.py
â”‚   â”‚       â”œâ”€â”€ file_payload_reader.py
â”‚   â”‚       â””â”€â”€ payload_exception.py
â”‚   â”‚
â”‚   â””â”€â”€ tool/                           # å·¥å…·ï¼ˆç”Ÿæˆworkloadé…ç½®ï¼‰
â”‚       â”œâ”€â”€ workload_generator.py
â”‚       â”œâ”€â”€ workload_generation_tool.py
â”‚       â””â”€â”€ workload_set_template.py
â”‚
â”œâ”€â”€ examples/                           # ç¤ºä¾‹é…ç½®
â”‚   â”œâ”€â”€ kafka-driver.yaml               # Kafkaé©±åŠ¨é…ç½®
â”‚   â”œâ”€â”€ simple-workload.yaml            # ç®€å•å·¥ä½œè´Ÿè½½
â”‚   â””â”€â”€ workers.yaml                    # Workeré…ç½®
â”‚
â”œâ”€â”€ requirements.txt                    # Pythonä¾èµ–
â”œâ”€â”€ setup.py                            # å®‰è£…è„šæœ¬
â””â”€â”€ README.md                           # è¯´æ˜æ–‡æ¡£
```

### ğŸ” å¿«é€ŸæŸ¥æ‰¾æŒ‡å—

**æƒ³äº†è§£æŸä¸ªåŠŸèƒ½ï¼Œçœ‹å“ªä¸ªæ–‡ä»¶ï¼Ÿ**

| åŠŸèƒ½ | æ–‡ä»¶ | è¯´æ˜ |
|------|------|------|
| ç¨‹åºå¦‚ä½•å¯åŠ¨ | `benchmark.py` | ä¸»ç¨‹åºå…¥å£ |
| å¦‚ä½•ç”Ÿæˆè´Ÿè½½ | `workload_generator.py` | è´Ÿè½½ç”Ÿæˆé€»è¾‘ |
| å¦‚ä½•å‘é€æ¶ˆæ¯ | `local_worker.py` | ç”Ÿäº§è€…çº¿ç¨‹é€»è¾‘ |
| å¦‚ä½•æ¥æ”¶æ¶ˆæ¯ | `kafka_benchmark_consumer.py` | æ¶ˆè´¹è€…è¿›ç¨‹é€»è¾‘ |
| å¦‚ä½•é™é€Ÿ | `uniform_rate_limiter.py` | ç²¾ç¡®é€Ÿç‡æ§åˆ¶ |
| å¦‚ä½•ç»Ÿè®¡ | `worker_stats.py` | å»¶è¿Ÿã€ååé‡ç»Ÿè®¡ |
| å¦‚ä½•è¿æ¥Kafka | `kafka_benchmark_driver.py` | Kafkaäº¤äº’ |
| é…ç½®å‚æ•°å«ä¹‰ | `workload.py` | æ‰€æœ‰å¯é…ç½®å‚æ•° |

---

## å¸¸è§é—®é¢˜è§£ç­”

### Q1: Producerå’ŒConsumeræ˜¯æ€ä¹ˆå¯¹åº”çš„ï¼Ÿ

**ç­”ï¼š** é€šè¿‡Topicå’ŒConsumerGroup

```
Topic: test-topic-0
  â”œâ”€â”€ Partition-0
  â”œâ”€â”€ Partition-1
  â”œâ”€â”€ Partition-2
  â””â”€â”€ Partition-3

Producers (10ä¸ª):
  â†’ å‘é€åˆ° test-topic-0
  â†’ Kafkaæ ¹æ®keyåˆ†é…åˆ°ä¸åŒpartition

ConsumerGroup: sub-001
  Consumers (4ä¸ª):
    â†’ Consumer-0 åˆ†é…åˆ° Partition-0
    â†’ Consumer-1 åˆ†é…åˆ° Partition-1
    â†’ Consumer-2 åˆ†é…åˆ° Partition-2
    â†’ Consumer-3 åˆ†é…åˆ° Partition-3

# å¦‚æœconsumeræ•° > partitionæ•°ï¼š
# å¤šä½™çš„consumerä¼šé—²ç½®

# å¦‚æœconsumeræ•° < partitionæ•°ï¼š
# ä¸€ä¸ªconsumerä¼šå¤„ç†å¤šä¸ªpartitions
```

### Q2: ä¸ºä»€ä¹ˆç”¨å¤šçº¿ç¨‹producer + å¤šè¿›ç¨‹consumerï¼Ÿ

**ç­”ï¼š**

```
Producerç”¨å¤šçº¿ç¨‹ï¼š
  - éœ€è¦å…±äº«statsï¼ˆç»Ÿè®¡æ•°æ®ï¼‰
  - Pythonçš„GILå¯¹å‘é€å½±å“å°ï¼ˆI/Oæ“ä½œä¼šé‡Šæ”¾GILï¼‰
  - çº¿ç¨‹é—´é€šä¿¡å¿«ï¼ˆå…±äº«å†…å­˜ï¼‰

Consumerç”¨å¤šè¿›ç¨‹ï¼š
  - é¿å…GILå½±å“ï¼ˆpollæ˜¯CPUå¯†é›†ï¼‰
  - éš”ç¦»æ€§å¥½ï¼ˆä¸€ä¸ªconsumerå´©æºƒä¸å½±å“å…¶ä»–ï¼‰
  - é€šè¿‡Queueé€šä¿¡ï¼ˆmessage_queueï¼‰
```

### Q3: å»¶è¿Ÿæ˜¯æ€ä¹ˆè®¡ç®—çš„ï¼Ÿ

**ç­”ï¼š**

```python
# 1. å‘å¸ƒå»¶è¿Ÿ (Publish Latency)
intended_time  = rate_limiter.acquire()  # é¢„æœŸå‘é€æ—¶é—´
send_time      = actual_send()           # å®é™…å‘é€æ—¶é—´
ack_time       = kafka_ack()             # æ”¶åˆ°Kafkaç¡®è®¤æ—¶é—´

publish_delay_latency = send_time - intended_time  # ç­‰å¾…æ—¶é—´
publish_latency = ack_time - send_time             # Kafkaå¤„ç†æ—¶é—´

# 2. ç«¯åˆ°ç«¯å»¶è¿Ÿ (End-to-End Latency)
publish_timestamp = æ¶ˆæ¯å‘é€æ—¶é—´ï¼ˆå­˜åœ¨æ¶ˆæ¯ä¸­ï¼‰
receive_timestamp = consumeræ¥æ”¶æ—¶é—´

end_to_end_latency = receive_timestamp - publish_timestamp

# å•ä½ï¼š
- å†…éƒ¨è®¡ç®—ï¼šçº³ç§’ (ns)
- è®°å½•åˆ°Histogramï¼šå¾®ç§’ (Î¼s)
- æ˜¾ç¤ºç»™ç”¨æˆ·ï¼šæ¯«ç§’ (ms)
```

### Q4: å¦‚ä½•ç†è§£æµ‹è¯•ç»“æœï¼Ÿ

**ç­”ï¼š**

```json
{
  "publishRate": [10000, 10050, 9980, ...],  // æ¯10ç§’çš„å‘é€é€Ÿç‡
  "consumeRate": [9800, 10020, 9950, ...],   // æ¯10ç§’çš„æ¥æ”¶é€Ÿç‡
  "backlog": [0, 200, 150, ...],             // æ¯10ç§’çš„ç§¯å‹æ¶ˆæ¯æ•°

  // å‘¨æœŸå»¶è¿Ÿï¼ˆæ¯10ç§’ï¼‰
  "publishLatencyAvg": [1.2, 1.3, 1.1, ...],      // å¹³å‡å»¶è¿Ÿ(ms)
  "publishLatency99pct": [5.2, 5.5, 5.0, ...],    // P99å»¶è¿Ÿ(ms)

  // èšåˆå»¶è¿Ÿï¼ˆæ•´ä¸ªæµ‹è¯•ï¼‰
  "aggregatedPublishLatency50pct": 1.1,           // P50å»¶è¿Ÿ
  "aggregatedPublishLatency95pct": 3.5,           // P95å»¶è¿Ÿ
  "aggregatedPublishLatency99pct": 5.2,           // P99å»¶è¿Ÿ
  "aggregatedPublishLatency999pct": 12.3,         // P99.9å»¶è¿Ÿ

  // å…³é”®æŒ‡æ ‡
  "messageSize": 1024,          // æ¶ˆæ¯å¤§å°
  "topics": 1,                  // topicæ•°é‡
  "partitions": 16,             // partitionæ•°é‡
  "producersPerTopic": 10,      // æ¯topicçš„produceræ•°
  "consumersPerTopic": 40       // æ¯topicçš„consumeræ•°
}
```

**å¦‚ä½•åˆ¤æ–­æµ‹è¯•å¥½åï¼Ÿ**

1. **ååé‡ç¨³å®š**ï¼špublishRateå’ŒconsumeRateæ¥è¿‘ä¸”ç¨³å®š
2. **ç§¯å‹ä¸º0**ï¼šbacklogæ¥è¿‘0ï¼ˆè¯´æ˜æ¶ˆè´¹é€Ÿåº¦è·Ÿå¾—ä¸Šï¼‰
3. **å»¶è¿Ÿä½**ï¼š
   - P50 < 10msï¼šå¾ˆå¥½
   - P99 < 50msï¼šè‰¯å¥½
   - P99.9 < 100msï¼šå¯æ¥å—
4. **æ²¡æœ‰é”™è¯¯**ï¼špublishErrorRate = 0

---

## æ€»ç»“

### ğŸ¯ é¡¹ç›®æ ¸å¿ƒæµç¨‹

```
1. ç”¨æˆ·é…ç½® (workload.yaml + driver.yaml)
     â†“
2. Benchmarkè¯»å–é…ç½®
     â†“
3. åˆ›å»ºWorkerï¼ˆLocalWorkerï¼‰
     â†“
4. åˆå§‹åŒ–Driverï¼ˆKafkaBenchmarkDriverï¼‰
     â†“
5. WorkloadGeneratoråˆ›å»ºTopics/Producers/Consumers
     â†“
6. å¯åŠ¨è´Ÿè½½ï¼š
   - å¤šä¸ªç”Ÿäº§è€…çº¿ç¨‹å‘é€æ¶ˆæ¯ï¼ˆé€Ÿç‡é™åˆ¶ï¼‰
   - å¤šä¸ªæ¶ˆè´¹è€…è¿›ç¨‹æ¥æ”¶æ¶ˆæ¯ï¼ˆåå°pollï¼‰
   - æŒç»­æ”¶é›†ç»Ÿè®¡ï¼ˆå»¶è¿Ÿã€ååé‡ï¼‰
     â†“
7. æµ‹è¯•ç»“æŸï¼Œä¿å­˜ç»“æœï¼ˆJSONæ–‡ä»¶ï¼‰
```

### ğŸ”‘ å…³é”®æŠ€æœ¯ç‚¹

1. **å¤šçº¿ç¨‹ç”Ÿäº§è€…**ï¼šæ¯ä¸ªproducerä¸€ä¸ªçº¿ç¨‹ï¼Œç‹¬ç«‹é€Ÿç‡é™åˆ¶
2. **å¤šè¿›ç¨‹æ¶ˆè´¹è€…**ï¼šæ¯ä¸ªconsumerä¸€ä¸ªè¿›ç¨‹ï¼Œé€šè¿‡Queueé€šä¿¡
3. **ç²¾ç¡®é€Ÿç‡æ§åˆ¶**ï¼šçº³ç§’çº§UniformRateLimiterï¼Œå¿™ç­‰å¾…
4. **é«˜ç²¾åº¦ç»Ÿè®¡**ï¼šHDR Histogramï¼Œæ”¯æŒP99.99ç»Ÿè®¡
5. **å¼‚æ­¥å‘é€**ï¼šKafka Producerå¼‚æ­¥å‘é€ï¼Œå›è°ƒè®°å½•ç»Ÿè®¡
6. **åŠ¨æ€é€Ÿç‡è°ƒæ•´**ï¼šRateControllerè‡ªåŠ¨æ¢æµ‹æœ€å¤§é€Ÿç‡

### ğŸ“– é˜…è¯»å»ºè®®

**ç¬¬ä¸€éé˜…è¯»ï¼ˆç†è§£æµç¨‹ï¼‰ï¼š**
1. `benchmark.py` - äº†è§£ä¸»æµç¨‹
2. `workload_generator.py` - äº†è§£æµ‹è¯•å¦‚ä½•æ‰§è¡Œ
3. `local_worker.py` - äº†è§£æ¶ˆæ¯å¦‚ä½•å‘é€/æ¥æ”¶

**ç¬¬äºŒéé˜…è¯»ï¼ˆç†è§£ç»†èŠ‚ï¼‰ï¼š**
1. `kafka_benchmark_driver.py` - Kafkaäº¤äº’
2. `kafka_benchmark_producer.py` - å¼‚æ­¥å‘é€æœºåˆ¶
3. `kafka_benchmark_consumer.py` - å¤šè¿›ç¨‹æ¶ˆè´¹æœºåˆ¶
4. `worker_stats.py` - ç»Ÿè®¡å®ç°

**ç¬¬ä¸‰éé˜…è¯»ï¼ˆç†è§£å·¥å…·ï¼‰ï¼š**
1. `uniform_rate_limiter.py` - é€Ÿç‡æ§åˆ¶ç®—æ³•
2. `message_producer.py` - å‘é€å°è£…
3. `rate_controller.py` - åŠ¨æ€é€Ÿç‡è°ƒæ•´

---

## é™„å½•ï¼šæ ¸å¿ƒç®—æ³•

### é€Ÿç‡é™åˆ¶ç®—æ³•

```python
class UniformRateLimiter:
    def __init__(self, rate):
        # è®¡ç®—æ¶ˆæ¯é—´éš”ï¼ˆçº³ç§’ï¼‰
        self.interval_ns = 1_000_000_000 / rate
        self.next_send_time_ns = time.perf_counter_ns()

    def acquire(self):
        # è¿”å›ä¸‹æ¬¡åº”è¯¥å‘é€çš„æ—¶é—´
        current = self.next_send_time_ns
        self.next_send_time_ns += self.interval_ns
        return current

# ä½¿ç”¨ï¼š
limiter = UniformRateLimiter(1000)  # 1000 msg/s
while True:
    intended = limiter.acquire()
    # å¿™ç­‰å¾…åˆ°æŒ‡å®šæ—¶é—´
    while time.perf_counter_ns() < intended:
        pass
    send_message()
```

### åŠ¨æ€é€Ÿç‡è°ƒæ•´ç®—æ³•

```python
def next_rate(current_rate, period_ns, sent, received):
    # ç›®æ ‡ï¼šæ¶ˆè´¹é€Ÿåº¦ = ç”Ÿäº§é€Ÿåº¦

    send_rate = sent / (period_ns / 1e9)
    receive_rate = received / (period_ns / 1e9)

    # å¦‚æœæ¶ˆè´¹é€Ÿåº¦ > ç”Ÿäº§é€Ÿåº¦ï¼šæé«˜é€Ÿç‡
    if receive_rate > send_rate * 1.05:
        return current_rate * 1.1

    # å¦‚æœæ¶ˆè´¹é€Ÿåº¦ < ç”Ÿäº§é€Ÿåº¦ï¼šé™ä½é€Ÿç‡
    elif receive_rate < send_rate * 0.95:
        return current_rate * 0.9

    # å¦åˆ™ï¼šä¿æŒä¸å˜
    else:
        return current_rate
```

### ç«¯åˆ°ç«¯å»¶è¿Ÿè®¡ç®—

```python
# Producerç«¯ï¼š
timestamp_ms = int(time.time() * 1000)  # æ¯«ç§’æ—¶é—´æˆ³
message = create_message(payload, timestamp=timestamp_ms)
send_to_kafka(message)

# Consumerç«¯ï¼š
message = poll_from_kafka()
publish_timestamp_ms = message.timestamp()
receive_timestamp_ms = int(time.time() * 1000)

e2e_latency_ms = receive_timestamp_ms - publish_timestamp_ms
e2e_latency_us = e2e_latency_ms * 1000  # è½¬ä¸ºå¾®ç§’

# è®°å½•åˆ°Histogram
histogram.record_value(e2e_latency_us)
```

---

å¸Œæœ›è¿™ä»½æ–‡æ¡£èƒ½å¸®åŠ©æ‚¨ç†è§£æ•´ä¸ªé¡¹ç›®ï¼å¦‚æœæœ‰ä»»ä½•ä¸æ¸…æ¥šçš„åœ°æ–¹ï¼Œéƒ½å¯ä»¥å†é—®æˆ‘ã€‚ç¥æ‚¨é˜…è¯»æ„‰å¿«ï¼ğŸ‰
