# OpenMessaging Benchmark 项目详解文档

> 这份文档会详细解释这个项目的每个部分，帮助您轻松理解整个系统。

---

## 📚 目录

1. [项目概述](#项目概述)
2. [整体架构](#整体架构)
3. [核心概念](#核心概念)
4. [代码执行流程](#代码执行流程)
5. [各模块详解](#各模块详解)
6. [文件结构导航](#文件结构导航)

---

## 项目概述

### 🎯 这个项目是干什么的？

这是一个**消息系统性能测试工具**，可以测试 Kafka 等消息队列的性能。

**打个比方：**
- 就像汽车厂要测试汽车的性能（最高时速、油耗等）
- 这个工具就是测试消息系统的"性能"（每秒能发多少消息、延迟多少）

### 📊 能测什么？

1. **吞吐量**：每秒能发多少条消息
2. **延迟**：消息从发送到接收要多久
3. **错误率**：发送失败的比例
4. **积压处理**：当消息堆积时的处理能力

### 🔧 怎么用？

```bash
python -m benchmark \
  -d kafka-driver.yaml \      # Kafka配置文件
  simple-workload.yaml        # 测试任务配置
```

---

## 整体架构

### 📦 四层架构

```
┌─────────────────────────────────────────────────┐
│         1. 主程序层 (Benchmark)                  │
│    负责：读配置、启动测试、收集结果               │
└─────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────┐
│     2. 负载生成层 (WorkloadGenerator)            │
│    负责：创建生产者/消费者、控制发送速率          │
└─────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────┐
│         3. Worker层 (LocalWorker)               │
│    负责：实际执行发送/接收、统计数据              │
└─────────────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────┐
│       4. 驱动层 (KafkaBenchmarkDriver)          │
│    负责：与Kafka交互（发消息、收消息）            │
└─────────────────────────────────────────────────┘
```

### 🔄 数据流向

```
配置文件 → Benchmark读取 → WorkloadGenerator创建任务
  → LocalWorker执行 → Kafka驱动发送/接收
    → 统计结果 → 保存JSON文件
```

---

## 核心概念

### 1️⃣ Workload（工作负载）

**定义：** 测试的参数配置

**包含什么：**
- `topics`: 创建几个主题
- `partitionsPerTopic`: 每个主题几个分区
- `messageSize`: 消息大小（字节）
- `producerRate`: 每秒发多少消息（0=最大速率）
- `testDurationMinutes`: 测试多久

**举例：**
```yaml
name: simple-test
topics: 1                    # 创建1个主题
partitionsPerTopic: 1        # 每个主题1个分区
messageSize: 1024            # 消息1KB
producerRate: 1000           # 每秒1000条消息
testDurationMinutes: 5       # 测试5分钟
```

### 2️⃣ Driver（驱动）

**定义：** 与具体消息系统（如Kafka）交互的代码

**职责：**
- 创建Topic
- 创建Producer（生产者）
- 创建Consumer（消费者）
- 发送消息
- 接收消息

### 3️⃣ Worker（工作节点）

**定义：** 执行实际测试的工作进程

**两种模式：**
1. **LocalWorker** - 本地模式（单机测试）
2. **DistributedWorker** - 分布式模式（多机测试）

### 4️⃣ Producer & Consumer

**Producer（生产者）：** 发送消息的组件
**Consumer（消费者）：** 接收消息的组件

---

## 代码执行流程

### 🚀 完整流程（一步一步）

#### 第1步：程序启动
```
用户运行命令
  ↓
__main__.py 接收参数
  ↓
调用 Benchmark.main()
```

#### 第2步：读取配置
```
Benchmark.main()
  ↓
读取 workload.yaml（测试配置）
读取 driver.yaml（Kafka配置）
读取 workers.yaml（Worker配置，可选）
```

#### 第3步：创建Worker
```
如果有workers配置 → 创建 DistributedWorkersEnsemble（分布式）
如果没有 → 创建 LocalWorker（本地）
```

#### 第4步：初始化Driver
```
LocalWorker.initialize_driver()
  ↓
读取driver配置文件
  ↓
动态加载 KafkaBenchmarkDriver
  ↓
连接到Kafka
```

#### 第5步：创建WorkloadGenerator
```
创建 WorkloadGenerator 对象
传入：
  - driver名称
  - workload配置
  - worker对象
```

#### 第6步：运行测试（最重要！）

```
WorkloadGenerator.run() {

  6.1 创建Topics
      worker.create_topics()
        → KafkaBenchmarkDriver.create_topics()
        → 在Kafka中创建主题

  6.2 创建Producers
      _create_producers()
        → 为每个topic创建多个producer
        → 例如：1个topic × 5个producers = 5个producer实例

  6.3 创建Consumers
      _create_consumers()
        → 为每个topic创建多个consumer
        → 例如：1个topic × 2个subscriptions × 3个consumers = 6个consumer实例

  6.4 确保Consumer就绪
      _ensure_topics_are_ready()
        → 发送测试消息
        → 等待consumer接收到消息
        → 确保consumer已经分配到partition

  6.5 预热阶段（可选）
      如果 warmupDurationMinutes > 0:
        → 启动发送消息（预热）
        → 收集预热数据（但不计入最终结果）

  6.6 正式测试阶段
      worker.start_load() {
        → 创建多个生产者线程
        → 每个线程循环发送消息：
          while not stopped:
            1. 速率限制（控制发送速度）
            2. 选择key（根据分布策略）
            3. 发送消息 producer.send_async()
            4. 记录统计（延迟、吞吐量等）
      }

      同时，Consumer在后台接收消息：
        → 每个consumer独立进程poll消息
        → 收到消息后回调 message_received()
        → 记录端到端延迟

  6.7 收集统计
      每10秒执行一次：
        → worker.get_period_stats()
        → 打印当前性能指标：
          - 发送速率（msg/s）
          - 接收速率（msg/s）
          - 延迟（平均、P50、P99等）
          - 积压数量

  6.8 测试结束
      → worker.stop_all()
      → 停止所有producer线程
      → 停止所有consumer进程
      → 返回 TestResult 对象
}
```

#### 第7步：保存结果
```
Benchmark.main()
  ↓
获取 TestResult
  ↓
转换为字典格式
  ↓
保存为JSON文件（包含所有性能指标）
```

---

## 各模块详解

### 模块1：主程序模块

#### 📁 `benchmark.py` - 主程序

**核心类：** `Benchmark`

**主要方法：**

1. **`main(args)`** - 程序入口
   ```python
   # 功能：
   - 解析命令行参数
   - 读取配置文件
   - 创建Worker
   - 执行测试
   - 保存结果
   ```

2. **`_dict_to_workload(data)`** - 转换配置
   ```python
   # 功能：
   - 把YAML配置转成Workload对象
   - 设置测试参数
   ```

3. **`_test_result_to_dict(result)`** - 导出结果
   ```python
   # 功能：
   - 把TestResult对象转成字典
   - 方便保存为JSON
   ```

**执行逻辑：**
```
1. 解析参数（-d driver, -wf workers, workload文件）
2. 加载workload配置
3. 创建worker（本地或分布式）
4. 遍历每个workload和driver组合：
   - 初始化driver
   - 创建WorkloadGenerator
   - 运行测试
   - 保存结果
5. 关闭worker
```

---

### 模块2：负载生成模块

#### 📁 `workload_generator.py` - 负载生成器

**核心类：** `WorkloadGenerator`

**构造函数：**
```python
def __init__(self, driver_name, workload, worker):
    self.driver_name = driver_name      # 驱动名称（如"Kafka"）
    self.workload = workload            # 测试配置
    self.worker = worker                # Worker对象
    self.executor = ThreadPoolExecutor  # 线程池（用于后台任务）
    self.target_publish_rate = 0.0      # 目标发送速率
```

**主要方法：**

1. **`run()`** - 执行测试（最重要！）
   ```python
   流程：
   1. 创建topics
   2. 创建producers和consumers
   3. 确保consumer就绪
   4. 预热（可选）
   5. 开始正式测试
   6. 收集统计
   7. 返回结果
   ```

2. **`_create_producers(topics)`** - 创建生产者
   ```python
   # 为每个topic创建N个producer
   # N = workload.producers_per_topic

   例如：
   - 2个topics
   - producers_per_topic = 3
   - 结果：创建 2×3=6 个producers
   ```

3. **`_create_consumers(topics)`** - 创建消费者
   ```python
   # 为每个topic创建消费者
   # 数量 = subscriptions_per_topic × consumer_per_subscription

   例如：
   - 2个topics
   - subscriptions_per_topic = 2
   - consumer_per_subscription = 3
   - 结果：创建 2×2×3=12 个consumers
   ```

4. **`_ensure_topics_are_ready()`** - 确保准备就绪
   ```python
   # 为什么需要？
   # Kafka的consumer需要先收到消息才能分配partition

   流程：
   1. 每个producer发送1条测试消息
   2. 等待consumer收到所有测试消息
   3. 超时60秒后报错
   ```

5. **`_print_and_collect_stats(duration)`** - 收集统计
   ```python
   # 每10秒执行：
   1. 获取period_stats（周期统计）
   2. 计算速率（发送/接收）
   3. 打印日志
   4. 添加到结果列表

   # 测试结束时：
   5. 获取cumulative_latencies（累计延迟）
   6. 计算百分位数（P50, P95, P99等）
   7. 返回TestResult对象
   ```

6. **`_find_maximum_sustainable_rate()`** - 自动探测最大速率
   ```python
   # 什么时候用？
   # 当 workload.producer_rate = 0 时

   # 怎么工作？
   1. 从10000 msg/s开始
   2. 每3秒检查一次：
      - 如果消费速度 < 生产速度 → 降低速率
      - 如果消费速度 = 生产速度 → 提高速率
   3. 使用RateController动态调整
   ```

7. **`_build_and_drain_backlog()`** - 积压测试
   ```python
   # 什么时候用？
   # 当 workload.consumer_backlog_size_gb > 0 时

   # 流程：
   1. 暂停所有consumer
   2. 继续发送消息，直到积压达到目标大小
   3. 恢复consumer
   4. 等待积压被消费完
   5. 再运行指定的测试时间
   ```

**关键点：**
- WorkloadGenerator是测试的"指挥官"
- 它协调producer、consumer、统计的工作
- 支持预热、积压测试、自动速率探测等高级功能

---

### 模块3：Worker模块

#### 📁 `worker/worker.py` - Worker接口

**核心类：** `Worker`（抽象基类）

**定义的接口：**
```python
initialize_driver()        # 初始化驱动
create_topics()           # 创建主题
create_producers()        # 创建生产者
create_consumers()        # 创建消费者
start_load()              # 开始发送负载
get_counters_stats()      # 获取计数统计
get_period_stats()        # 获取周期统计
stop_all()                # 停止所有任务
```

这是一个**接口**（Java术语叫Interface），定义了Worker必须实现的方法。

---

#### 📁 `worker/local_worker.py` - 本地Worker

**核心类：** `LocalWorker`（实现Worker接口）

**主要属性：**
```python
self.benchmark_driver     # Kafka驱动实例
self.producers            # 生产者列表
self.consumers            # 消费者列表
self.stats                # 统计对象（WorkerStats）
self.producer_threads     # 生产者线程列表
self.stop_producing       # 停止标志
```

**核心方法详解：**

1. **`initialize_driver(config_file)`**
   ```python
   # 功能：初始化Kafka驱动

   流程：
   1. 读取driver配置文件（YAML）
   2. 解析配置（driverClass等）
   3. 动态导入driver类
      例如：benchmark.drivers.kafka.kafka_benchmark_driver.KafkaBenchmarkDriver
   4. 实例化driver
   5. 调用driver.initialize()
   ```

2. **`create_topics(topics_info)`**
   ```python
   # 功能：创建Kafka主题

   流程：
   1. 生成topic名称（格式：test-topic-0, test-topic-1...）
   2. 调用 driver.create_topics()
   3. 等待创建完成
   4. 返回topic名称列表
   ```

3. **`create_producers(topics)`**
   ```python
   # 功能：为每个topic创建producer

   流程：
   1. 为每个topic创建ProducerInfo对象
   2. 调用 driver.create_producers()
   3. 保存到 self.producers 列表

   例如：
   topics = ["test-topic-0", "test-topic-1"]
   → 创建2个KafkaBenchmarkProducer实例
   ```

4. **`create_consumers(consumer_assignment)`**
   ```python
   # 功能：创建consumers

   流程：
   1. 为每个(topic, subscription)对创建ConsumerInfo
   2. 传入callback（self，因为LocalWorker实现了ConsumerCallback）
   3. 调用 driver.create_consumers()
   4. 保存到 self.consumers 列表

   重要：LocalWorker本身是ConsumerCallback！
   当consumer收到消息时，会调用 self.message_received()
   ```

5. **`start_load(producer_work_assignment)`**
   ```python
   # 功能：开始发送消息（最重要！）

   流程：
   1. 保存work_assignment（包含payload、key分布策略等）
   2. 清除stop_producing标志
   3. 为每个producer创建一个线程：
      - 线程名：producer-0, producer-1...
      - 线程函数：_producer_worker_simple()
      - daemon=True（守护线程，主程序退出时自动结束）
   4. 启动所有线程

   关键：每个producer一个线程，独立发送消息
   ```

6. **`_producer_worker_simple(producer, producer_index)`**
   ```python
   # 功能：生产者工作线程（核心发送逻辑）

   流程：
   1. 创建独立的RateLimiter（速率限制器）
   2. 创建独立的MessageProducer（消息发送器）
   3. 进入无限循环：
      while not stopped:
        a. 根据key分布策略选择key
           - NO_KEY: key = None
           - RANDOM: key = random(0, 1000000)
           - ROUND_ROBIN: key = producer_index

        b. 调用 message_producer.send_message()
           - 速率限制（等待到指定时间才发送）
           - 记录intended_send_time（预期发送时间）
           - 发送消息 producer.send_async()
           - 记录统计（延迟、吞吐量）

        c. 异常处理（失败后sleep 0.1秒）

   关键：
   - 每个线程有独立的速率限制
   - producer_rate 是"每个producer"的速率，不是总速率
   - 例如：5个producers × 1000 msg/s = 5000 msg/s总速率
   ```

7. **`adjust_publish_rate(publish_rate)`**
   ```python
   # 功能：动态调整发送速率

   # 用于：
   - 自动速率探测
   - burst测试

   # 实现：
   - 更新 shared_publish_rate（多进程共享变量）
   - 各个生产者线程会定期检查并更新自己的速率
   ```

8. **`message_received(payload, publish_timestamp)`**
   ```python
   # 功能：消费者回调（实现ConsumerCallback接口）

   # 何时调用？
   - 当KafkaBenchmarkConsumer收到消息时

   # 参数：
   - payload: 消息内容（字节数组）
   - publish_timestamp: 发送时间戳（毫秒）

   # 流程：
   1. 获取当前时间（receive_timestamp）
   2. 计算端到端延迟 = receive_timestamp - publish_timestamp
   3. 转换为微秒（与Java版本一致）
   4. 调用 stats.record_message_received()

   # 关键：
   - 这个方法在consumer的进程中被调用
   - 通过multiprocessing.Queue传递消息到主进程
   ```

9. **`get_period_stats()`**
   ```python
   # 功能：获取周期统计（自上次调用以来的增量）

   # 返回PeriodStats对象，包含：
   - messages_sent: 发送的消息数
   - bytes_sent: 发送的字节数
   - messages_received: 接收的消息数
   - publish_latency: 发布延迟直方图（HDR Histogram）
   - end_to_end_latency: 端到端延迟直方图

   # 注意：
   - 调用后会重置周期统计（但保留累计统计）
   - WorkloadGenerator每10秒调用一次
   ```

10. **`stop_all()`**
    ```python
    # 功能：停止所有测试

    流程：
    1. 设置 stop_producing 标志
    2. 等待所有producer线程结束（最多1秒）
    3. 关闭所有producer（flush待发送消息）
    4. 关闭所有consumer
    5. 清空producer和consumer列表

    # 重要：
    - 确保消息都发送完毕（flush）
    - 避免数据丢失
    ```

**架构设计：**
```
LocalWorker
  ├── benchmark_driver (KafkaBenchmarkDriver)
  │     ├── create_topics()
  │     ├── create_producers() → [Producer1, Producer2...]
  │     └── create_consumers() → [Consumer1, Consumer2...]
  │
  ├── producer_threads (多线程)
  │     ├── Thread-0: _producer_worker_simple(Producer1)
  │     ├── Thread-1: _producer_worker_simple(Producer2)
  │     └── ...
  │
  ├── consumers (多进程)
  │     ├── Process-0: KafkaBenchmarkConsumer (后台poll)
  │     ├── Process-1: KafkaBenchmarkConsumer (后台poll)
  │     └── ...  → 收到消息 → message_received() → 统计
  │
  └── stats (WorkerStats)
        ├── messages_sent (原子计数器)
        ├── messages_received (原子计数器)
        ├── publish_latency (HDR Histogram)
        └── end_to_end_latency (HDR Histogram)
```

---

### 模块4：Kafka驱动模块

#### 📁 `driver_kafka/kafka_benchmark_driver.py`

**核心类：** `KafkaBenchmarkDriver`

**主要属性：**
```python
self.config                # 配置对象
self.producer_properties   # Producer配置（字典）
self.consumer_properties   # Consumer配置（字典）
self.admin                 # Kafka管理客户端
self.producers             # Producer列表
self.consumers             # Consumer列表
```

**核心方法：**

1. **`initialize(config_file, stats_logger)`**
   ```python
   # 功能：初始化Kafka驱动

   流程：
   1. 读取YAML配置文件
   2. 解析配置：
      - replicationFactor: 副本数
      - commonConfig: 公共配置（如bootstrap.servers）
      - producerConfig: 生产者配置
      - consumerConfig: 消费者配置
      - topicConfig: 主题配置

   3. 合并配置：
      producer_properties = commonConfig + producerConfig
      consumer_properties = commonConfig + consumerConfig

   4. 创建AdminClient（用于创建topic）

   配置文件示例：
   commonConfig: |
     bootstrap.servers=localhost:9092
   producerConfig: |
     acks=1
     linger.ms=1
   consumerConfig: |
     auto.offset.reset=earliest
     enable.auto.commit=true
   ```

2. **`create_topics(topic_infos)`**
   ```python
   # 功能：创建Kafka主题

   流程：
   1. 为每个topic创建NewTopic对象：
      - topic名称
      - partition数量
      - 副本数（replicationFactor）
      - topic配置（如retention.ms）

   2. 调用 admin.create_topics()
   3. 等待创建完成（阻塞）
   4. 处理"topic已存在"错误（忽略）

   返回：Future对象（可以.result()获取结果）
   ```

3. **`create_producers(producer_infos)`**
   ```python
   # 功能：创建多个Producer

   流程：
   1. 遍历producer_infos列表
   2. 为每个info创建KafkaBenchmarkProducer：
      - 传入topic名称
      - 传入producer_properties副本
   3. 添加到self.producers列表
   4. 返回Future（结果是producers列表）

   注意：
   - 每个producer有独立的Kafka Producer实例
   - properties是副本，互不影响
   ```

4. **`create_consumers(consumer_infos)`**
   ```python
   # 功能：创建多个Consumer

   流程：
   1. 遍历consumer_infos列表
   2. 为每个info创建KafkaBenchmarkConsumer：
      - topic: 要订阅的主题
      - subscription_name: 消费者组名（group.id）
      - properties: consumer配置
      - callback: 消息回调（LocalWorker）
   3. 添加到self.consumers列表
   4. 返回Future

   重要：
   - 每个consumer独立进程
   - 同一个subscription_name的consumers属于同一个消费者组
   - 会自动进行partition分配
   ```

5. **`close()`**
   ```python
   # 功能：清理资源

   流程：
   1. 关闭所有producers（flush消息）
   2. 关闭所有consumers
   3. 删除创建的topics（保证幂等性）

   为什么删除topics？
   - 避免重复运行时topic冲突
   - 保证每次测试环境干净
   ```

---

#### 📁 `driver_kafka/kafka_benchmark_producer.py`

**核心类：** `KafkaBenchmarkProducer`

**主要属性：**
```python
self.topic      # 要发送到的topic
self.producer   # confluent_kafka.Producer实例
```

**核心方法：**

1. **`send_async(key, payload)`**
   ```python
   # 功能：异步发送消息

   # 参数：
   - key: 消息key（字符串，可以为None）
   - payload: 消息内容（字节数组）

   # 流程：
   1. 创建FutureResult对象（模拟Java的Future）
   2. 定义delivery_callback（发送完成回调）
   3. 调用 producer.produce()：
      - topic: 目标主题
      - key: 转为字节（如果不为None）
      - value: payload
      - callback: delivery_callback
   4. 调用 producer.poll(0) 处理回调（非阻塞）
   5. 返回FutureResult

   # FutureResult的作用：
   - 可以添加done_callback
   - MessageProducer用它来记录延迟统计

   # 为什么异步？
   - 高性能：不等待Kafka确认就返回
   - 批量发送：Kafka会自动批量
   - 回调处理：发送完成后通过callback通知
   ```

2. **`close()`**
   ```python
   # 功能：关闭producer

   # 流程：
   1. 调用 producer.flush(10)
      - 等待所有待发送消息发送完毕
      - 最多等10秒
   2. 忽略异常（防止重复关闭报错）

   # 为什么要flush？
   - 确保消息不丢失
   - Kafka producer有内部缓冲区
   - 不flush可能导致消息丢失
   ```

**FutureResult类：**
```python
# 这是一个简单的Future实现

class FutureResult:
    def __init__(self):
        self.completed = False          # 是否完成
        self.exception_value = None     # 异常
        self._result = None             # 结果
        self._callbacks = []            # 回调列表

    def set_result(self, result):
        # 设置结果，触发回调

    def set_exception(self, exc):
        # 设置异常，触发回调

    def add_done_callback(self, fn):
        # 添加完成回调
        # MessageProducer用这个来记录延迟
```

---

#### 📁 `driver_kafka/kafka_benchmark_consumer.py`

**核心类：** `KafkaBenchmarkConsumer`

**架构设计：**
```
KafkaBenchmarkConsumer
  ├── consumer_process (独立进程)
  │     └── _consumer_loop_func()
  │           ├── 创建Kafka Consumer
  │           ├── 订阅topic
  │           └── while循环：
  │                 ├── poll消息
  │                 ├── 放入message_queue
  │                 └── 定期commit offset
  │
  └── callback_thread (回调线程)
        └── _callback_loop()
              ├── 从message_queue取消息
              └── 调用 callback.message_received()
```

**主要属性：**
```python
self.topic             # 订阅的topic
self.properties        # Consumer配置
self.callback          # 消息回调（LocalWorker）
self.closing           # 关闭标志（Event）
self.paused            # 暂停标志（Event）
self.message_queue     # 消息队列（进程间通信）
self.consumer_process  # 消费者进程
self.callback_thread   # 回调线程
```

**核心方法：**

1. **`__init__(topic, subscription_name, properties, callback)`**
   ```python
   # 功能：初始化consumer

   流程：
   1. 设置 group.id = subscription_name
      - 这样同一个subscription的consumers属于同一个消费者组
      - Kafka会自动分配partition

   2. 创建multiprocessing.Event标志：
      - closing: 是否关闭
      - paused: 是否暂停

   3. 创建message_queue（进程间消息队列）
      - maxsize=1000（最多缓存1000条消息）

   4. 启动consumer_process：
      - target: _consumer_loop_func
      - args: topic, properties, queue, closing, paused
      - daemon=True（守护进程）

   5. 启动callback_thread：
      - target: _callback_loop
      - daemon=True（守护线程）

   # 为什么需要两个组件？
   - consumer_process: 独立进程poll Kafka（避免GIL影响）
   - callback_thread: 主进程处理消息（访问stats等共享数据）
   ```

2. **`_consumer_loop_func()` （全局函数，在独立进程运行）**
   ```python
   # 功能：消费者循环（独立进程）

   流程：
   1. 创建Consumer实例
   2. 订阅topic: consumer.subscribe([topic])
   3. 进入循环：
      while not closing:
        a. 检查是否暂停：
           if paused:
             consumer.pause(所有partitions)
             sleep(0.1)
             continue
           else:
             consumer.resume(所有partitions)

        b. Poll消息：
           msg = consumer.poll(timeout=0.1)

        c. 处理消息：
           if msg is not None and no error:
             - 提取timestamp（毫秒）
             - 放入message_queue: (payload, timestamp)

        d. 定期commit offset（每100条消息）:
           message_count += 1
           if message_count >= 100:
             consumer.commit(asynchronous=True)
             message_count = 0

   4. 退出时final commit:
      consumer.commit(asynchronous=False)
      consumer.close()

   # 关键点：
   - timestamp是Kafka消息的原始时间戳（毫秒）
   - 异步commit提高性能
   - 最后要同步commit确保offset保存
   ```

3. **`_callback_loop()` （在主进程的回调线程运行）**
   ```python
   # 功能：回调循环（主进程线程）

   流程：
   while not closing:
     1. 从message_queue取消息（timeout 0.1秒）
     2. 如果取到消息：
        payload, timestamp = queue.get()
        callback.message_received(payload, timestamp)
     3. 异常忽略（queue空或超时）

   # 为什么需要这个线程？
   - consumer_process在独立进程，无法直接访问主进程数据
   - 通过queue传递消息到主进程
   - callback_thread在主进程，可以访问stats等共享数据
   ```

4. **`pause()` / `resume()`**
   ```python
   # 功能：暂停/恢复消费

   # 用于：积压测试
   - pause(): 设置paused标志
   - resume(): 清除paused标志

   # consumer_process会检查paused标志：
   - 暂停时：调用Kafka consumer.pause()
   - 恢复时：调用Kafka consumer.resume()
   ```

5. **`close()`**
   ```python
   # 功能：关闭consumer

   流程：
   1. 设置closing标志
   2. 等待callback_thread结束（最多2秒）
   3. 等待consumer_process结束（最多5秒）
   4. 如果进程未结束，强制terminate

   # 为什么要terminate？
   - 有时进程卡在poll中
   - 需要强制结束避免死锁
   ```

**时间戳处理：**
```python
# Kafka消息的timestamp有3种类型：
# 0 = TIMESTAMP_NOT_AVAILABLE (无时间戳)
# 1 = CREATE_TIME (消息创建时间)
# 2 = LOG_APPEND_TIME (写入日志时间)

timestamp_type, timestamp_ms = msg.timestamp()
if timestamp_type != 0:
    publish_timestamp = timestamp_ms  # 使用Kafka的时间戳（毫秒）
else:
    publish_timestamp = 0             # 无时间戳，设为0

# MessageProducer在发送时会设置CREATE_TIME
# 所以这里获取的是消息发送时的时间戳
```

---

### 模块5：统计模块

#### 📁 `worker/worker_stats.py`

**核心类：** `WorkerStats`

**主要属性：**
```python
# 原子计数器（线程安全）
self.messages_sent = AtomicLong()           # 周期发送消息数
self.total_messages_sent = AtomicLong()     # 总发送消息数
self.messages_received = AtomicLong()       # 周期接收消息数
self.total_messages_received = AtomicLong() # 总接收消息数
self.bytes_sent = AtomicLong()              # 周期发送字节数
self.bytes_received = AtomicLong()          # 周期接收字节数
self.message_send_errors = AtomicLong()     # 周期发送错误数

# HDR Histogram（高性能延迟统计）
self.publish_latency_recorder           # 发布延迟（微秒）
self.publish_delay_latency_recorder     # 发布延迟（微秒，queue时间）
self.end_to_end_latency_recorder        # 端到端延迟（微秒）

# 累计直方图
self.cumulative_publish_latency_recorder
self.cumulative_publish_delay_latency_recorder
self.cumulative_end_to_end_latency_recorder
```

**核心方法：**

1. **`record_producer_success(payload_len, intended, sent, acked)`**
   ```python
   # 功能：记录成功发送

   # 参数（都是纳秒）：
   - payload_len: 消息大小（字节）
   - intended: 预期发送时间
   - sent: 实际发送时间
   - acked: 收到确认时间

   # 计算：
   publish_delay = sent - intended           # 延迟（等待时间）
   publish_latency = acked - sent            # 延迟（网络+Kafka处理）

   # 记录：
   1. messages_sent += 1
   2. bytes_sent += payload_len
   3. publish_latency_recorder.record(latency_us)
   4. publish_delay_latency_recorder.record(delay_us)
   5. 同时记录到cumulative直方图

   # 单位转换：
   - 纳秒 → 微秒：除以1000
   ```

2. **`record_message_received(payload_len, e2e_latency_us)`**
   ```python
   # 功能：记录消息接收

   # 参数：
   - payload_len: 消息大小
   - e2e_latency_us: 端到端延迟（微秒）

   # 记录：
   1. messages_received += 1
   2. bytes_received += payload_len
   3. end_to_end_latency_recorder.record(e2e_latency_us)
   4. cumulative_end_to_end_latency_recorder.record(e2e_latency_us)
   ```

3. **`to_period_stats()`**
   ```python
   # 功能：获取周期统计（增量）

   # 流程：
   1. 获取当前值
   2. 创建PeriodStats对象
   3. 重置周期计数器（但保留total和cumulative）

   # 返回：PeriodStats对象
   - messages_sent: 这个周期发送的消息数
   - bytes_sent: 这个周期发送的字节数
   - messages_received: 这个周期接收的消息数
   - publish_latency: 发布延迟直方图（周期）
   - end_to_end_latency: 端到端延迟直方图（周期）

   # 重要：
   - 调用后会重置周期统计
   - WorkloadGenerator每10秒调用一次
   ```

4. **`to_cumulative_latencies()`**
   ```python
   # 功能：获取累计延迟统计

   # 返回：CumulativeLatencies对象
   - publish_latency: 累计发布延迟直方图
   - publish_delay_latency: 累计发布延迟直方图
   - end_to_end_latency: 累计端到端延迟直方图

   # 用途：
   - 测试结束时获取整体统计
   - 计算P50, P95, P99等百分位数
   ```

**HDR Histogram 解释：**
```python
# HDR Histogram是什么？
# High Dynamic Range Histogram（高动态范围直方图）
# 用于高精度、低内存的延迟统计

# 为什么用它？
1. 精度高：可以记录纳秒到小时级别的延迟
2. 内存小：固定大小，不随样本数增长
3. 性能好：记录和查询都是O(1)
4. 百分位准确：P99.99也很准确

# 主要方法：
histogram.record_value(value_us)        # 记录一个值（微秒）
histogram.get_mean_value()              # 平均值
histogram.get_value_at_percentile(99)   # P99
histogram.get_max_value()               # 最大值

# 编码/解码（用于进程间传输）：
encoded = histogram.encode()            # 编码为字节
histogram = HdrHistogram.decode(encoded) # 解码
```

---

### 模块6：工具模块

#### 📁 `utils/uniform_rate_limiter.py`

**核心类：** `UniformRateLimiter`

**功能：** 精确控制发送速率

**原理：**
```python
# 目标：每秒发1000条消息
# 那么两条消息之间应该间隔：1秒 / 1000 = 1毫秒

# 实现：
1. 记录上次发送时间
2. 计算下次应该发送的时间 = 上次时间 + 间隔
3. 等待到下次发送时间
4. 发送消息
```

**主要方法：**

1. **`__init__(rate)`**
   ```python
   # 参数：rate（每秒消息数）

   # 计算：
   self.interval_ns = 1_000_000_000 / rate  # 纳秒间隔
   self.next_send_time_ns = time.perf_counter_ns()

   例如：rate = 1000
   interval_ns = 1_000_000 (1毫秒)
   ```

2. **`acquire()`**
   ```python
   # 功能：获取下次发送时间（纳秒）

   # 流程：
   1. 计算 next_send_time = 当前时间 + 间隔
   2. 更新 self.next_send_time_ns
   3. 返回 next_send_time

   # 使用：
   intended_time = rate_limiter.acquire()
   while time.perf_counter_ns() < intended_time:
       pass  # 忙等待（busy-wait）
   send_message()

   # 为什么忙等待？
   - sleep()不够精确（最小1毫秒）
   - 高速率需要微秒级精度
   - 忙等待可以达到纳秒级精度
   ```

**关键设计：**
```python
# 问题：如果处理太慢怎么办？
# 例如：应该每1ms发一条，但处理用了5ms

# 解决：
- acquire()不会"补偿"，而是继续按照固定间隔
- next_send_time 总是递增 interval_ns
- 这样可以保持长期速率稳定

# 示例：
t0: acquire() → next_send = t0 + 1ms
t5: acquire() → next_send = t0 + 2ms (已经过了！)
    → 立即发送
t5: acquire() → next_send = t0 + 3ms
    → 等到 t0 + 3ms
```

---

#### 📁 `worker/message_producer.py`

**核心类：** `MessageProducer`

**功能：** 统一的消息发送接口，集成速率限制和统计

**主要属性：**
```python
self.rate_limiter  # UniformRateLimiter实例
self.stats         # WorkerStats实例
```

**核心方法：**

**`send_message(producer, key, payload)`**
```python
# 功能：发送一条消息（集成速率限制和统计）

# 流程：
1. 速率限制：
   intended_send_time_ns = rate_limiter.acquire()
   while time.perf_counter_ns() < intended_send_time_ns:
       producer.producer.poll(0)  # 处理回调，避免空转

2. 记录发送时间：
   send_time_ns = time.perf_counter_ns()

3. 发送消息：
   future = producer.send_async(key, payload)

4. 添加回调（记录统计）：
   def record_stats(f):
       ack_time_ns = time.perf_counter_ns()
       if f.exception():
           stats.record_producer_failure()
       else:
           stats.record_producer_success(
               len(payload),
               intended_send_time_ns,
               send_time_ns,
               ack_time_ns
           )

   future.add_done_callback(record_stats)

# 关键点：
- intended: 预期发送时间（速率限制目标）
- send: 实际发送时间
- ack: 收到Kafka确认时间
- 可以分析：
  - 速率限制开销 = send - intended
  - Kafka延迟 = ack - send
```

---

### 模块7：配置类

#### 📁 `workload.py`

**核心类：** `Workload`

**所有属性：**
```python
self.name = None                          # 测试名称
self.topics = 0                           # topic数量
self.partitions_per_topic = 0             # 每个topic的partition数
self.key_distributor = None               # key分布策略（NO_KEY/RANDOM/ROUND_ROBIN）
self.message_size = 0                     # 消息大小（字节）

# 随机payload配置
self.use_randomized_payloads = False      # 是否使用随机payload
self.random_bytes_ratio = 0.0             # 随机字节比例（测试压缩）
self.randomized_payload_pool_size = 0     # payload池大小

self.payload_file = None                  # payload文件路径

# Producer/Consumer配置
self.subscriptions_per_topic = 0          # 每个topic的订阅数
self.producers_per_topic = 0              # 每个topic的producer数
self.consumer_per_subscription = 0        # 每个订阅的consumer数

self.producer_rate = 0                    # 发送速率（0=自动探测最大速率）

# 积压测试配置
self.consumer_backlog_size_gb = 0         # 积压大小（GB）
self.backlog_drain_ratio = 1.0            # 积压清空比例（1.0=100%）

# 测试时长
self.test_duration_minutes = 0            # 测试时长（分钟）
self.warmup_duration_minutes = 1          # 预热时长（分钟）
```

**配置示例：**
```yaml
name: high-throughput-test
topics: 4                        # 4个topics
partitionsPerTopic: 16           # 每个topic 16个partitions
keyDistributor: RANDOM           # 随机key分布
messageSize: 1024                # 1KB消息
subscriptionsPerTopic: 1         # 每个topic 1个订阅
producersPerTopic: 10            # 每个topic 10个producers
consumerPerSubscription: 40      # 每个订阅 40个consumers
producerRate: 10000              # 每个producer 10000 msg/s
testDurationMinutes: 10          # 测试10分钟
warmupDurationMinutes: 2         # 预热2分钟

# 计算：
# 总producers = 4 topics × 10 = 40个
# 总consumers = 4 topics × 1 subscription × 40 = 160个
# 总发送速率 = 40 producers × 10000 = 400000 msg/s
```

---

#### 📁 `driver_configuration.py`

**核心类：** `DriverConfiguration`

**属性：**
```python
self.name = None          # 驱动名称（如"Kafka"）
self.driver_class = None  # 驱动类路径
```

**配置示例：**
```yaml
name: Kafka
driverClass: benchmark.driver_kafka.kafka_benchmark_driver.KafkaBenchmarkDriver
replicationFactor: 3
commonConfig: |
  bootstrap.servers=localhost:9092
producerConfig: |
  acks=1
  linger.ms=1
  batch.size=16384
consumerConfig: |
  auto.offset.reset=earliest
  enable.auto.commit=true
```

---

## 文件结构导航

### 📂 完整目录树

```
openmessaging-benchmark/
│
├── benchmark/                          # 核心代码目录
│   ├── __init__.py                     # 包初始化（导出核心类）
│   ├── __main__.py                     # 程序入口（python -m benchmark）
│   ├── benchmark.py                    # 主程序（Benchmark类）
│   │
│   ├── 配置类
│   ├── workload.py                     # 工作负载配置
│   ├── driver_configuration.py         # 驱动配置
│   ├── workers.py                      # Worker配置
│   │
│   ├── 核心组件
│   ├── workload_generator.py           # 负载生成器（核心！）
│   ├── rate_controller.py              # 速率控制器
│   ├── test_result.py                  # 测试结果类
│   ├── results_to_csv.py               # 结果转CSV
│   │
│   ├── worker/                         # Worker框架
│   │   ├── worker.py                   # Worker接口（抽象类）
│   │   ├── local_worker.py             # 本地Worker（核心！）
│   │   ├── distributed_workers_ensemble.py  # 分布式Worker
│   │   ├── http_worker_client.py       # HTTP客户端
│   │   ├── benchmark_worker.py         # Worker服务端
│   │   ├── worker_handler.py           # HTTP处理器
│   │   ├── worker_stats.py             # 统计类（核心！）
│   │   ├── message_producer.py         # 消息发送器
│   │   │
│   │   └── commands/                   # 命令对象（数据传输）
│   │       ├── consumer_assignment.py
│   │       ├── producer_work_assignment.py
│   │       ├── counters_stats.py
│   │       ├── period_stats.py
│   │       ├── cumulative_latencies.py
│   │       └── ...
│   │
│   ├── driver/                         # 驱动接口
│   │   ├── benchmark_driver.py         # 驱动接口（抽象类）
│   │   ├── benchmark_producer.py       # Producer接口
│   │   ├── benchmark_consumer.py       # Consumer接口
│   │   ├── consumer_callback.py        # 消费者回调接口
│   │   └── resource_creator.py
│   │
│   ├── driver_kafka/                   # Kafka驱动实现
│   │   ├── kafka_benchmark_driver.py   # Kafka驱动（核心！）
│   │   ├── kafka_benchmark_producer.py # Kafka Producer
│   │   ├── kafka_benchmark_consumer.py # Kafka Consumer
│   │   └── config.py                   # 配置类
│   │
│   ├── utils/                          # 工具类
│   │   ├── uniform_rate_limiter.py     # 速率限制器（核心！）
│   │   ├── timer.py                    # 计时器
│   │   ├── random_generator.py         # 随机数生成器
│   │   ├── padding_decimal_format.py   # 数字格式化
│   │   ├── list_partition.py           # 列表分区
│   │   ├── env.py                      # 环境变量
│   │   │
│   │   ├── distributor/                # Key分布策略
│   │   │   ├── key_distributor_type.py
│   │   │   ├── no_key_distributor.py
│   │   │   ├── key_round_robin.py
│   │   │   └── random_nano.py
│   │   │
│   │   └── payload/                    # Payload处理
│   │       ├── payload_reader.py
│   │       ├── file_payload_reader.py
│   │       └── payload_exception.py
│   │
│   └── tool/                           # 工具（生成workload配置）
│       ├── workload_generator.py
│       ├── workload_generation_tool.py
│       └── workload_set_template.py
│
├── examples/                           # 示例配置
│   ├── kafka-driver.yaml               # Kafka驱动配置
│   ├── simple-workload.yaml            # 简单工作负载
│   └── workers.yaml                    # Worker配置
│
├── requirements.txt                    # Python依赖
├── setup.py                            # 安装脚本
└── README.md                           # 说明文档
```

### 🔍 快速查找指南

**想了解某个功能，看哪个文件？**

| 功能 | 文件 | 说明 |
|------|------|------|
| 程序如何启动 | `benchmark.py` | 主程序入口 |
| 如何生成负载 | `workload_generator.py` | 负载生成逻辑 |
| 如何发送消息 | `local_worker.py` | 生产者线程逻辑 |
| 如何接收消息 | `kafka_benchmark_consumer.py` | 消费者进程逻辑 |
| 如何限速 | `uniform_rate_limiter.py` | 精确速率控制 |
| 如何统计 | `worker_stats.py` | 延迟、吞吐量统计 |
| 如何连接Kafka | `kafka_benchmark_driver.py` | Kafka交互 |
| 配置参数含义 | `workload.py` | 所有可配置参数 |

---

## 常见问题解答

### Q1: Producer和Consumer是怎么对应的？

**答：** 通过Topic和ConsumerGroup

```
Topic: test-topic-0
  ├── Partition-0
  ├── Partition-1
  ├── Partition-2
  └── Partition-3

Producers (10个):
  → 发送到 test-topic-0
  → Kafka根据key分配到不同partition

ConsumerGroup: sub-001
  Consumers (4个):
    → Consumer-0 分配到 Partition-0
    → Consumer-1 分配到 Partition-1
    → Consumer-2 分配到 Partition-2
    → Consumer-3 分配到 Partition-3

# 如果consumer数 > partition数：
# 多余的consumer会闲置

# 如果consumer数 < partition数：
# 一个consumer会处理多个partitions
```

### Q2: 为什么用多线程producer + 多进程consumer？

**答：**

```
Producer用多线程：
  - 需要共享stats（统计数据）
  - Python的GIL对发送影响小（I/O操作会释放GIL）
  - 线程间通信快（共享内存）

Consumer用多进程：
  - 避免GIL影响（poll是CPU密集）
  - 隔离性好（一个consumer崩溃不影响其他）
  - 通过Queue通信（message_queue）
```

### Q3: 延迟是怎么计算的？

**答：**

```python
# 1. 发布延迟 (Publish Latency)
intended_time  = rate_limiter.acquire()  # 预期发送时间
send_time      = actual_send()           # 实际发送时间
ack_time       = kafka_ack()             # 收到Kafka确认时间

publish_delay_latency = send_time - intended_time  # 等待时间
publish_latency = ack_time - send_time             # Kafka处理时间

# 2. 端到端延迟 (End-to-End Latency)
publish_timestamp = 消息发送时间（存在消息中）
receive_timestamp = consumer接收时间

end_to_end_latency = receive_timestamp - publish_timestamp

# 单位：
- 内部计算：纳秒 (ns)
- 记录到Histogram：微秒 (μs)
- 显示给用户：毫秒 (ms)
```

### Q4: 如何理解测试结果？

**答：**

```json
{
  "publishRate": [10000, 10050, 9980, ...],  // 每10秒的发送速率
  "consumeRate": [9800, 10020, 9950, ...],   // 每10秒的接收速率
  "backlog": [0, 200, 150, ...],             // 每10秒的积压消息数

  // 周期延迟（每10秒）
  "publishLatencyAvg": [1.2, 1.3, 1.1, ...],      // 平均延迟(ms)
  "publishLatency99pct": [5.2, 5.5, 5.0, ...],    // P99延迟(ms)

  // 聚合延迟（整个测试）
  "aggregatedPublishLatency50pct": 1.1,           // P50延迟
  "aggregatedPublishLatency95pct": 3.5,           // P95延迟
  "aggregatedPublishLatency99pct": 5.2,           // P99延迟
  "aggregatedPublishLatency999pct": 12.3,         // P99.9延迟

  // 关键指标
  "messageSize": 1024,          // 消息大小
  "topics": 1,                  // topic数量
  "partitions": 16,             // partition数量
  "producersPerTopic": 10,      // 每topic的producer数
  "consumersPerTopic": 40       // 每topic的consumer数
}
```

**如何判断测试好坏？**

1. **吞吐量稳定**：publishRate和consumeRate接近且稳定
2. **积压为0**：backlog接近0（说明消费速度跟得上）
3. **延迟低**：
   - P50 < 10ms：很好
   - P99 < 50ms：良好
   - P99.9 < 100ms：可接受
4. **没有错误**：publishErrorRate = 0

---

## 总结

### 🎯 项目核心流程

```
1. 用户配置 (workload.yaml + driver.yaml)
     ↓
2. Benchmark读取配置
     ↓
3. 创建Worker（LocalWorker）
     ↓
4. 初始化Driver（KafkaBenchmarkDriver）
     ↓
5. WorkloadGenerator创建Topics/Producers/Consumers
     ↓
6. 启动负载：
   - 多个生产者线程发送消息（速率限制）
   - 多个消费者进程接收消息（后台poll）
   - 持续收集统计（延迟、吞吐量）
     ↓
7. 测试结束，保存结果（JSON文件）
```

### 🔑 关键技术点

1. **多线程生产者**：每个producer一个线程，独立速率限制
2. **多进程消费者**：每个consumer一个进程，通过Queue通信
3. **精确速率控制**：纳秒级UniformRateLimiter，忙等待
4. **高精度统计**：HDR Histogram，支持P99.99统计
5. **异步发送**：Kafka Producer异步发送，回调记录统计
6. **动态速率调整**：RateController自动探测最大速率

### 📖 阅读建议

**第一遍阅读（理解流程）：**
1. `benchmark.py` - 了解主流程
2. `workload_generator.py` - 了解测试如何执行
3. `local_worker.py` - 了解消息如何发送/接收

**第二遍阅读（理解细节）：**
1. `kafka_benchmark_driver.py` - Kafka交互
2. `kafka_benchmark_producer.py` - 异步发送机制
3. `kafka_benchmark_consumer.py` - 多进程消费机制
4. `worker_stats.py` - 统计实现

**第三遍阅读（理解工具）：**
1. `uniform_rate_limiter.py` - 速率控制算法
2. `message_producer.py` - 发送封装
3. `rate_controller.py` - 动态速率调整

---

## 附录：核心算法

### 速率限制算法

```python
class UniformRateLimiter:
    def __init__(self, rate):
        # 计算消息间隔（纳秒）
        self.interval_ns = 1_000_000_000 / rate
        self.next_send_time_ns = time.perf_counter_ns()

    def acquire(self):
        # 返回下次应该发送的时间
        current = self.next_send_time_ns
        self.next_send_time_ns += self.interval_ns
        return current

# 使用：
limiter = UniformRateLimiter(1000)  # 1000 msg/s
while True:
    intended = limiter.acquire()
    # 忙等待到指定时间
    while time.perf_counter_ns() < intended:
        pass
    send_message()
```

### 动态速率调整算法

```python
def next_rate(current_rate, period_ns, sent, received):
    # 目标：消费速度 = 生产速度

    send_rate = sent / (period_ns / 1e9)
    receive_rate = received / (period_ns / 1e9)

    # 如果消费速度 > 生产速度：提高速率
    if receive_rate > send_rate * 1.05:
        return current_rate * 1.1

    # 如果消费速度 < 生产速度：降低速率
    elif receive_rate < send_rate * 0.95:
        return current_rate * 0.9

    # 否则：保持不变
    else:
        return current_rate
```

### 端到端延迟计算

```python
# Producer端：
timestamp_ms = int(time.time() * 1000)  # 毫秒时间戳
message = create_message(payload, timestamp=timestamp_ms)
send_to_kafka(message)

# Consumer端：
message = poll_from_kafka()
publish_timestamp_ms = message.timestamp()
receive_timestamp_ms = int(time.time() * 1000)

e2e_latency_ms = receive_timestamp_ms - publish_timestamp_ms
e2e_latency_us = e2e_latency_ms * 1000  # 转为微秒

# 记录到Histogram
histogram.record_value(e2e_latency_us)
```

---

希望这份文档能帮助您理解整个项目！如果有任何不清楚的地方，都可以再问我。祝您阅读愉快！🎉
