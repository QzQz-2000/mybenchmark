"""
å¤šè¿›ç¨‹æ‰§è¡Œå™¨ - æ¯ä¸ª Producer/Consumer ç‹¬ç«‹è¿›ç¨‹è¿è¡Œ

è¿™ä¸ªæ¨¡å—å®ç°äº†ç±»ä¼¼ Java OMB çš„å¤šçº¿ç¨‹æ¨¡å‹ï¼Œä½†ä½¿ç”¨ Python å¤šè¿›ç¨‹æ¥ç»•è¿‡ GILã€‚
æ¯ä¸ª producer/consumer agent è¿è¡Œåœ¨ç‹¬ç«‹çš„è¿›ç¨‹ä¸­ï¼ŒçœŸå®æ¨¡æ‹Ÿå¤š agent è´Ÿè½½åœºæ™¯ã€‚
"""

import multiprocessing as mp
import asyncio
import time
import sys
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
import traceback
import json

from benchmark.core.worker import ProducerTask, ConsumerTask
from benchmark.core.config import DriverConfig
from benchmark.core.results import WorkerResult, ThroughputStats, LatencyStats, ErrorStats
from benchmark.utils.logging import LoggerMixin


@dataclass
class ProcessResult:
    """è¿›ç¨‹æ‰§è¡Œç»“æœ"""
    task_id: str
    task_type: str  # 'producer' or 'consumer'
    pid: int
    start_time: float
    end_time: float
    success: bool

    # ç»Ÿè®¡æ•°æ®
    messages_sent: int = 0
    messages_received: int = 0
    bytes_sent: int = 0
    bytes_received: int = 0
    errors: int = 0

    # å»¶è¿Ÿç»Ÿè®¡ (dict æ ¼å¼ä¾¿äºåºåˆ—åŒ–)
    latency_stats: Optional[Dict] = None

    # é”™è¯¯ä¿¡æ¯
    error_message: Optional[str] = None

    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return asdict(self)


class ProcessExecutor(LoggerMixin):
    """
    å¤šè¿›ç¨‹æ‰§è¡Œå™¨

    è´Ÿè´£ç®¡ç†å¤šä¸ªç‹¬ç«‹çš„ producer/consumer è¿›ç¨‹ï¼Œæ¯ä¸ªä»»åŠ¡è¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ã€‚
    """

    def __init__(self, worker_id: str):
        super().__init__()
        self.worker_id = worker_id
        self._processes: List[mp.Process] = []
        self._result_queue = mp.Queue()

    async def execute_producer_tasks(
        self,
        tasks: List[ProducerTask],
        driver_config: DriverConfig
    ) -> List[WorkerResult]:
        """
        æ‰§è¡Œå¤šä¸ª producer ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡ä¸€ä¸ªç‹¬ç«‹è¿›ç¨‹

        Args:
            tasks: Producer ä»»åŠ¡åˆ—è¡¨
            driver_config: Driver é…ç½®

        Returns:
            æ‰€æœ‰ producer çš„æ‰§è¡Œç»“æœ
        """
        # æ¸…ç©ºä¹‹å‰çš„è¿›ç¨‹åˆ—è¡¨ï¼ˆç¡®ä¿ä¸ç´¯ç§¯ï¼‰
        self._processes.clear()

        self.logger.info(f"ğŸš€ å¯åŠ¨ {len(tasks)} ä¸ªç‹¬ç«‹ Producer è¿›ç¨‹...")

        # å¯åŠ¨æ‰€æœ‰ producer è¿›ç¨‹
        for task in tasks:
            process = mp.Process(
                target=_producer_process_main,
                args=(task, driver_config, self._result_queue),
                name=f"producer-{task.task_id}"
            )
            process.start()
            self._processes.append(process)

            self.logger.info(
                f"   âœ… å¯åŠ¨ Producer: {task.task_id} (PID: {process.pid})"
            )

        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
        results = await self._wait_for_processes(len(tasks))

        # è½¬æ¢ä¸º WorkerResult
        worker_results = []
        for result in results:
            worker_result = self._convert_to_worker_result(result)
            worker_results.append(worker_result)

        self.logger.info(f"âœ¨ æ‰€æœ‰ {len(tasks)} ä¸ª Producer è¿›ç¨‹å·²å®Œæˆ")

        return worker_results

    async def execute_consumer_tasks(
        self,
        tasks: List[ConsumerTask],
        driver_config: DriverConfig
    ) -> List[WorkerResult]:
        """
        æ‰§è¡Œå¤šä¸ª consumer ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡ä¸€ä¸ªç‹¬ç«‹è¿›ç¨‹

        Args:
            tasks: Consumer ä»»åŠ¡åˆ—è¡¨
            driver_config: Driver é…ç½®

        Returns:
            æ‰€æœ‰ consumer çš„æ‰§è¡Œç»“æœ
        """
        # æ¸…ç©ºä¹‹å‰çš„è¿›ç¨‹åˆ—è¡¨ï¼ˆç¡®ä¿ä¸ç´¯ç§¯ï¼‰
        self._processes.clear()

        self.logger.info(f"ğŸš€ å¯åŠ¨ {len(tasks)} ä¸ªç‹¬ç«‹ Consumer è¿›ç¨‹...")

        # å¯åŠ¨æ‰€æœ‰ consumer è¿›ç¨‹
        for task in tasks:
            process = mp.Process(
                target=_consumer_process_main,
                args=(task, driver_config, self._result_queue),
                name=f"consumer-{task.task_id}"
            )
            process.start()
            self._processes.append(process)

            self.logger.info(
                f"   âœ… å¯åŠ¨ Consumer: {task.task_id} (PID: {process.pid})"
            )

        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
        results = await self._wait_for_processes(len(tasks))

        # è½¬æ¢ä¸º WorkerResult
        worker_results = []
        for result in results:
            worker_result = self._convert_to_worker_result(result)
            worker_results.append(worker_result)

        self.logger.info(f"âœ¨ æ‰€æœ‰ {len(tasks)} ä¸ª Consumer è¿›ç¨‹å·²å®Œæˆ")

        return worker_results

    async def _wait_for_processes(self, expected_count: int) -> List[ProcessResult]:
        """
        ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆå¹¶æ”¶é›†ç»“æœ

        Args:
            expected_count: æœŸæœ›çš„ç»“æœæ•°é‡

        Returns:
            æ‰€æœ‰è¿›ç¨‹çš„ç»“æœ
        """
        results = []

        # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹
        for process in self._processes:
            process.join()

        # æ”¶é›†æ‰€æœ‰ç»“æœ
        while not self._result_queue.empty():
            try:
                result_dict = self._result_queue.get_nowait()
                result = ProcessResult(**result_dict)
                results.append(result)
            except Exception as e:
                self.logger.error(f"æ”¶é›†ç»“æœå¤±è´¥: {e}")

        if len(results) != expected_count:
            self.logger.warning(
                f"æœŸæœ› {expected_count} ä¸ªç»“æœï¼Œå®é™…æ”¶åˆ° {len(results)} ä¸ª"
            )

        return results

    def _convert_to_worker_result(self, process_result: ProcessResult) -> WorkerResult:
        """å°† ProcessResult è½¬æ¢ä¸º WorkerResult"""

        # æ„å»º ThroughputStats
        duration = process_result.end_time - process_result.start_time
        if process_result.task_type == 'producer':
            throughput = ThroughputStats(
                total_messages=process_result.messages_sent,
                total_bytes=process_result.bytes_sent,
                duration_seconds=duration,
                messages_per_second=process_result.messages_sent / duration if duration > 0 else 0,
                bytes_per_second=process_result.bytes_sent / duration if duration > 0 else 0,
                mb_per_second=(process_result.bytes_sent / duration / 1024 / 1024) if duration > 0 else 0
            )
        else:
            throughput = ThroughputStats(
                total_messages=process_result.messages_received,
                total_bytes=process_result.bytes_received,
                duration_seconds=duration,
                messages_per_second=process_result.messages_received / duration if duration > 0 else 0,
                bytes_per_second=process_result.bytes_received / duration if duration > 0 else 0,
                mb_per_second=(process_result.bytes_received / duration / 1024 / 1024) if duration > 0 else 0
            )

        # æ„å»º LatencyStats
        if process_result.latency_stats:
            latency = LatencyStats(**process_result.latency_stats)
        else:
            latency = LatencyStats(
                count=0,
                min_ms=0, max_ms=0, mean_ms=0, median_ms=0,
                p50_ms=0, p95_ms=0, p99_ms=0, p99_9_ms=0
            )

        # æ„å»º ErrorStats
        error_rate = 0.0
        if process_result.task_type == 'producer' and process_result.messages_sent > 0:
            error_rate = process_result.errors / (process_result.messages_sent + process_result.errors)

        errors = ErrorStats(
            total_errors=process_result.errors,
            error_rate=error_rate,
            error_types={}
        )

        # æ„å»º WorkerResult
        return WorkerResult(
            worker_id=f"{self.worker_id}-process-{process_result.pid}",
            worker_url="local-process",
            task_type=process_result.task_type,
            start_time=process_result.start_time,
            end_time=process_result.end_time,
            throughput=throughput,
            latency=latency,
            errors=errors,
            metadata={
                'task_id': process_result.task_id,
                'pid': process_result.pid,
                'success': process_result.success,
                'error_message': process_result.error_message
            }
        )

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        # ç¡®ä¿æ‰€æœ‰è¿›ç¨‹å·²ç»ˆæ­¢
        for process in self._processes:
            if process.is_alive():
                self.logger.warning(f"å¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹ {process.pid}")
                process.terminate()
                process.join(timeout=5)
                if process.is_alive():
                    process.kill()

        self._processes.clear()


# ============================================================================
# è¿›ç¨‹å…¥å£å‡½æ•°ï¼ˆåœ¨å­è¿›ç¨‹ä¸­è¿è¡Œï¼‰
# ============================================================================

def _producer_process_main(
    task: ProducerTask,
    driver_config: DriverConfig,
    result_queue: mp.Queue
):
    """
    Producer è¿›ç¨‹ä¸»å‡½æ•°ï¼ˆè¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ï¼‰

    è¿™æ˜¯æ¯ä¸ª producer agent çš„å…¥å£ç‚¹ï¼Œæ¨¡æ‹ŸçœŸå®çš„ç‹¬ç«‹åº”ç”¨ã€‚
    """
    try:
        # åœ¨å­è¿›ç¨‹ä¸­éœ€è¦é‡æ–°å¯¼å…¥å’Œåˆå§‹åŒ–
        import asyncio

        # è¿è¡Œå¼‚æ­¥é€»è¾‘
        result = asyncio.run(_run_producer_async(task, driver_config))

        # è¿”å›ç»“æœ
        result_queue.put(result.to_dict())

    except Exception as e:
        # é”™è¯¯å¤„ç†
        error_result = ProcessResult(
            task_id=task.task_id,
            task_type='producer',
            pid=mp.current_process().pid,
            start_time=time.time(),
            end_time=time.time(),
            success=False,
            error_message=f"{str(e)}\n{traceback.format_exc()}"
        )
        result_queue.put(error_result.to_dict())


def _consumer_process_main(
    task: ConsumerTask,
    driver_config: DriverConfig,
    result_queue: mp.Queue
):
    """
    Consumer è¿›ç¨‹ä¸»å‡½æ•°ï¼ˆè¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ï¼‰

    è¿™æ˜¯æ¯ä¸ª consumer agent çš„å…¥å£ç‚¹ï¼Œæ¨¡æ‹ŸçœŸå®çš„ç‹¬ç«‹åº”ç”¨ã€‚
    """
    try:
        # åœ¨å­è¿›ç¨‹ä¸­éœ€è¦é‡æ–°å¯¼å…¥å’Œåˆå§‹åŒ–
        import asyncio

        # è¿è¡Œå¼‚æ­¥é€»è¾‘
        result = asyncio.run(_run_consumer_async(task, driver_config))

        # è¿”å›ç»“æœ
        result_queue.put(result.to_dict())

    except Exception as e:
        # é”™è¯¯å¤„ç†
        error_result = ProcessResult(
            task_id=task.task_id,
            task_type='consumer',
            pid=mp.current_process().pid,
            start_time=time.time(),
            end_time=time.time(),
            success=False,
            error_message=f"{str(e)}\n{traceback.format_exc()}"
        )
        result_queue.put(error_result.to_dict())


async def _run_producer_async(
    task: ProducerTask,
    driver_config: DriverConfig
) -> ProcessResult:
    """
    å¼‚æ­¥è¿è¡Œ producer é€»è¾‘ï¼ˆåœ¨å­è¿›ç¨‹ä¸­ï¼‰
    """
    from benchmark.drivers.kafka import KafkaDriver
    from benchmark.drivers.base import Message, DriverUtils
    from benchmark.utils.rate_limiter import create_rate_limiter

    pid = mp.current_process().pid
    print(f"[Producer {task.task_id} PID:{pid}] ğŸš€ å¯åŠ¨", flush=True)

    start_time = time.time()
    messages_sent = 0
    bytes_sent = 0
    errors = 0

    try:
        # 1. åˆ›å»º Driver
        driver = KafkaDriver(driver_config)
        await driver.initialize()

        # 2. åˆ›å»º Producer
        producer = driver.create_producer()
        await producer._initialize_producer()

        # 3. åˆ›å»ºé€Ÿç‡é™åˆ¶å™¨
        rate_limiter = None
        if task.rate_limit and task.rate_limit > 0:
            rate_limiter = create_rate_limiter(task.rate_limit)

        # 4. ç”Ÿæˆ payload
        payload = DriverUtils.create_test_payload(
            task.message_size,
            task.payload_data
        )

        # 5. å‘é€æ¶ˆæ¯å¾ªç¯
        print(f"[Producer {task.task_id} PID:{pid}] ğŸ“¤ å¼€å§‹å‘é€ {task.num_messages} æ¡æ¶ˆæ¯", flush=True)

        for i in range(task.num_messages):
            # é€Ÿç‡é™åˆ¶
            if rate_limiter:
                await rate_limiter.acquire()

            # ç”Ÿæˆæ¶ˆæ¯
            key = DriverUtils.generate_message_key(
                task.key_pattern, i, task.num_messages
            )

            send_timestamp_ms = int(time.time() * 1000)
            headers = {
                'send_timestamp': str(send_timestamp_ms).encode(),
                'task_id': task.task_id.encode(),
                'producer_pid': str(pid).encode()
            }

            message = Message(key, payload, headers, time.time())

            # å‘é€
            try:
                await producer.send_message(task.topic, message)
                messages_sent += 1
                bytes_sent += len(payload)
            except Exception as e:
                errors += 1
                if errors <= 10:  # åªæ‰“å°å‰ 10 ä¸ªé”™è¯¯
                    print(f"[Producer {task.task_id} PID:{pid}] âŒ å‘é€å¤±è´¥: {e}", flush=True)

            # è¿›åº¦æ—¥å¿—
            if messages_sent > 0 and messages_sent % 10000 == 0:
                print(f"[Producer {task.task_id} PID:{pid}] ğŸ“Š å·²å‘é€ {messages_sent}/{task.num_messages}", flush=True)

        # 6. åˆ·æ–°
        print(f"[Producer {task.task_id} PID:{pid}] ğŸ”„ åˆ·æ–°...", flush=True)
        await producer.flush()

        # 7. ç­‰å¾…äº¤ä»˜ç¡®è®¤
        print(f"[Producer {task.task_id} PID:{pid}] â³ ç­‰å¾…äº¤ä»˜ç¡®è®¤...", flush=True)
        delivery_status = await producer.wait_for_delivery(timeout_seconds=60)

        if delivery_status.get('timed_out'):
            pending = delivery_status.get('pending_messages', 0)
            print(f"[Producer {task.task_id} PID:{pid}] âš ï¸ è¶…æ—¶: {pending} æ¡æ¶ˆæ¯æœªç¡®è®¤", flush=True)

        # 8. è·å–å»¶è¿Ÿç»Ÿè®¡
        latency_snapshot = producer.get_latency_snapshot()

        from benchmark.utils.latency_recorder import snapshot_to_legacy_stats
        latency_stats = snapshot_to_legacy_stats(
            latency_snapshot,
            producer._latency_recorder.export_histogram()
        )

        # 9. å…³é—­
        await producer.close()
        await driver.cleanup()

        end_time = time.time()
        duration = end_time - start_time

        print(
            f"[Producer {task.task_id} PID:{pid}] âœ… å®Œæˆ: "
            f"{messages_sent} æ¡æ¶ˆæ¯, "
            f"{messages_sent/duration:.1f} msg/s, "
            f"å»¶è¿Ÿ p99={latency_snapshot.p99_ms:.2f}ms",
            flush=True
        )

        # 10. è¿”å›ç»“æœ
        return ProcessResult(
            task_id=task.task_id,
            task_type='producer',
            pid=pid,
            start_time=start_time,
            end_time=end_time,
            success=True,
            messages_sent=messages_sent,
            bytes_sent=bytes_sent,
            errors=errors,
            latency_stats=latency_stats.__dict__
        )

    except Exception as e:
        end_time = time.time()
        error_msg = f"{str(e)}\n{traceback.format_exc()}"
        print(f"[Producer {task.task_id} PID:{pid}] âŒ é”™è¯¯: {error_msg}", flush=True)

        return ProcessResult(
            task_id=task.task_id,
            task_type='producer',
            pid=pid,
            start_time=start_time,
            end_time=end_time,
            success=False,
            messages_sent=messages_sent,
            bytes_sent=bytes_sent,
            errors=errors + 1,
            error_message=error_msg
        )


async def _run_consumer_async(
    task: ConsumerTask,
    driver_config: DriverConfig
) -> ProcessResult:
    """
    å¼‚æ­¥è¿è¡Œ consumer é€»è¾‘ï¼ˆåœ¨å­è¿›ç¨‹ä¸­ï¼‰
    """
    from benchmark.drivers.kafka import KafkaDriver
    from benchmark.utils.latency_recorder import EndToEndLatencyRecorder

    pid = mp.current_process().pid
    print(f"[Consumer {task.task_id} PID:{pid}] ğŸš€ å¯åŠ¨", flush=True)

    start_time = time.time()
    messages_received = 0
    bytes_received = 0
    errors = 0

    try:
        # 1. åˆ›å»º Driver
        driver = KafkaDriver(driver_config)
        await driver.initialize()

        # 2. åˆ›å»º Consumer
        consumer = driver.create_consumer()

        # 3. è®¢é˜…
        await consumer.subscribe(task.topics, task.subscription_name)
        print(
            f"[Consumer {task.task_id} PID:{pid}] ğŸ“¥ è®¢é˜…: "
            f"topics={task.topics}, group={task.subscription_name}",
            flush=True
        )

        # 4. E2E å»¶è¿Ÿè¿½è¸ª
        e2e_latency_recorder = EndToEndLatencyRecorder()

        # 5. æ¶ˆè´¹æ¶ˆæ¯
        end_time = start_time + task.test_duration_seconds
        print(
            f"[Consumer {task.task_id} PID:{pid}] ğŸ”„ å¼€å§‹æ¶ˆè´¹ "
            f"({task.test_duration_seconds}s)...",
            flush=True
        )

        while time.time() < end_time:
            try:
                async for consumed_message in consumer.consume_messages(timeout_seconds=1.0):
                    messages_received += 1

                    # ç»Ÿè®¡å­—èŠ‚æ•°
                    if hasattr(consumed_message, 'message') and hasattr(consumed_message.message, 'value'):
                        message_value = consumed_message.message.value
                        if isinstance(message_value, (bytes, str)):
                            bytes_received += len(message_value)

                    # E2E å»¶è¿Ÿ
                    if hasattr(consumed_message, 'message') and hasattr(consumed_message.message, 'headers'):
                        headers = consumed_message.message.headers or {}
                        if 'send_timestamp' in headers:
                            try:
                                send_ts_bytes = headers['send_timestamp']
                                if isinstance(send_ts_bytes, bytes):
                                    send_timestamp_ms = float(send_ts_bytes.decode('utf-8'))
                                    e2e_latency_recorder.record_from_timestamp(send_timestamp_ms)
                            except:
                                pass

                    # è¿›åº¦æ—¥å¿—
                    if messages_received % 10000 == 0:
                        print(
                            f"[Consumer {task.task_id} PID:{pid}] ğŸ“Š å·²æ¶ˆè´¹ {messages_received}",
                            flush=True
                        )

            except Exception as e:
                errors += 1
                if errors <= 10:
                    print(f"[Consumer {task.task_id} PID:{pid}] âš ï¸ æ¶ˆè´¹é”™è¯¯: {e}", flush=True)

        # 6. å…³é—­
        await consumer.close()
        await driver.cleanup()

        actual_end_time = time.time()
        duration = actual_end_time - start_time

        # 7. E2E å»¶è¿Ÿç»Ÿè®¡
        e2e_snapshot = e2e_latency_recorder.get_snapshot()

        from benchmark.utils.latency_recorder import snapshot_to_legacy_stats
        e2e_latency_stats = snapshot_to_legacy_stats(e2e_snapshot)

        print(
            f"[Consumer {task.task_id} PID:{pid}] âœ… å®Œæˆ: "
            f"{messages_received} æ¡æ¶ˆæ¯, "
            f"{messages_received/duration:.1f} msg/s, "
            f"E2E p99={e2e_snapshot.p99_ms:.2f}ms",
            flush=True
        )

        # 8. è¿”å›ç»“æœ
        return ProcessResult(
            task_id=task.task_id,
            task_type='consumer',
            pid=pid,
            start_time=start_time,
            end_time=actual_end_time,
            success=True,
            messages_received=messages_received,
            bytes_received=bytes_received,
            errors=errors,
            latency_stats=e2e_latency_stats.__dict__
        )

    except Exception as e:
        actual_end_time = time.time()
        error_msg = f"{str(e)}\n{traceback.format_exc()}"
        print(f"[Consumer {task.task_id} PID:{pid}] âŒ é”™è¯¯: {error_msg}", flush=True)

        return ProcessResult(
            task_id=task.task_id,
            task_type='consumer',
            pid=pid,
            start_time=start_time,
            end_time=actual_end_time,
            success=False,
            messages_received=messages_received,
            bytes_received=bytes_received,
            errors=errors + 1,
            error_message=error_msg
        )
