"""
å¤šè¿›ç¨‹æ‰§è¡Œå™¨ - æ¯ä¸ª Producer/Consumer ç‹¬ç«‹è¿›ç¨‹è¿è¡Œ

è¿™ä¸ªæ¨¡å—å®ç°äº†ç±»ä¼¼ Java OMB çš„å¤šçº¿ç¨‹æ¨¡å‹ï¼Œä½†ä½¿ç”¨ Python å¤šè¿›ç¨‹æ¥ç»•è¿‡ GILã€‚
æ¯ä¸ª producer/consumer agent è¿è¡Œåœ¨ç‹¬ç«‹çš„è¿›ç¨‹ä¸­ï¼ŒçœŸå®æ¨¡æ‹Ÿå¤š agent è´Ÿè½½åœºæ™¯ã€‚
"""

import multiprocessing as mp
import asyncio
import time
import sys
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
import traceback
import json

from benchmark.core.worker import ProducerTask, ConsumerTask
from benchmark.core.config import DriverConfig
from benchmark.core.results import WorkerResult, ThroughputStats, LatencyStats, ErrorStats
from benchmark.utils.logging import LoggerMixin


@dataclass
class ProcessResult:
    """è¿›ç¨‹æ‰§è¡Œç»“æœ"""
    task_id: str
    task_type: str  # 'producer' or 'consumer'
    pid: int
    start_time: float
    end_time: float
    success: bool

    # ç»Ÿè®¡æ•°æ®
    messages_sent: int = 0
    messages_received: int = 0
    bytes_sent: int = 0
    bytes_received: int = 0
    errors: int = 0

    # å»¶è¿Ÿç»Ÿè®¡ (dict æ ¼å¼ä¾¿äºåºåˆ—åŒ–)
    latency_stats: Optional[Dict] = None

    # é”™è¯¯ä¿¡æ¯
    error_message: Optional[str] = None

    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return asdict(self)


class ProcessExecutor(LoggerMixin):
    """
    å¤šè¿›ç¨‹æ‰§è¡Œå™¨ - Java OMB style with stop signal

    è´Ÿè´£ç®¡ç†å¤šä¸ªç‹¬ç«‹çš„ producer/consumer è¿›ç¨‹ï¼Œæ¯ä¸ªä»»åŠ¡è¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ã€‚
    ä½¿ç”¨å…±äº«çš„ stop_event æ¥æ§åˆ¶æ‰€æœ‰è¿›ç¨‹çš„åœæ­¢ï¼ˆç±»ä¼¼ Java OMB çš„ testCompleted flagï¼‰ã€‚
    """

    def __init__(self, worker_id: str):
        super().__init__()
        self.worker_id = worker_id
        self._processes: List[mp.Process] = []
        self._result_queue = mp.Queue()
        self._stop_event = mp.Event()  # Shared stop signal (Java OMB style)

    def reset(self):
        """Reset executor state for a new test run."""
        self._processes.clear()
        self._stop_event.clear()
        # Clear result queue
        while not self._result_queue.empty():
            try:
                self._result_queue.get_nowait()
            except:
                break
        self.logger.info("ProcessExecutor reset for new test run")

    async def execute_producer_tasks(
        self,
        tasks: List[ProducerTask],
        driver_config: DriverConfig
    ) -> None:
        """
        å¯åŠ¨å¤šä¸ª producer ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡ä¸€ä¸ªç‹¬ç«‹è¿›ç¨‹ (Java OMB style)

        è¿›ç¨‹å°†æŒç»­è¿è¡Œç›´åˆ°æ”¶åˆ° stop ä¿¡å·ã€‚
        æ­¤æ–¹æ³•å¯åŠ¨è¿›ç¨‹åç«‹å³è¿”å›ï¼Œä¸ç­‰å¾…å®Œæˆã€‚

        Args:
            tasks: Producer ä»»åŠ¡åˆ—è¡¨
            driver_config: Driver é…ç½®
        """
        # NOTE: Do NOT clear _processes or _stop_event here!
        # In Java OMB style, consumers are started first, then producers.
        # Both share the same process list and stop signal.

        self.logger.info(f"ğŸš€ å¯åŠ¨ {len(tasks)} ä¸ªç‹¬ç«‹ Producer è¿›ç¨‹ (æŒç»­æ¨¡å¼)...")

        # å¯åŠ¨æ‰€æœ‰ producer è¿›ç¨‹ - ä¼ é€’ stop_event
        for task in tasks:
            process = mp.Process(
                target=_producer_process_main,
                args=(task, driver_config, self._result_queue, self._stop_event),  # Pass stop_event
                name=f"producer-{task.task_id}"
            )
            process.start()
            self._processes.append(process)

            self.logger.info(
                f"   âœ… å¯åŠ¨ Producer: {task.task_id} (PID: {process.pid})"
            )

        self.logger.info(f"âœ¨ æ‰€æœ‰ {len(tasks)} ä¸ª Producer è¿›ç¨‹å·²å¯åŠ¨ï¼Œç­‰å¾… stop ä¿¡å·...")

    async def execute_consumer_tasks(
        self,
        tasks: List[ConsumerTask],
        driver_config: DriverConfig
    ) -> None:
        """
        å¯åŠ¨å¤šä¸ª consumer ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡ä¸€ä¸ªç‹¬ç«‹è¿›ç¨‹ (Java OMB style)

        è¿›ç¨‹å°†æŒç»­è¿è¡Œç›´åˆ°æ”¶åˆ° stop ä¿¡å·ã€‚
        æ­¤æ–¹æ³•å¯åŠ¨è¿›ç¨‹åç«‹å³è¿”å›ï¼Œä¸ç­‰å¾…å®Œæˆã€‚

        åœ¨ Java OMB é£æ ¼ä¸­ï¼ŒConsumers å…ˆå¯åŠ¨ï¼Œæ‰€ä»¥åœ¨è¿™é‡Œé‡ç½®çŠ¶æ€ã€‚

        Args:
            tasks: Consumer ä»»åŠ¡åˆ—è¡¨
            driver_config: Driver é…ç½®
        """
        # Reset state for new test run (consumers are started first)
        self.reset()

        self.logger.info(f"ğŸš€ å¯åŠ¨ {len(tasks)} ä¸ªç‹¬ç«‹ Consumer è¿›ç¨‹ (æŒç»­æ¨¡å¼)...")

        # å¯åŠ¨æ‰€æœ‰ consumer è¿›ç¨‹ - ä¼ é€’ stop_event
        for task in tasks:
            process = mp.Process(
                target=_consumer_process_main,
                args=(task, driver_config, self._result_queue, self._stop_event),  # Pass stop_event
                name=f"consumer-{task.task_id}"
            )
            process.start()
            self._processes.append(process)

            self.logger.info(
                f"   âœ… å¯åŠ¨ Consumer: {task.task_id} (PID: {process.pid})"
            )

        self.logger.info(f"âœ¨ æ‰€æœ‰ {len(tasks)} ä¸ª Consumer è¿›ç¨‹å·²å¯åŠ¨ï¼Œç­‰å¾… stop ä¿¡å·...")

    async def stop_all(self):
        """
        Stop all running processes - Java OMB style

        Sets the stop_event to signal all processes to complete gracefully.
        """
        self.logger.info("ğŸ›‘ Setting stop signal for all processes...")
        self._stop_event.set()

    async def wait_for_completion(self) -> List[ProcessResult]:
        """
        Wait for all processes to complete and collect results.

        This should be called after stop_all() has been called.
        """
        total_processes = len(self._processes)
        self.logger.info(f"â³ Waiting for {total_processes} processes to complete...")

        results = []

        # Wait for all processes to finish
        for process in self._processes:
            process.join()

        # Collect all results
        while not self._result_queue.empty():
            try:
                result_dict = self._result_queue.get_nowait()
                result = ProcessResult(**result_dict)
                results.append(result)
            except Exception as e:
                self.logger.error(f"æ”¶é›†ç»“æœå¤±è´¥: {e}")

        if len(results) != total_processes:
            self.logger.warning(
                f"æœŸæœ› {total_processes} ä¸ªç»“æœï¼Œå®é™…æ”¶åˆ° {len(results)} ä¸ª"
            )

        self.logger.info(f"âœ… æ‰€æœ‰ {total_processes} ä¸ªè¿›ç¨‹å·²å®Œæˆï¼Œæ”¶åˆ° {len(results)} ä¸ªç»“æœ")

        return results

    def _convert_to_worker_result(self, process_result: ProcessResult) -> WorkerResult:
        """å°† ProcessResult è½¬æ¢ä¸º WorkerResult"""

        # æ„å»º ThroughputStats
        duration = process_result.end_time - process_result.start_time
        if process_result.task_type == 'producer':
            throughput = ThroughputStats(
                total_messages=process_result.messages_sent,
                total_bytes=process_result.bytes_sent,
                duration_seconds=duration,
                messages_per_second=process_result.messages_sent / duration if duration > 0 else 0,
                bytes_per_second=process_result.bytes_sent / duration if duration > 0 else 0,
                mb_per_second=(process_result.bytes_sent / duration / 1024 / 1024) if duration > 0 else 0
            )
        else:
            throughput = ThroughputStats(
                total_messages=process_result.messages_received,
                total_bytes=process_result.bytes_received,
                duration_seconds=duration,
                messages_per_second=process_result.messages_received / duration if duration > 0 else 0,
                bytes_per_second=process_result.bytes_received / duration if duration > 0 else 0,
                mb_per_second=(process_result.bytes_received / duration / 1024 / 1024) if duration > 0 else 0
            )

        # æ„å»º LatencyStats
        if process_result.latency_stats:
            latency = LatencyStats(**process_result.latency_stats)
        else:
            latency = LatencyStats(
                count=0,
                min_ms=0, max_ms=0, mean_ms=0, median_ms=0,
                p50_ms=0, p95_ms=0, p99_ms=0, p99_9_ms=0
            )

        # æ„å»º ErrorStats
        error_rate = 0.0
        if process_result.task_type == 'producer' and process_result.messages_sent > 0:
            error_rate = process_result.errors / (process_result.messages_sent + process_result.errors)

        errors = ErrorStats(
            total_errors=process_result.errors,
            error_rate=error_rate,
            error_types={}
        )

        # æ„å»º WorkerResult
        return WorkerResult(
            worker_id=f"{self.worker_id}-process-{process_result.pid}",
            worker_url="local-process",
            task_type=process_result.task_type,
            start_time=process_result.start_time,
            end_time=process_result.end_time,
            throughput=throughput,
            latency=latency,
            errors=errors,
            metadata={
                'task_id': process_result.task_id,
                'pid': process_result.pid,
                'success': process_result.success,
                'error_message': process_result.error_message
            }
        )

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        # ç¡®ä¿æ‰€æœ‰è¿›ç¨‹å·²ç»ˆæ­¢
        for process in self._processes:
            if process.is_alive():
                self.logger.warning(f"å¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹ {process.pid}")
                process.terminate()
                process.join(timeout=5)
                if process.is_alive():
                    process.kill()

        self._processes.clear()


# ============================================================================
# è¿›ç¨‹å…¥å£å‡½æ•°ï¼ˆåœ¨å­è¿›ç¨‹ä¸­è¿è¡Œï¼‰
# ============================================================================

def _producer_process_main(
    task: ProducerTask,
    driver_config: DriverConfig,
    result_queue: mp.Queue,
    stop_event: mp.Event  # NEW: stop signal from coordinator
):
    """
    Producer è¿›ç¨‹ä¸»å‡½æ•°ï¼ˆè¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ï¼‰- Java OMB style

    Runs continuously until stop_event is set by coordinator.
    æ¨¡æ‹ŸçœŸå®çš„ç‹¬ç«‹åº”ç”¨ï¼ŒæŒç»­å‘é€æ¶ˆæ¯ç›´åˆ°æ”¶åˆ°åœæ­¢ä¿¡å·ã€‚
    """
    try:
        # åœ¨å­è¿›ç¨‹ä¸­éœ€è¦é‡æ–°å¯¼å…¥å’Œåˆå§‹åŒ–
        import asyncio

        # è¿è¡Œå¼‚æ­¥é€»è¾‘ï¼ˆä¼ é€’ stop_eventï¼‰
        result = asyncio.run(_run_producer_async(task, driver_config, stop_event))

        # è¿”å›ç»“æœ
        result_queue.put(result.to_dict())

    except Exception as e:
        # é”™è¯¯å¤„ç†
        error_result = ProcessResult(
            task_id=task.task_id,
            task_type='producer',
            pid=mp.current_process().pid,
            start_time=time.time(),
            end_time=time.time(),
            success=False,
            error_message=f"{str(e)}\n{traceback.format_exc()}"
        )
        result_queue.put(error_result.to_dict())


def _consumer_process_main(
    task: ConsumerTask,
    driver_config: DriverConfig,
    result_queue: mp.Queue,
    stop_event: mp.Event  # NEW: stop signal from coordinator
):
    """
    Consumer è¿›ç¨‹ä¸»å‡½æ•°ï¼ˆè¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ï¼‰- Java OMB style

    Runs continuously until stop_event is set by coordinator.
    æ¨¡æ‹ŸçœŸå®çš„ç‹¬ç«‹åº”ç”¨ï¼ŒæŒç»­æ¶ˆè´¹æ¶ˆæ¯ç›´åˆ°æ”¶åˆ°åœæ­¢ä¿¡å·ã€‚
    """
    try:
        # åœ¨å­è¿›ç¨‹ä¸­éœ€è¦é‡æ–°å¯¼å…¥å’Œåˆå§‹åŒ–
        import asyncio

        # è¿è¡Œå¼‚æ­¥é€»è¾‘ï¼ˆä¼ é€’ stop_eventï¼‰
        result = asyncio.run(_run_consumer_async(task, driver_config, stop_event))

        # è¿”å›ç»“æœ
        result_queue.put(result.to_dict())

    except Exception as e:
        # é”™è¯¯å¤„ç†
        error_result = ProcessResult(
            task_id=task.task_id,
            task_type='consumer',
            pid=mp.current_process().pid,
            start_time=time.time(),
            end_time=time.time(),
            success=False,
            error_message=f"{str(e)}\n{traceback.format_exc()}"
        )
        result_queue.put(error_result.to_dict())


async def _run_producer_async(
    task: ProducerTask,
    driver_config: DriverConfig,
    stop_event: mp.Event
) -> ProcessResult:
    """
    å¼‚æ­¥è¿è¡Œ producer é€»è¾‘ï¼ˆåœ¨å­è¿›ç¨‹ä¸­ï¼‰- Java OMB continuous mode

    Runs continuously at specified rate until stop_event is set.
    """
    from benchmark.drivers.kafka import KafkaDriver
    from benchmark.drivers.base import Message, DriverUtils
    from benchmark.utils.rate_limiter import create_rate_limiter

    pid = mp.current_process().pid
    print(f"[Producer {task.task_id} PID:{pid}] ğŸš€ å¯åŠ¨ (æŒç»­æ¨¡å¼)", flush=True)

    start_time = time.time()
    messages_sent = 0
    bytes_sent = 0
    errors = 0

    try:
        # 1. åˆ›å»º Driver
        driver = KafkaDriver(driver_config)
        await driver.initialize()

        # 2. åˆ›å»º Producer
        producer = driver.create_producer()
        await producer._initialize_producer()

        # 3. åˆ›å»ºé€Ÿç‡é™åˆ¶å™¨
        rate_limiter = None
        if task.rate_limit and task.rate_limit > 0:
            rate_limiter = create_rate_limiter(task.rate_limit)
            print(f"[Producer {task.task_id} PID:{pid}] ğŸ“Š é€Ÿç‡é™åˆ¶: {task.rate_limit} msg/s", flush=True)

        # 4. ç”Ÿæˆ payload
        payload = DriverUtils.create_test_payload(
            task.message_size,
            task.payload_data
        )

        # 5. æŒç»­å‘é€æ¶ˆæ¯ç›´åˆ°æ”¶åˆ°åœæ­¢ä¿¡å· (Java OMB style)
        print(f"[Producer {task.task_id} PID:{pid}] ğŸ“¤ å¼€å§‹æŒç»­å‘é€æ¶ˆæ¯...", flush=True)

        message_counter = 0
        while not stop_event.is_set():
            message_counter += 1

            # é€Ÿç‡é™åˆ¶
            if rate_limiter:
                await rate_limiter.acquire()

            # ç”Ÿæˆæ¶ˆæ¯ - ä½¿ç”¨ counter è€Œä¸æ˜¯å›ºå®šçš„ num_messages
            key = DriverUtils.generate_message_key(
                task.key_pattern, message_counter, 0  # 0 means unlimited
            )

            send_timestamp_ms = int(time.time() * 1000)
            headers = {
                'send_timestamp': str(send_timestamp_ms).encode(),
                'task_id': task.task_id.encode(),
                'producer_pid': str(pid).encode()
            }

            message = Message(key, payload, headers, time.time())

            # å‘é€
            try:
                await producer.send_message(task.topic, message)
                messages_sent += 1
                bytes_sent += len(payload)
            except Exception as e:
                errors += 1
                if errors <= 10:  # åªæ‰“å°å‰ 10 ä¸ªé”™è¯¯
                    print(f"[Producer {task.task_id} PID:{pid}] âŒ å‘é€å¤±è´¥: {e}", flush=True)

            # è¿›åº¦æ—¥å¿— (æ¯10000æ¡æ‰“å°ä¸€æ¬¡)
            if messages_sent > 0 and messages_sent % 10000 == 0:
                elapsed = time.time() - start_time
                rate = messages_sent / elapsed if elapsed > 0 else 0
                print(f"[Producer {task.task_id} PID:{pid}] ğŸ“Š å·²å‘é€ {messages_sent} æ¡ ({rate:.1f} msg/s)", flush=True)

        # 6. åˆ·æ–°
        print(f"[Producer {task.task_id} PID:{pid}] ğŸ”„ åˆ·æ–°...", flush=True)
        await producer.flush()

        # 7. ç­‰å¾…äº¤ä»˜ç¡®è®¤
        print(f"[Producer {task.task_id} PID:{pid}] â³ ç­‰å¾…äº¤ä»˜ç¡®è®¤...", flush=True)
        delivery_status = await producer.wait_for_delivery(timeout_seconds=60)

        if delivery_status.get('timed_out'):
            pending = delivery_status.get('pending_messages', 0)
            print(f"[Producer {task.task_id} PID:{pid}] âš ï¸ è¶…æ—¶: {pending} æ¡æ¶ˆæ¯æœªç¡®è®¤", flush=True)

        # 8. è·å–å»¶è¿Ÿç»Ÿè®¡
        latency_snapshot = producer.get_latency_snapshot()

        from benchmark.utils.latency_recorder import snapshot_to_legacy_stats
        latency_stats = snapshot_to_legacy_stats(
            latency_snapshot,
            producer._latency_recorder.export_histogram()
        )

        # 9. å…³é—­
        await producer.close()
        await driver.cleanup()

        end_time = time.time()
        duration = end_time - start_time

        print(
            f"[Producer {task.task_id} PID:{pid}] âœ… å®Œæˆ: "
            f"{messages_sent} æ¡æ¶ˆæ¯, "
            f"{messages_sent/duration:.1f} msg/s, "
            f"å»¶è¿Ÿ p99={latency_snapshot.p99_ms:.2f}ms",
            flush=True
        )

        # 10. è¿”å›ç»“æœ
        return ProcessResult(
            task_id=task.task_id,
            task_type='producer',
            pid=pid,
            start_time=start_time,
            end_time=end_time,
            success=True,
            messages_sent=messages_sent,
            bytes_sent=bytes_sent,
            errors=errors,
            latency_stats=latency_stats.__dict__
        )

    except Exception as e:
        end_time = time.time()
        error_msg = f"{str(e)}\n{traceback.format_exc()}"
        print(f"[Producer {task.task_id} PID:{pid}] âŒ é”™è¯¯: {error_msg}", flush=True)

        return ProcessResult(
            task_id=task.task_id,
            task_type='producer',
            pid=pid,
            start_time=start_time,
            end_time=end_time,
            success=False,
            messages_sent=messages_sent,
            bytes_sent=bytes_sent,
            errors=errors + 1,
            error_message=error_msg
        )


async def _run_consumer_async(
    task: ConsumerTask,
    driver_config: DriverConfig,
    stop_event: mp.Event
) -> ProcessResult:
    """
    å¼‚æ­¥è¿è¡Œ consumer é€»è¾‘ï¼ˆåœ¨å­è¿›ç¨‹ä¸­ï¼‰- Java OMB continuous mode

    Runs continuously until stop_event is set by coordinator.
    """
    from benchmark.drivers.kafka import KafkaDriver
    from benchmark.utils.latency_recorder import EndToEndLatencyRecorder

    pid = mp.current_process().pid
    print(f"[Consumer {task.task_id} PID:{pid}] ğŸš€ å¯åŠ¨ (æŒç»­æ¨¡å¼)", flush=True)

    start_time = time.time()
    messages_received = 0
    bytes_received = 0
    errors = 0

    try:
        # 1. åˆ›å»º Driver
        driver = KafkaDriver(driver_config)
        await driver.initialize()

        # 2. åˆ›å»º Consumer
        consumer = driver.create_consumer()

        # 3. è®¢é˜…
        await consumer.subscribe(task.topics, task.subscription_name)
        print(
            f"[Consumer {task.task_id} PID:{pid}] ğŸ“¥ è®¢é˜…: "
            f"topics={task.topics}, group={task.subscription_name}",
            flush=True
        )

        # 4. E2E å»¶è¿Ÿè¿½è¸ª
        e2e_latency_recorder = EndToEndLatencyRecorder()

        # 5. æŒç»­æ¶ˆè´¹æ¶ˆæ¯ç›´åˆ°æ”¶åˆ°åœæ­¢ä¿¡å· (Java OMB style)
        print(
            f"[Consumer {task.task_id} PID:{pid}] ğŸ”„ å¼€å§‹æŒç»­æ¶ˆè´¹æ¶ˆæ¯...",
            flush=True
        )

        while not stop_event.is_set():
            try:
                async for consumed_message in consumer.consume_messages(timeout_seconds=1.0):
                    messages_received += 1

                    # ç»Ÿè®¡å­—èŠ‚æ•°
                    if hasattr(consumed_message, 'message') and hasattr(consumed_message.message, 'value'):
                        message_value = consumed_message.message.value
                        if isinstance(message_value, (bytes, str)):
                            bytes_received += len(message_value)

                    # E2E å»¶è¿Ÿ
                    if hasattr(consumed_message, 'message') and hasattr(consumed_message.message, 'headers'):
                        headers = consumed_message.message.headers or {}
                        if 'send_timestamp' in headers:
                            try:
                                send_ts_bytes = headers['send_timestamp']
                                if isinstance(send_ts_bytes, bytes):
                                    send_timestamp_ms = float(send_ts_bytes.decode('utf-8'))
                                    e2e_latency_recorder.record_from_timestamp(send_timestamp_ms)
                            except:
                                pass

                    # è¿›åº¦æ—¥å¿— (æ¯10000æ¡æ‰“å°ä¸€æ¬¡)
                    if messages_received % 10000 == 0:
                        elapsed = time.time() - start_time
                        rate = messages_received / elapsed if elapsed > 0 else 0
                        print(
                            f"[Consumer {task.task_id} PID:{pid}] ğŸ“Š å·²æ¶ˆè´¹ {messages_received} æ¡ ({rate:.1f} msg/s)",
                            flush=True
                        )

            except Exception as e:
                errors += 1
                if errors <= 10:
                    print(f"[Consumer {task.task_id} PID:{pid}] âš ï¸ æ¶ˆè´¹é”™è¯¯: {e}", flush=True)

        # 6. å…³é—­
        await consumer.close()
        await driver.cleanup()

        actual_end_time = time.time()
        duration = actual_end_time - start_time

        # 7. E2E å»¶è¿Ÿç»Ÿè®¡
        e2e_snapshot = e2e_latency_recorder.get_snapshot()

        from benchmark.utils.latency_recorder import snapshot_to_legacy_stats
        e2e_latency_stats = snapshot_to_legacy_stats(e2e_snapshot)

        print(
            f"[Consumer {task.task_id} PID:{pid}] âœ… å®Œæˆ: "
            f"{messages_received} æ¡æ¶ˆæ¯, "
            f"{messages_received/duration:.1f} msg/s, "
            f"E2E p99={e2e_snapshot.p99_ms:.2f}ms",
            flush=True
        )

        # 8. è¿”å›ç»“æœ
        return ProcessResult(
            task_id=task.task_id,
            task_type='consumer',
            pid=pid,
            start_time=start_time,
            end_time=actual_end_time,
            success=True,
            messages_received=messages_received,
            bytes_received=bytes_received,
            errors=errors,
            latency_stats=e2e_latency_stats.__dict__
        )

    except Exception as e:
        actual_end_time = time.time()
        error_msg = f"{str(e)}\n{traceback.format_exc()}"
        print(f"[Consumer {task.task_id} PID:{pid}] âŒ é”™è¯¯: {error_msg}", flush=True)

        return ProcessResult(
            task_id=task.task_id,
            task_type='consumer',
            pid=pid,
            start_time=start_time,
            end_time=actual_end_time,
            success=False,
            messages_received=messages_received,
            bytes_received=bytes_received,
            errors=errors + 1,
            error_message=error_msg
        )
