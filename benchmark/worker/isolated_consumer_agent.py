# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
ISOLATEDæ¨¡å¼Consumer Agent Worker - ç‹¬ç«‹è¿›ç¨‹å®ç°
æ¯ä¸ªConsumer Agentä½œä¸ºç‹¬ç«‹è¿›ç¨‹è¿è¡Œï¼Œå®Œå…¨éš”ç¦»
"""

import logging
import time


def isolated_consumer_agent(agent_id, topic, subscription_name, kafka_consumer_config,
                            stop_event, stats_queue, reset_flag, ready_queue):
    """
    ç‹¬ç«‹Consumer Agentè¿›ç¨‹å·¥ä½œå‡½æ•° - ISOLATEDæ¨¡å¼

    :param agent_id: Agentå”¯ä¸€ID
    :param topic: è¦è®¢é˜…çš„ä¸»é¢˜
    :param subscription_name: Consumer group name
    :param kafka_consumer_config: Kafka Consumeré…ç½®å­—å…¸
    :param stop_event: multiprocessing.Event - åœæ­¢ä¿¡å·
    :param stats_queue: multiprocessing.Queue - ç»Ÿè®¡æ•°æ®é˜Ÿåˆ—
    :param reset_flag: multiprocessing.Value - é‡ç½®æ ‡å¿—ï¼ˆepochè®¡æ•°å™¨ï¼‰
    :param ready_queue: multiprocessing.Queue - å°±ç»ª/é”™è¯¯ä¿¡å·é˜Ÿåˆ—
    """
    # è®¾ç½®è¿›ç¨‹çº§æ—¥å¿—
    logger = logging.getLogger(f"consumer-agent-{agent_id}")
    logger.setLevel(logging.INFO)

    try:
        # é€šçŸ¥ä¸»è¿›ç¨‹ï¼šAgentæ­£åœ¨åˆå§‹åŒ–
        logger.info(f"Consumer Agent {agent_id} initializing...")

        # åœ¨è¿›ç¨‹å†…å¯¼å…¥ï¼ˆé¿å…åºåˆ—åŒ–é—®é¢˜ï¼‰
        from confluent_kafka import Consumer, KafkaError
        from hdrh.histogram import HdrHistogram

        logger.info(f"Consumer Agent {agent_id} starting (independent consumer process)")

        # 1. åˆ›å»ºç‹¬ç«‹çš„Kafka Consumer
        consumer_config = kafka_consumer_config.copy()
        consumer_config['group.id'] = subscription_name
        consumer_config['client.id'] = f'consumer-agent-{agent_id}'
        consumer = Consumer(consumer_config)

        # 1.5 å®šä¹‰ Rebalance Callbackï¼ˆç”¨äºç›‘æ§å’Œè°ƒè¯•ï¼‰
        rebalance_count = {'count': 0, 'last_time': time.time()}

        def on_assign(consumer, partitions):
            """å½“åˆ†åŒºè¢«åˆ†é…ç»™è¿™ä¸ª consumer æ—¶è°ƒç”¨"""
            rebalance_count['count'] += 1
            rebalance_count['last_time'] = time.time()
            partition_ids = [p.partition for p in partitions]
            logger.info(
                f"ğŸ”„ Consumer Agent {agent_id} REBALANCE #{rebalance_count['count']}: "
                f"Assigned {len(partitions)} partitions: {partition_ids}"
            )

        def on_revoke(consumer, partitions):
            """å½“åˆ†åŒºä»è¿™ä¸ª consumer æ’¤é”€æ—¶è°ƒç”¨"""
            partition_ids = [p.partition for p in partitions]
            logger.info(
                f"âš ï¸  Consumer Agent {agent_id} REBALANCE: "
                f"Revoked {len(partitions)} partitions: {partition_ids}"
            )

        def on_lost(consumer, partitions):
            """å½“åˆ†åŒºä¸¢å¤±æ—¶è°ƒç”¨ï¼ˆå¦‚è¶…æ—¶ï¼‰"""
            partition_ids = [p.partition for p in partitions]
            logger.warning(
                f"âŒ Consumer Agent {agent_id} PARTITION LOST: "
                f"Lost {len(partitions)} partitions: {partition_ids}"
            )

        # 2. è®¢é˜…topicï¼ˆå¸¦ rebalance callbackï¼‰
        consumer.subscribe([topic], on_assign=on_assign, on_revoke=on_revoke, on_lost=on_lost)
        logger.info(f"Consumer Agent {agent_id} subscribed to topic: {topic}, group: {subscription_name}")

        # 3. æœ¬åœ°ç»Ÿè®¡å¯¹è±¡ï¼ˆè¿›ç¨‹å†…ç‹¬ç«‹ï¼‰
        # ä½¿ç”¨HdrHistogramæ›¿ä»£listï¼ˆä¸Javaç‰ˆæœ¬ä¸€è‡´ï¼‰
        class LocalStats:
            def __init__(self):
                self.messages_received = 0
                self.bytes_received = 0
                # End-to-endå»¶è¿Ÿhistogramï¼ˆèŒƒå›´æ›´å¤§ï¼š12å°æ—¶ï¼‰
                self.e2e_latency_histogram = HdrHistogram(1, 12 * 60 * 60 * 1_000, 5)

            def record_e2e_latency(self, latency_ms):
                """è®°å½•ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰"""
                if 0 < latency_ms <= 12 * 60 * 60 * 1_000:
                    self.e2e_latency_histogram.record_value(int(latency_ms))

            def reset_histogram(self):
                """é‡ç½®histogram"""
                self.e2e_latency_histogram = HdrHistogram(1, 12 * 60 * 60 * 1_000, 5)

        local_stats = LocalStats()

        # å‘é€å°±ç»ªä¿¡å·ç»™ä¸»è¿›ç¨‹
        try:
            ready_queue.put({'agent_id': agent_id, 'status': 'ready', 'type': 'consumer'}, timeout=1.0)
            logger.info(f"Consumer Agent {agent_id} is ready")
        except Exception as e:
            logger.error(f"Consumer Agent {agent_id} failed to send ready signal: {e}")

        # 4. ç»Ÿè®¡æ±‡æŠ¥æ—¶é—´å’Œepochè·Ÿè¸ª
        last_stats_report = time.time()
        last_epoch_check = time.time()
        current_epoch = reset_flag.value if reset_flag else 0

        # 4.5 æ–‡ä»¶è¾“å‡ºé…ç½®ï¼ˆåŒè¾“å‡ºæ¨¡å¼ï¼šQueue + Fileï¼‰
        import os
        import pickle
        from pathlib import Path
        # âœ… ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œåœ¨å½“å‰å·¥ä½œç›®å½•ä¸‹åˆ›å»º benchmark_results æ–‡ä»¶å¤¹
        stats_dir = Path.cwd() / "benchmark_results"
        stats_dir.mkdir(parents=True, exist_ok=True)
        stats_file = stats_dir / f"consumer_{agent_id}_stats.pkl"
        last_file_write = time.time()
        file_write_interval = 5  # æ¯5ç§’å†™ä¸€æ¬¡æ–‡ä»¶

        # 5. Consumerä¸»å¾ªç¯
        message_count = 0  # æ€»æ¶ˆæ¯è®¡æ•°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        test_message_count = 0  # æµ‹è¯•é˜¶æ®µæ¶ˆæ¯è®¡æ•°ï¼ˆç”¨äºç»Ÿè®¡æ–‡ä»¶ï¼‰

        while not stop_event.is_set():
            try:
                # 5.1 æ‰¹é‡Pollæ¶ˆæ¯ï¼ˆä¸€æ¬¡æœ€å¤š100æ¡ï¼Œtimeout 100msï¼‰
                # âœ… ä¼˜åŒ–ï¼šå‡å°‘ timeout ä» 1ç§’åˆ° 100msï¼Œé™ä½å»¶è¿Ÿ
                messages = consumer.consume(num_messages=100, timeout=0.1)

                if not messages:
                    # æ²¡æœ‰æ¶ˆæ¯ï¼Œç»§ç»­
                    pass
                else:
                    # æ‰¹é‡å¤„ç†æ¶ˆæ¯
                    for msg in messages:
                        if msg.error():
                            # é”™è¯¯å¤„ç†
                            if msg.error().code() == KafkaError._PARTITION_EOF:
                                # åˆ†åŒºæœ«å°¾ï¼Œæ­£å¸¸æƒ…å†µ
                                logger.debug(f"Consumer Agent {agent_id} reached end of partition {msg.partition()}")
                            else:
                                logger.error(f"Consumer Agent {agent_id} error: {msg.error()}")
                            continue

                        # æˆåŠŸæ¥æ”¶æ¶ˆæ¯
                        message_count += 1  # æ€»è®¡æ•°ï¼ˆå«warmupï¼‰
                        test_message_count += 1  # æµ‹è¯•é˜¶æ®µè®¡æ•°
                        local_stats.messages_received += 1

                        # ä» payload ä¸­æå–æ—¶é—´æˆ³ï¼ˆå‰8å­—èŠ‚ï¼‰
                        payload = msg.value()
                        if payload and len(payload) >= 8:
                            import struct
                            # è§£æå‰8å­—èŠ‚çš„æ—¶é—´æˆ³ï¼ˆå¤§ç«¯åºï¼‰
                            publish_timestamp_ms = struct.unpack('>Q', payload[:8])[0]
                            receive_timestamp_ms = int(time.time() * 1000)
                            e2e_latency_ms = receive_timestamp_ms - publish_timestamp_ms

                            # ç»Ÿè®¡å®Œæ•´æ¶ˆæ¯å¤§å°ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰ï¼Œä¸Producerä¿æŒä¸€è‡´
                            # è¿™æ ·Producerå‘é€çš„bytes_sentå’ŒConsumeræ¥æ”¶çš„bytes_receivedèƒ½å¯¹åº”ä¸Š
                            local_stats.bytes_received += len(payload)

                            if message_count <= 5:
                                logger.info(f"Consumer Agent {agent_id} msg {message_count}: E2E latency={e2e_latency_ms} ms (pub={publish_timestamp_ms}, recv={receive_timestamp_ms})")

                            # è®°å½•åˆ°histogramï¼ˆä¸Javaç‰ˆæœ¬ä¸€è‡´ï¼‰
                            local_stats.record_e2e_latency(e2e_latency_ms)
                        else:
                            # Payload å¤ªå°æˆ–ä¸ºç©ºï¼Œæ— æ³•æå–æ—¶é—´æˆ³
                            local_stats.bytes_received += len(payload) if payload else 0
                            if message_count <= 5:
                                logger.warning(f"Consumer Agent {agent_id} msg {message_count}: Payload too small ({len(payload) if payload else 0} bytes), cannot extract timestamp")

                # 5.2 æ£€æŸ¥epoché‡ç½®ï¼ˆæ¯ç§’æ£€æŸ¥ä¸€æ¬¡ï¼‰
                now = time.time()
                if now - last_epoch_check > 1.0:
                    if reset_flag:
                        new_epoch = reset_flag.value
                        if new_epoch > current_epoch:
                            logger.info(f"Consumer Agent {agent_id} detected stats reset: epoch {current_epoch} -> {new_epoch}")
                            current_epoch = new_epoch
                            # é‡ç½®æœ¬åœ°ç»Ÿè®¡
                            local_stats.messages_received = 0
                            local_stats.bytes_received = 0
                            local_stats.reset_histogram()
                            # âœ… é‡ç½®æµ‹è¯•é˜¶æ®µæ¶ˆæ¯è®¡æ•°ï¼ˆä¸histogramä¿æŒåŒæ­¥ï¼‰
                            test_message_count = 0

                    last_epoch_check = now

                # 5.3 å®šæœŸæ±‡æŠ¥ç»Ÿè®¡ï¼ˆæ¯ç§’ä¸€æ¬¡ï¼‰- å·²æ³¨é‡Šï¼Œä»…ä½¿ç”¨æ–‡ä»¶è¾“å‡º
                # if now - last_stats_report >= 1.0:
                #     try:
                #         # å‘é€histogramç¼–ç æ•°æ®ï¼ˆä¸Javaç‰ˆæœ¬ä¸€è‡´ï¼‰
                #         # æ³¨æ„ï¼šåªå‘é€å‘¨æœŸè®¡æ•°å™¨ï¼Œhistogramä¸é‡ç½®ï¼ˆç´¯ç§¯ç»Ÿè®¡ï¼‰
                #         stats_dict = {
                #             'agent_id': agent_id,
                #             'type': 'consumer',
                #             'messages_received': local_stats.messages_received,
                #             'bytes_received': local_stats.bytes_received,
                #             'timestamp': now,
                #             'epoch': current_epoch,
                #             # å‘é€ç¼–ç åçš„histogramï¼ˆç´¯ç§¯æ•°æ®ï¼Œä¸é‡ç½®ï¼‰
                #             'e2e_latency_histogram_encoded': local_stats.e2e_latency_histogram.encode(),
                #         }
                #
                #         # ä½¿ç”¨å¸¦è¶…æ—¶çš„putï¼Œé¿å…é˜Ÿåˆ—æ»¡æ—¶é˜»å¡
                #         try:
                #             stats_queue.put(stats_dict, timeout=0.1)
                #             # åªé‡ç½®å‘¨æœŸè®¡æ•°å™¨ï¼Œä¸é‡ç½®histogramï¼ˆhistogramæ˜¯ç´¯ç§¯çš„ï¼‰
                #             local_stats.messages_received = 0
                #             local_stats.bytes_received = 0
                #         except:
                #             logger.warning(f"Consumer Agent {agent_id} stats queue full, dropping stats report")
                #             # å³ä½¿é˜Ÿåˆ—æ»¡ï¼Œä¹Ÿé‡ç½®è®¡æ•°å™¨é¿å…é‡å¤è®¡æ•°
                #             local_stats.messages_received = 0
                #             local_stats.bytes_received = 0
                #
                #     except Exception as e:
                #         logger.error(f"Consumer Agent {agent_id} failed to send stats: {e}", exc_info=True)
                #
                #     last_stats_report = now

                # 5.4 å®šæœŸå†™å…¥æ–‡ä»¶ï¼ˆæ¯5ç§’ä¸€æ¬¡ï¼‰
                if now - last_file_write >= file_write_interval:
                    try:
                        # å†™å…¥ç´¯ç§¯ç»Ÿè®¡åˆ°æ–‡ä»¶
                        # âœ… ä½¿ç”¨ test_message_countï¼ˆä»…æµ‹è¯•é˜¶æ®µï¼‰è€Œé message_countï¼ˆå«warmupï¼‰
                        file_data = {
                            'agent_id': agent_id,
                            'total_messages_received': test_message_count,
                            'e2e_latency_histogram_encoded': local_stats.e2e_latency_histogram.encode(),
                            'timestamp': now,
                            'epoch': current_epoch
                        }

                        # åŸå­å†™å…¥
                        temp_file = stats_file.with_suffix('.tmp')
                        with open(temp_file, 'wb') as f:
                            pickle.dump(file_data, f)
                        temp_file.rename(stats_file)

                        logger.debug(f"Consumer Agent {agent_id} wrote stats to {stats_file}")
                        last_file_write = now
                    except Exception as e:
                        logger.error(f"Consumer Agent {agent_id} failed to write stats file: {e}", exc_info=True)

            except KeyboardInterrupt:
                logger.info(f"Consumer Agent {agent_id} received keyboard interrupt, stopping...")
                break
            except Exception as e:
                logger.error(f"Consumer Agent {agent_id} error in poll loop: {e}", exc_info=True)
                time.sleep(0.1)

        logger.info(f"Consumer Agent {agent_id} stopping gracefully (received {message_count} messages total)")

    except Exception as e:
        logger.error(f"Consumer Agent {agent_id} fatal error: {e}", exc_info=True)
        # å‘é€é”™è¯¯ä¿¡å·ç»™ä¸»è¿›ç¨‹
        try:
            ready_queue.put({'agent_id': agent_id, 'status': 'error', 'type': 'consumer', 'error': str(e)}, timeout=0.5)
        except:
            pass

    finally:
        # 6. æ¸…ç†èµ„æº
        try:
            consumer.close()
            logger.info(f"Consumer Agent {agent_id} closed consumer")
        except Exception as e:
            logger.error(f"Consumer Agent {agent_id} error closing consumer: {e}")

        # 7. å†™å…¥æœ€ç»ˆç»Ÿè®¡åˆ°æ–‡ä»¶
        # âœ… ä½¿ç”¨ test_message_countï¼ˆä»…æµ‹è¯•é˜¶æ®µï¼‰è€Œé message_countï¼ˆå«warmupï¼‰
        try:
            final_file_data = {
                'agent_id': agent_id,
                'total_messages_received': test_message_count,
                'e2e_latency_histogram_encoded': local_stats.e2e_latency_histogram.encode(),
                'timestamp': time.time(),
                'epoch': current_epoch,
                'final': True
            }
            with open(stats_file, 'wb') as f:
                pickle.dump(final_file_data, f)
            logger.info(f"Consumer Agent {agent_id} wrote final stats to {stats_file}")
        except Exception as e:
            logger.error(f"Consumer Agent {agent_id} error writing final stats file: {e}")

        # 8. å‘é€æœ€ç»ˆç»Ÿè®¡åˆ°Queue - å·²æ³¨é‡Šï¼Œä»…ä½¿ç”¨æ–‡ä»¶è¾“å‡º
        # try:
        #     final_stats = {
        #         'agent_id': agent_id,
        #         'type': 'consumer',
        #         'final': True,
        #         'total_messages': message_count
        #     }
        #     stats_queue.put(final_stats, timeout=1.0)
        # except Exception as e:
        #     logger.error(f"Consumer Agent {agent_id} error sending final stats: {e}")

        logger.info(f"Consumer Agent {agent_id} terminated")
