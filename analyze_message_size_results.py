#!/usr/bin/env python3
"""
æ¶ˆæ¯å¤§å°æ€§èƒ½å®éªŒç»“æœåˆ†æè„šæœ¬
åˆ†æä¸åŒæ¶ˆæ¯å¤§å°å¯¹Kafkaæ€§èƒ½çš„å½±å“
"""

import json
import glob
import os
from typing import List, Dict
import statistics


def load_results() -> List[Dict]:
    """åŠ è½½æ‰€æœ‰msg-sizeæµ‹è¯•ç»“æœ"""
    results = []

    # æŸ¥æ‰¾æ‰€æœ‰msg-sizeå¼€å¤´çš„JSONæ–‡ä»¶
    pattern = "msg-size-*-Kafka-*.json"
    files = glob.glob(pattern)

    if not files:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•ç»“æœæ–‡ä»¶ï¼")
        print(f"   æŸ¥æ‰¾æ¨¡å¼: {pattern}")
        print(f"   å½“å‰ç›®å½•: {os.getcwd()}")
        return []

    print(f"ğŸ“‚ æ‰¾åˆ° {len(files)} ä¸ªç»“æœæ–‡ä»¶\n")

    for file_path in sorted(files):
        with open(file_path, 'r') as f:
            data = json.load(f)
            results.append({
                'file': file_path,
                'data': data
            })

    return results


def calculate_throughput(msg_size_bytes: int, msg_rate: float) -> Dict[str, float]:
    """è®¡ç®—ååé‡ (MB/s)"""
    bytes_per_sec = msg_size_bytes * msg_rate
    mb_per_sec = bytes_per_sec / (1024 * 1024)

    return {
        'msg_rate': msg_rate,
        'bytes_per_sec': bytes_per_sec,
        'mb_per_sec': mb_per_sec
    }


def analyze_results(results: List[Dict]):
    """åˆ†æç»“æœå¹¶ç”Ÿæˆå¯¹æ¯”è¡¨"""

    if not results:
        print("æ²¡æœ‰ç»“æœå¯åˆ†æ")
        return

    print("=" * 100)
    print("æ¶ˆæ¯å¤§å°æ€§èƒ½å¯¹æ¯”åˆ†æ")
    print("=" * 100)
    print()

    # è¡¨å¤´
    print(f"{'æ¶ˆæ¯å¤§å°':<12} {'ååé‡(msg/s)':<15} {'ååé‡(MB/s)':<15} "
          f"{'P50å»¶è¿Ÿ(ms)':<15} {'P99å»¶è¿Ÿ(ms)':<15} {'P99.9å»¶è¿Ÿ(ms)':<15} "
          f"{'é”™è¯¯ç‡':<10} {'ç§¯å‹':<10}")
    print("-" * 100)

    # æ•°æ®è¡Œ
    analysis_data = []

    for result in results:
        data = result['data']
        msg_size = data['messageSize']

        # è®¡ç®—å¹³å‡ååé‡
        avg_msg_rate = statistics.mean(data['publishRate'])
        throughput = calculate_throughput(msg_size, avg_msg_rate)

        # è·å–å»¶è¿ŸæŒ‡æ ‡
        p50 = data['aggregatedPublishLatency50pct']
        p99 = data['aggregatedPublishLatency99pct']
        p999 = data['aggregatedPublishLatency999pct']

        # è·å–é”™è¯¯ç‡
        avg_error_rate = statistics.mean(data['publishErrorRate'])

        # è·å–å¹³å‡ç§¯å‹
        avg_backlog = statistics.mean(data['backlog'])

        # æ ¼å¼åŒ–æ¶ˆæ¯å¤§å°
        if msg_size >= 1024:
            size_str = f"{msg_size // 1024} KB"
        else:
            size_str = f"{msg_size} B"

        print(f"{size_str:<12} {avg_msg_rate:<15.1f} {throughput['mb_per_sec']:<15.2f} "
              f"{p50:<15.2f} {p99:<15.2f} {p999:<15.2f} "
              f"{avg_error_rate:<10.2f} {avg_backlog:<10.0f}")

        # ä¿å­˜ç”¨äºåç»­åˆ†æ
        analysis_data.append({
            'msg_size': msg_size,
            'size_str': size_str,
            'msg_rate': avg_msg_rate,
            'mb_per_sec': throughput['mb_per_sec'],
            'p50': p50,
            'p99': p99,
            'p999': p999,
            'error_rate': avg_error_rate,
            'backlog': avg_backlog
        })

    print()
    print("=" * 100)
    print()

    # å…³é”®å‘ç°
    print("ğŸ“Š å…³é”®å‘ç°:")
    print()

    if len(analysis_data) >= 2:
        # ååé‡åˆ†æ
        print("1. ååé‡è¶‹åŠ¿:")
        baseline = analysis_data[0]
        for i, item in enumerate(analysis_data):
            if i == 0:
                print(f"   - {item['size_str']}: {item['mb_per_sec']:.2f} MB/s (åŸºçº¿)")
            else:
                ratio = item['mb_per_sec'] / baseline['mb_per_sec']
                change = ((item['mb_per_sec'] - baseline['mb_per_sec']) / baseline['mb_per_sec']) * 100
                print(f"   - {item['size_str']}: {item['mb_per_sec']:.2f} MB/s "
                      f"({change:+.1f}%, {ratio:.2f}xåŸºçº¿)")
        print()

        # å»¶è¿Ÿåˆ†æ
        print("2. P99å»¶è¿Ÿè¶‹åŠ¿:")
        for i, item in enumerate(analysis_data):
            if i == 0:
                print(f"   - {item['size_str']}: {item['p99']:.2f} ms (åŸºçº¿)")
            else:
                change = ((item['p99'] - baseline['p99']) / baseline['p99']) * 100
                print(f"   - {item['size_str']}: {item['p99']:.2f} ms ({change:+.1f}%)")
        print()

        # ç¨³å®šæ€§åˆ†æ
        print("3. ç¨³å®šæ€§åˆ†æ:")
        stable_tests = [item for item in analysis_data if item['error_rate'] == 0 and item['backlog'] < 1000]
        if stable_tests:
            print(f"   - {len(stable_tests)}/{len(analysis_data)} ä¸ªæµ‹è¯•å®Œå…¨ç¨³å®š (é›¶é”™è¯¯ï¼Œä½ç§¯å‹)")
            if len(stable_tests) < len(analysis_data):
                unstable = [item for item in analysis_data if item not in stable_tests]
                print(f"   - ä¸ç¨³å®šçš„é…ç½®: {', '.join([item['size_str'] for item in unstable])}")
        print()

        # æœ€ä¼˜é…ç½®æ¨è
        print("4. æ¨èé…ç½®:")
        best_throughput = max(analysis_data, key=lambda x: x['mb_per_sec'])
        best_latency = min(analysis_data, key=lambda x: x['p99'])

        print(f"   - æœ€é«˜ååé‡: {best_throughput['size_str']} ({best_throughput['mb_per_sec']:.2f} MB/s)")
        print(f"   - æœ€ä½å»¶è¿Ÿ:   {best_latency['size_str']} (P99={best_latency['p99']:.2f} ms)")

        # ç»¼åˆè¯„åˆ† (ååé‡ / å»¶è¿Ÿ)
        for item in analysis_data:
            item['score'] = item['mb_per_sec'] / (item['p99'] / 100)  # å½’ä¸€åŒ–å»¶è¿Ÿ

        best_overall = max(analysis_data, key=lambda x: x['score'])
        print(f"   - ç»¼åˆæœ€ä¼˜:   {best_overall['size_str']} (é«˜åå+ä½å»¶è¿Ÿ)")
        print()


def main():
    print()
    print("ğŸ”¬ æ¶ˆæ¯å¤§å°æ€§èƒ½å®éªŒç»“æœåˆ†æ")
    print()

    results = load_results()

    if results:
        analyze_results(results)
        print("âœ… åˆ†æå®Œæˆ")
    else:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å®éªŒç»“æœ")
        print()
        print("è¯·å…ˆè¿è¡Œå®éªŒ:")
        print("  bash run_message_size_experiment.sh")

    print()


if __name__ == '__main__':
    main()
