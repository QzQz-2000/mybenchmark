# OpenMessaging Benchmark - Python å®ç°æ€»ç»“

## ğŸ“‹ ç›®å½•
- [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
- [æ¶æ„è½¬æ¢](#æ¶æ„è½¬æ¢)
- [æ ¸å¿ƒç»„ä»¶è®¾è®¡](#æ ¸å¿ƒç»„ä»¶è®¾è®¡)
- [å…³é”®å®ç°ç»†èŠ‚](#å…³é”®å®ç°ç»†èŠ‚)
- [æ€§èƒ½åˆ†æ](#æ€§èƒ½åˆ†æ)
- [å¾…æ”¹è¿›é¡¹](#å¾…æ”¹è¿›é¡¹)
- [ä½¿ç”¨æŒ‡å—](#ä½¿ç”¨æŒ‡å—)

---

## é¡¹ç›®æ¦‚è¿°

### è½¬æ¢ç›®æ ‡
å°† OpenMessaging Benchmark ä» **kafka-python + threading** è½¬æ¢ä¸º **confluent-kafka + multiprocessing/threading æ··åˆæ¶æ„**

### æ ¸å¿ƒæ”¹åŠ¨
1. âœ… Kafka å®¢æˆ·ç«¯åº“ï¼š`kafka-python` â†’ `confluent-kafka-python`
2. âœ… å¹¶å‘æ¨¡å‹ï¼šå•ä¸€ threading â†’ multiprocessing + threading æ··åˆ
3. âœ… èµ„æºç®¡ç†ï¼šæ·»åŠ å¹‚ç­‰æ€§æ¸…ç†æœºåˆ¶

---

## æ¶æ„è½¬æ¢

### 1. Kafka å®¢æˆ·ç«¯è¿ç§»

#### é…ç½®å‚æ•°æ˜ å°„
| kafka-python | confluent-kafka | è¯´æ˜ |
|--------------|-----------------|------|
| `buffer.memory` | `queue.buffering.max.kbytes` | ç”Ÿäº§è€…ç¼“å†²åŒºå¤§å° |
| `enable.auto.commit` | `enable.auto.commit` | è‡ªåŠ¨æäº¤å¼€å…³ |
| å…¶ä»–å‚æ•° | åŸºæœ¬å…¼å®¹ | confluent-kafka ä½¿ç”¨ librdkafka é…ç½® |

#### æ–‡ä»¶ä¿®æ”¹æ¸…å•
```
requirements.txt           # kafka-python â†’ confluent-kafka
setup.py                   # ä¾èµ–æ›´æ–°
examples/kafka-driver.yaml # é…ç½®å‚æ•°è°ƒæ•´
```

### 2. å¹¶å‘æ¨¡å‹è®¾è®¡

#### æœ€ç»ˆæ¶æ„ï¼ˆæ··åˆæ–¹æ¡ˆï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Main Process                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   LocalWorker (ä¸»æ§åˆ¶å™¨)                â”‚   â”‚
â”‚  â”‚   - WorkerStats (å…±äº«ç»Ÿè®¡)              â”‚   â”‚
â”‚  â”‚   - BenchmarkDriver                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Producer    â”‚  â”‚  Producer    â”‚  (Threads) â”‚
â”‚  â”‚  Thread 1    â”‚  â”‚  Thread N    â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”‚                  â”‚                    â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                â–¼                                â”‚
â”‚         WorkerStats (shared)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ multiprocessing.Queue
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Consumer Process (ç‹¬ç«‹è¿›ç¨‹)             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Consumer (_consumer_loop_func)         â”‚   â”‚
â”‚  â”‚  - confluent_kafka.Consumer              â”‚   â”‚
â”‚  â”‚  - æ¶ˆæ¯æ‹‰å–                              â”‚   â”‚
â”‚  â”‚  - æ‰¹é‡ Offset Commit                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                                       â”‚
â”‚         â”‚ Queue.put(msg, timestamp)             â”‚
â”‚         â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Main Process Callback Thread           â”‚   â”‚
â”‚  â”‚  - Queue.get()                           â”‚   â”‚
â”‚  â”‚  - callback.message_received()           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### è®¾è®¡å†³ç­–

**ä¸ºä»€ä¹ˆ Consumer ä½¿ç”¨ multiprocessingï¼Ÿ**
- âœ… å®Œå…¨éš”ç¦»ï¼Œé¿å… GIL å½±å“æ¶ˆè´¹æ€§èƒ½
- âœ… Consumer å’Œ Kafka broker é€šä¿¡æ˜¯ I/O å¯†é›†å‹
- âœ… ç‹¬ç«‹è¿›ç¨‹å´©æºƒä¸å½±å“ä¸»è¿›ç¨‹

**ä¸ºä»€ä¹ˆ Producer ä½¿ç”¨ threadingï¼Ÿ**
- âœ… confluent-kafka åº•å±‚æ˜¯ C åº“ï¼ˆlibrdkafkaï¼‰ï¼Œ**è‡ªåŠ¨é‡Šæ”¾ GIL**
- âœ… å¤šçº¿ç¨‹å¯ä»¥å……åˆ†åˆ©ç”¨å¤šæ ¸ CPU
- âœ… é¿å… multiprocessing çš„ pickle é—®é¢˜
- âœ… å…±äº« WorkerStatsï¼Œç»Ÿè®¡æ•°æ®å‡†ç¡®æ±‡æ€»

---

## æ ¸å¿ƒç»„ä»¶è®¾è®¡

### 1. KafkaBenchmarkDriver

**ä½ç½®**: `benchmark/driver_kafka/kafka_benchmark_driver.py`

**èŒè´£**:
- Kafka é›†ç¾¤è¿æ¥ç®¡ç†
- Topic åˆ›å»º/åˆ é™¤ï¼ˆå¹‚ç­‰æ€§ï¼‰
- Producer/Consumer å·¥å‚

**å…³é”®æ–¹æ³•**:
```python
def create_topic(topic, partitions) -> Future
def create_topics(topic_infos) -> Future
def create_producer(topic) -> Future
def create_consumer(topic, subscription, callback) -> Future
def delete_topics()  # æ–°å¢ï¼šå¹‚ç­‰æ€§æ¸…ç†
def close()          # æ¸…ç†æ‰€æœ‰èµ„æº + åˆ é™¤ topics
```

**å¹‚ç­‰æ€§å®ç°**:
```python
self.created_topics = []  # è¿½è¸ªåˆ›å»ºçš„ topics

def create_topics():
    # åˆ›å»ºæ—¶è®°å½•
    self.created_topics.append(topic_name)

def close():
    # å…³é—­æ—¶åˆ é™¤
    self.admin.delete_topics(self.created_topics)
    self.created_topics.clear()
```

### 2. KafkaBenchmarkProducer

**ä½ç½®**: `benchmark/driver_kafka/kafka_benchmark_producer.py`

**å…³é”®ç‰¹æ€§**:
- ä½¿ç”¨ `confluent_kafka.Producer`
- å¼‚æ­¥å‘é€ + å›è°ƒæœºåˆ¶
- å®ç°å®Œæ•´çš„ `FutureResult` ç±»

**FutureResult å®ç°**:
```python
class FutureResult:
    def __init__(self):
        self.completed = False
        self.exception_value = None
        self._result = None
        self._callbacks = []

    def add_done_callback(self, fn):
        """æ”¯æŒå¼‚æ­¥å›è°ƒ"""
        if self.completed:
            fn(self)
        else:
            self._callbacks.append(fn)

    def set_result(self, result=None):
        self._result = result
        self.completed = True
        self._run_callbacks()
```

**ä¸ºä»€ä¹ˆéœ€è¦è‡ªå®šä¹‰ FutureResultï¼Ÿ**
- confluent-kafka çš„ `produce()` ä¸è¿”å› Future
- Benchmark æ¡†æ¶éœ€è¦ Future æ¥å£æ¥å¤„ç†å¼‚æ­¥å›è°ƒ
- éœ€è¦å…¼å®¹ `add_done_callback()` æ–¹æ³•

### 3. KafkaBenchmarkConsumer

**ä½ç½®**: `benchmark/driver_kafka/kafka_benchmark_consumer.py`

**æ¶æ„**:
```
Consumer Process                Main Process
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_consumer_loop_func()    â”€â”€â”
  â”œâ”€ Consumer.poll()       â”‚ multiprocessing.Queue
  â”œâ”€ message_queue.put()   â”‚
  â””â”€ commit(async)         â”‚
                          â”€â”˜
                           â”Œâ”€â”€> _callback_loop() (Thread)
                           â”‚      â”œâ”€ queue.get()
                           â”‚      â””â”€ callback.message_received()
```

**å…³é”®ä¼˜åŒ–**:
1. **æ‰¹é‡ Commit**: æ¯ 100 æ¡æ¶ˆæ¯æäº¤ä¸€æ¬¡
   ```python
   message_count += 1
   if message_count >= commit_interval:
       consumer.commit(asynchronous=True)
       message_count = 0
   ```

2. **è¿›ç¨‹é—´é€šä¿¡**: ä½¿ç”¨ `multiprocessing.Queue`
   ```python
   message_queue = multiprocessing.Queue(maxsize=1000)
   message_queue.put((msg.value(), timestamp_us))
   ```

3. **Callback çº¿ç¨‹**: åœ¨ä¸»è¿›ç¨‹ä¸­å¤„ç†å›è°ƒ
   ```python
   def _callback_loop(self):
       while not self.closing.is_set():
           payload, timestamp_us = self.message_queue.get(timeout=0.1)
           self.callback.message_received(payload, timestamp_us)
   ```

### 4. LocalWorker

**ä½ç½®**: `benchmark/worker/local_worker.py`

**èŒè´£**:
- æœ¬åœ° Benchmark æ‰§è¡Œå™¨
- ç®¡ç† Producers/Consumers ç”Ÿå‘½å‘¨æœŸ
- è´Ÿè½½ç”Ÿæˆä¸ç»Ÿè®¡æ”¶é›†

**Producer çº¿ç¨‹ç®¡ç†**:
```python
def start_load(self, producer_work_assignment):
    per_producer_rate = total_rate / len(self.producers)

    for i, producer in enumerate(self.producers):
        thread = threading.Thread(
            target=self._producer_worker,
            args=(producer, i, per_producer_rate),
            daemon=True
        )
        thread.start()
        self.producer_threads.append(thread)

def _producer_worker(self, producer, index, rate):
    """ç”Ÿäº§è€…å·¥ä½œçº¿ç¨‹"""
    rate_limiter = UniformRateLimiter(rate)
    message_producer = MessageProducer(rate_limiter, self.stats)

    while not self.stop_producing.is_set():
        key = self._select_key(index)  # æ ¹æ®ç­–ç•¥é€‰æ‹© key
        message_producer.send_message(producer, key, payload)
```

### 5. WorkerStats

**ä½ç½®**: `benchmark/worker/worker_stats.py`

**å¹¶å‘å®‰å…¨è®¾è®¡**:

```python
class LongAdder:
    """è¿›ç¨‹/çº¿ç¨‹å®‰å…¨çš„è®¡æ•°å™¨"""
    def __init__(self):
        self._value = multiprocessing.Value('q', 0)  # å…±äº«å†…å­˜
        self._lock = multiprocessing.Lock()          # è¿›ç¨‹é”

    def increment(self):
        with self._lock:
            self._value.value += 1

class WorkerStats:
    def __init__(self):
        # ä½¿ç”¨ multiprocessing åŸè¯­
        self.histogram_lock = multiprocessing.Lock()
        self.messages_sent = LongAdder()
        self.messages_received = LongAdder()

    def record_producer_success(self, ...):
        self.messages_sent.increment()
        with self.histogram_lock:
            self.publish_latency_recorder.record_value(latency)
```

**ä¸ºä»€ä¹ˆç”¨ multiprocessing è€Œä¸æ˜¯ threadingï¼Ÿ**
- å³ä½¿ Producer ç”¨ threadingï¼Œä½†ç»Ÿè®¡å¯¹è±¡ä¼šåœ¨å¤šä¸ªè¿›ç¨‹é—´ä¼ é€’
- `multiprocessing.Value` ä½¿ç”¨å…±äº«å†…å­˜ï¼Œè·¨è¿›ç¨‹å¯è§
- `multiprocessing.Lock` åœ¨è¿›ç¨‹å’Œçº¿ç¨‹é—´éƒ½æœ‰æ•ˆ

---

## å…³é”®å®ç°ç»†èŠ‚

### 1. Pickle å…¼å®¹æ€§é—®é¢˜

**é—®é¢˜**: macOS ä½¿ç”¨ `spawn` å¯åŠ¨è¿›ç¨‹ï¼Œæ‰€æœ‰å‚æ•°å¿…é¡»å¯ pickle

**è§£å†³æ–¹æ¡ˆ**:
1. **Consumer**: åœ¨å­è¿›ç¨‹ä¸­åˆ›å»º Consumer å¯¹è±¡
   ```python
   def _consumer_loop_func(topic, properties, ...):
       consumer = Consumer(properties)  # åœ¨å­è¿›ç¨‹ä¸­åˆ›å»º
   ```

2. **Producer**: ä½¿ç”¨çº¿ç¨‹è€Œéè¿›ç¨‹
   ```python
   # âœ— é”™è¯¯ï¼šProducer å¯¹è±¡ä¸èƒ½ pickle
   process = Process(target=work, args=(producer,))

   # âœ“ æ­£ç¡®ï¼šä½¿ç”¨çº¿ç¨‹
   thread = Thread(target=work, args=(producer,))
   ```

3. **WorkerStats**: ä¸ç›´æ¥ä¼ é€’ï¼Œåœ¨å­è¿›ç¨‹ä¸­é‡å»º
   ```python
   def _producer_worker_func(...):
       stats = WorkerStats()  # å­è¿›ç¨‹ç‹¬ç«‹ç»Ÿè®¡ï¼ˆä¸å…±äº«ï¼‰
   ```

### 2. Consumer è¶…æ—¶é—®é¢˜

**é—®é¢˜**: OffsetCommit è¶…æ—¶
```
REQTMOUT: Timed out OffsetCommitRequest in flight (after 60303ms)
```

**æ ¹æœ¬åŸå› **:
- æ¯æ¡æ¶ˆæ¯éƒ½è°ƒç”¨ `commit(asynchronous=True)`
- é«˜ååé‡æ—¶è¯·æ±‚å †ç§¯ï¼Œè¶…è¿‡ `request.timeout.ms`

**è§£å†³æ–¹æ¡ˆ**:
```python
commit_interval = 100  # æ¯ 100 æ¡æ¶ˆæ¯æäº¤ä¸€æ¬¡

message_count += 1
if message_count >= commit_interval:
    consumer.commit(asynchronous=True)
    message_count = 0
```

**é…ç½®ä¼˜åŒ–**:
```yaml
consumerConfig: |
  session.timeout.ms=300000      # 5åˆ†é’Ÿ
  max.poll.interval.ms=300000    # 5åˆ†é’Ÿ
```

### 3. ç”Ÿäº§è€…æ€§èƒ½ä¼˜åŒ–

**å½“å‰ç“¶é¢ˆ**:
- å•ä¸ª Producer çº¿ç¨‹
- å‘é€å»¶è¿Ÿ ~159msï¼ˆKafka å“åº”æ…¢ï¼‰
- Rate Limiter è°ƒåº¦å»¶è¿Ÿ ~1.6ms

**ä¼˜åŒ–æ–¹å‘**:
1. **å¢åŠ  Producer æ•°é‡**:
   ```yaml
   # workload.yaml
   producersPerTopic: 4  # ä» 1 å¢åŠ åˆ° 4
   ```

2. **è°ƒæ•´ç”Ÿäº§è€…é…ç½®**:
   ```yaml
   producerConfig: |
     linger.ms=1                  # å‡å°‘æ‰¹é‡ç­‰å¾…æ—¶é—´
     batch.size=65536             # å¢åŠ æ‰¹é‡å¤§å°
     compression.type=lz4         # å¯ç”¨å‹ç¼©
     acks=0                       # æ— éœ€ç­‰å¾…ç¡®è®¤ï¼ˆæµ‹è¯•ç”¨ï¼‰
   ```

3. **Rate Limiter ä¼˜åŒ–**:
   - å½“å‰ä½¿ç”¨ `time.sleep()` ç²¾åº¦ä¸å¤Ÿ
   - å¯è€ƒè™‘ä½¿ç”¨ busy-wait æˆ–æ›´ç²¾ç¡®çš„å®šæ—¶å™¨

---

## æ€§èƒ½åˆ†æ

### æµ‹è¯•ç»“æœ

**é…ç½®**:
- Topics: 1
- Partitions: 10
- Producer Rate: 1000 msg/s
- Message Size: 1024 bytes

**å®é™…ååé‡**:
```
Pub rate:   500 msg/s (ç›®æ ‡çš„ 50%)
Cons rate: 3600 msg/s (åŒ…å«å†å²ç§¯å‹)
Pub Latency: 159ms (p50: 101ms, p99: 843ms)
Pub Delay:   1.6ms (rate limiter è°ƒåº¦å»¶è¿Ÿ)
```

### æ€§èƒ½ç“¶é¢ˆåˆ†æ

#### 1. Producer æœªè¾¾åˆ°ç›®æ ‡é€Ÿç‡

**åŸå› **:
1. **å•çº¿ç¨‹ç“¶é¢ˆ**: åªæœ‰ 1 ä¸ª Producer çº¿ç¨‹
2. **Kafka å»¶è¿Ÿé«˜**: p50=101ms, p99=843ms
3. **Rate Limiter ä¸ç²¾ç¡®**: è°ƒåº¦å»¶è¿Ÿ 1.6ms

**è®¡ç®—éªŒè¯**:
```
ç†è®ºæœ€å¤§é€Ÿç‡ = 1000ms / (101ms + 1.6ms) â‰ˆ 9.7 msg/s per thread
å®é™…é€Ÿç‡ = 500 msg/s
```
ç¬¦åˆå•çº¿ç¨‹ + é«˜å»¶è¿Ÿçš„é¢„æœŸ

#### 2. Consumer é«˜ååé‡

**åŸå› **:
1. **æ‰¹é‡æ‹‰å–**: Kafka Consumer æ‰¹é‡ poll
2. **æ— é€Ÿç‡é™åˆ¶**: Consumer å…¨é€Ÿæ¶ˆè´¹
3. **å†å²ç§¯å‹**: å¯åŠ¨æ—¶å·²æœ‰ 5000+ æ¡æ¶ˆæ¯

**éªŒè¯**:
```
å¯åŠ¨æ—¶: Received: 5209  (å†å²æ¶ˆæ¯)
è¿è¡Œæ—¶: 3600 msg/s      (æ–°æ¶ˆæ¯ + å‰©ä½™ç§¯å‹)
```

### ååé‡å·®å¼‚è§£é‡Š

**ä¸ºä»€ä¹ˆ Consumer æ¯” Producer å¿« 7 å€ï¼Ÿ**

1. **å†å²ç§¯å‹**: Consumer åœ¨æ¶ˆè´¹å¯åŠ¨å‰ç§¯ç´¯çš„æ¶ˆæ¯
2. **æ‰¹é‡å¤„ç†**: Kafka æ‰¹é‡è¿”å›æ¶ˆæ¯ï¼ŒConsumer æ‰¹é‡å¤„ç†
3. **å¼‚æ­¥ç¡®è®¤**: Consumer æ¯ 100 æ¡æ‰æäº¤ä¸€æ¬¡
4. **ç‹¬ç«‹è¿›ç¨‹**: Consumer è¿›ç¨‹æ—  GIL é™åˆ¶

---

## å¾…æ”¹è¿›é¡¹

### é«˜ä¼˜å…ˆçº§

#### 1. ç»Ÿè®¡æ•°æ®å…±äº«ï¼ˆè·¨è¿›ç¨‹ï¼‰

**å½“å‰é—®é¢˜**:
- Producer ä½¿ç”¨çº¿ç¨‹ï¼Œç»Ÿè®¡æ­£å¸¸
- å¦‚æœæ”¹ç”¨è¿›ç¨‹ï¼Œæ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹ç»Ÿè®¡ï¼Œä¸»è¿›ç¨‹çœ‹ä¸åˆ°

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ A: ä½¿ç”¨ Manager å…±äº«å¯¹è±¡
manager = multiprocessing.Manager()
shared_stats = manager.Namespace()

# æ–¹æ¡ˆ B: ä½¿ç”¨é˜Ÿåˆ—æ±‡æ€»
stats_queue = multiprocessing.Queue()
# å­è¿›ç¨‹: stats_queue.put(stats_dict)
# ä¸»è¿›ç¨‹: å®šæœŸæ±‡æ€»
```

#### 2. å¹‚ç­‰æ€§æµ‹è¯•ä¸å®Œæ•´

**å½“å‰é—®é¢˜**:
- `close()` æ—¶åˆ é™¤ topics
- ä½†å¼‚å¸¸é€€å‡ºæ—¶å¯èƒ½ä¸æ‰§è¡Œ

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ A: ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
with KafkaBenchmarkDriver() as driver:
    # ... æµ‹è¯•é€»è¾‘

# æ–¹æ¡ˆ B: ä¿¡å·å¤„ç†
import signal
def cleanup(signum, frame):
    driver.delete_topics()
signal.signal(signal.SIGTERM, cleanup)
signal.signal(signal.SIGINT, cleanup)

# æ–¹æ¡ˆ C: å¯åŠ¨æ—¶æ¸…ç†æ—§ topics
def initialize():
    # åˆ é™¤æ‰€æœ‰ä»¥ test-topic- å¼€å¤´çš„ topics
    existing = admin.list_topics()
    old_topics = [t for t in existing if t.startswith('test-topic-')]
    admin.delete_topics(old_topics)
```

#### 3. Producer æ€§èƒ½ä¼˜åŒ–

**å¤šçº¿ç¨‹ vs å¤šè¿›ç¨‹æƒè¡¡**:

| æ–¹æ¡ˆ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|------|
| å½“å‰ï¼ˆå¤šçº¿ç¨‹ï¼‰ | âœ“ å…±äº«ç»Ÿè®¡<br>âœ“ æ—  pickle é—®é¢˜<br>âœ“ librdkafka é‡Šæ”¾ GIL | âœ— å•è¿›ç¨‹ CPU é™åˆ¶ |
| å¤šè¿›ç¨‹ | âœ“ çœŸæ­£å¹¶è¡Œ<br>âœ“ ç‹¬ç«‹å´©æºƒéš”ç¦» | âœ— ç»Ÿè®¡æ±‡æ€»å¤æ‚<br>âœ— pickle é™åˆ¶ |

**æ¨è**:
```python
# æ··åˆæ–¹æ¡ˆï¼šæ¯ä¸ªè¿›ç¨‹å¤šä¸ªçº¿ç¨‹
num_processes = 4
threads_per_process = 4

for proc_id in range(num_processes):
    process = Process(target=run_producers,
                     args=(threads_per_process, ...))
```

#### 4. Rate Limiter ç²¾åº¦

**å½“å‰é—®é¢˜**:
- `time.sleep()` ç²¾åº¦ ~10msï¼ˆæ“ä½œç³»ç»Ÿè°ƒåº¦ï¼‰
- æœŸæœ›å»¶è¿Ÿ 1ms æ—¶ï¼Œå®é™…å¯èƒ½ 1-10ms

**æ”¹è¿›æ–¹æ¡ˆ**:
```python
class HighPrecisionRateLimiter:
    def acquire(self):
        target_time = self.next_time

        # Busy-wait for last 1ms
        while True:
            now = time.perf_counter_ns()
            diff = target_time - now

            if diff <= 0:
                break
            elif diff > 1_000_000:  # > 1ms
                time.sleep(diff / 1_000_000_000 * 0.9)
            # else: busy-wait

        return target_time
```

### ä¸­ä¼˜å…ˆçº§

#### 5. Consumer è‡ªåŠ¨é‡è¿

**é—®é¢˜**: Consumer è¿›ç¨‹å¼‚å¸¸é€€å‡ºæ—¶ä¸ä¼šè‡ªåŠ¨é‡å¯

**æ–¹æ¡ˆ**:
```python
class ResilientConsumer:
    def __init__(self):
        self.max_retries = 3
        self.retry_count = 0

    def _monitor_consumer_process(self):
        while not self.closing.is_set():
            if not self.consumer_process.is_alive():
                if self.retry_count < self.max_retries:
                    logger.warning("Consumer died, restarting...")
                    self._restart_consumer()
                    self.retry_count += 1
            time.sleep(1)
```

#### 6. é…ç½®éªŒè¯

**é—®é¢˜**: æ— æ•ˆé…ç½®ç›´åˆ°è¿è¡Œæ—¶æ‰æŠ¥é”™

**æ–¹æ¡ˆ**:
```python
def validate_config(properties: dict):
    required = ['bootstrap.servers']
    for key in required:
        if key not in properties:
            raise ValueError(f"Missing required config: {key}")

    # ç±»å‹æ£€æŸ¥
    if 'linger.ms' in properties:
        if not isinstance(properties['linger.ms'], int):
            raise TypeError("linger.ms must be int")
```

#### 7. ç›‘æ§ä¸å¯è§‚æµ‹æ€§

**æ”¹è¿›æ–¹å‘**:
```python
# æ–¹æ¡ˆ A: Prometheus æŒ‡æ ‡
from prometheus_client import Counter, Histogram

msg_sent = Counter('benchmark_messages_sent', 'Total messages sent')
send_latency = Histogram('benchmark_send_latency_seconds',
                         'Message send latency')

# æ–¹æ¡ˆ B: ç»“æ„åŒ–æ—¥å¿—
import structlog
logger = structlog.get_logger()
logger.info("message_sent",
           topic=topic,
           latency_ms=latency,
           size_bytes=len(payload))
```

### ä½ä¼˜å…ˆçº§

#### 8. æ”¯æŒæ›´å¤šæ¶ˆæ¯ç³»ç»Ÿ

**æ‰©å±•æ–¹å‘**:
- Pulsar Driver
- RocketMQ Driver
- RabbitMQ Driver

**å®ç°æ­¥éª¤**:
1. ç»§æ‰¿ `BenchmarkDriver` åŸºç±»
2. å®ç° `create_producer/consumer` ç­‰æ–¹æ³•
3. æ·»åŠ é…ç½®æ–‡ä»¶æ¨¡æ¿

#### 9. åˆ†å¸ƒå¼ Worker æ”¯æŒ

**å½“å‰**: åªæ”¯æŒ LocalWorker

**æ”¹è¿›**: å®Œå–„ `DistributedWorkersEnsemble`
```python
class DistributedWorkersEnsemble:
    def __init__(self, worker_urls: List[str]):
        self.workers = [HttpWorkerClient(url)
                       for url in worker_urls]

    def start_load(self, assignment):
        # è´Ÿè½½å‡è¡¡åˆ†é…
        for worker, sub_assignment in zip(self.workers,
                                          self._split_assignment(assignment)):
            worker.start_load(sub_assignment)
```

#### 10. åŠ¨æ€è´Ÿè½½è°ƒæ•´

**åŠŸèƒ½**: è¿è¡Œæ—¶è°ƒæ•´å‘é€é€Ÿç‡

**å®ç°**:
```python
class AdaptiveRateController:
    def adjust_rate(self, current_stats):
        if current_stats.error_rate > 0.01:  # 1% é”™è¯¯ç‡
            self.target_rate *= 0.9  # é™ä½ 10%
        elif current_stats.latency_p99 < 100:  # p99 < 100ms
            self.target_rate *= 1.1  # æé«˜ 10%
```

---

## ä½¿ç”¨æŒ‡å—

### å®‰è£…ä¾èµ–

```bash
# å®‰è£… confluent-kafka
pip install -r requirements.txt

# æˆ–æ‰‹åŠ¨å®‰è£…
pip install confluent-kafka>=2.0.0 pyyaml hdrhistogram requests Flask
```

### é…ç½®æ–‡ä»¶

**Driver é…ç½®** (`examples/kafka-driver.yaml`):
```yaml
name: Kafka
driverClass: benchmark.driver_kafka.kafka_benchmark_driver.KafkaBenchmarkDriver

replicationFactor: 1

commonConfig: |
  bootstrap.servers=localhost:9092

producerConfig: |
  acks=1
  linger.ms=10
  batch.size=16384
  queue.buffering.max.kbytes=32768  # confluent-kafka å‚æ•°

consumerConfig: |
  auto.offset.reset=earliest
  enable.auto.commit=false
  session.timeout.ms=300000         # 5åˆ†é’Ÿ
  max.poll.interval.ms=300000

topicConfig: |
  min.insync.replicas=1
```

**Workload é…ç½®** (`examples/simple-workload.yaml`):
```yaml
name: simple-workload
topics: 1
partitionsPerTopic: 10
messageSize: 1024

subscriptionsPerTopic: 1
producersPerTopic: 1              # å»ºè®®å¢åŠ åˆ° 4
consumerPerSubscription: 1

producerRate: 1000                # msg/s
testDurationMinutes: 1
warmupDurationMinutes: 1

keyDistributor: NO_KEY            # NO_KEY | ROUND_ROBIN | RANDOM
```

### è¿è¡Œæµ‹è¯•

```bash
# å¯åŠ¨ Kafka (Docker)
docker-compose up -d

# è¿è¡Œ Benchmark
python -m benchmark.benchmark \
  -d examples/kafka-driver.yaml \
  examples/simple-workload.yaml

# æŸ¥çœ‹ç»“æœ
cat simple-workload-Kafka-*.json
```

### æ¸…ç†ç¯å¢ƒ

```bash
# æ‰‹åŠ¨æ¸…ç† topics
kafka-topics --bootstrap-server localhost:9092 \
  --delete --topic 'test-topic-.*'

# é‡ç½® Consumer Group
kafka-consumer-groups --bootstrap-server localhost:9092 \
  --group benchmark-group \
  --reset-offsets --to-latest --execute --all-topics
```

### æ€§èƒ½è°ƒä¼˜å»ºè®®

#### 1. æå‡ Producer ååé‡
```yaml
# workload.yaml
producersPerTopic: 4              # å¢åŠ å¹¶å‘

# kafka-driver.yaml
producerConfig: |
  acks=0                          # æ— éœ€ç¡®è®¤ï¼ˆæµ‹è¯•ç”¨ï¼‰
  linger.ms=1                     # å‡å°‘å»¶è¿Ÿ
  batch.size=65536                # å¢åŠ æ‰¹é‡
  compression.type=lz4            # å¯ç”¨å‹ç¼©
  max.in.flight.requests.per.connection=10
```

#### 2. å‡å°‘ Consumer å»¶è¿Ÿ
```yaml
consumerConfig: |
  fetch.min.bytes=1               # ç«‹å³è¿”å›
  fetch.max.wait.ms=100           # æœ€å¤šç­‰å¾… 100ms
  max.poll.records=500            # æ¯æ¬¡æ‹‰å– 500 æ¡
```

#### 3. Kafka Broker ä¼˜åŒ–
```properties
# server.properties
num.network.threads=8
num.io.threads=16
socket.send.buffer.bytes=1048576
socket.receive.buffer.bytes=1048576
```

---

## å¸¸è§é—®é¢˜

### Q1: Consumer è¶…æ—¶æ€ä¹ˆåŠï¼Ÿ
**A**: å¢åŠ è¶…æ—¶é…ç½®æˆ–å‡å°‘ commit é¢‘ç‡
```yaml
consumerConfig: |
  session.timeout.ms=300000
  max.poll.interval.ms=300000
```

### Q2: Producer é€Ÿç‡ä¸è¾¾æ ‡ï¼Ÿ
**A**:
1. æ£€æŸ¥ Kafka å»¶è¿Ÿï¼š`kafka-broker-api-versions --bootstrap-server localhost:9092`
2. å¢åŠ  Producer æ•°é‡ï¼š`producersPerTopic: 4`
3. å‡å°‘ acksï¼š`acks=0`ï¼ˆæµ‹è¯•ç”¨ï¼‰

### Q3: å¦‚ä½•æ¸…ç†å†å²æ¶ˆæ¯ï¼Ÿ
**A**:
```bash
# æ–¹æ¡ˆ A: åˆ é™¤å¹¶é‡å»º topic
kafka-topics --delete --topic test-topic-0 --bootstrap-server localhost:9092
kafka-topics --create --topic test-topic-0 --partitions 10 --bootstrap-server localhost:9092

# æ–¹æ¡ˆ B: é‡ç½® Consumer offset
kafka-consumer-groups --reset-offsets --to-latest --execute --group benchmark-group
```

### Q4: macOS pickle é”™è¯¯ï¼Ÿ
**A**: ç¡®ä¿ä½¿ç”¨äº†æ··åˆæ¶æ„ï¼š
- Consumer: multiprocessing âœ“
- Producer: threading âœ“
- ä¸è¦åœ¨è¿›ç¨‹é—´ä¼ é€’ä¸å¯ pickle å¯¹è±¡

---

## æ€»ç»“

### æˆåŠŸå®Œæˆ
âœ… Kafka å®¢æˆ·ç«¯è¿ç§»ï¼ˆkafka-python â†’ confluent-kafkaï¼‰
âœ… å¹¶å‘æ¨¡å‹è½¬æ¢ï¼ˆthreading â†’ multiprocessing/threading æ··åˆï¼‰
âœ… å¹‚ç­‰æ€§èµ„æºç®¡ç†ï¼ˆtopic è‡ªåŠ¨æ¸…ç†ï¼‰
âœ… æ€§èƒ½ä¼˜åŒ–ï¼ˆæ‰¹é‡ commitã€å‡å°‘è¶…æ—¶ï¼‰

### æ ¸å¿ƒä¼˜åŠ¿
- **Consumer**: ç‹¬ç«‹è¿›ç¨‹ï¼Œæ—  GIL é™åˆ¶ï¼Œé«˜ååé‡
- **Producer**: å¤šçº¿ç¨‹ + librdkafka é‡Šæ”¾ GILï¼Œå…±äº«ç»Ÿè®¡
- **å¹‚ç­‰æ€§**: è‡ªåŠ¨æ¸…ç† topicsï¼Œæ”¯æŒé‡å¤æµ‹è¯•
- **å…¼å®¹æ€§**: å®Œå…¨å…¼å®¹åŸ OMB æ¡†æ¶æ¥å£

### æ¶æ„äº®ç‚¹
1. **æ··åˆå¹¶å‘**: æ ¹æ®ç»„ä»¶ç‰¹æ€§é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ
2. **è¿›ç¨‹éš”ç¦»**: Consumer å´©æºƒä¸å½±å“ä¸»è¿›ç¨‹
3. **ç»Ÿè®¡å‡†ç¡®**: çº¿ç¨‹å…±äº« + è¿›ç¨‹å®‰å…¨é”
4. **é…ç½®å…¼å®¹**: å¹³æ»‘è¿ç§» kafka-python é…ç½®

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-10-03
**ä½œè€…**: Claude (Anthropic)
