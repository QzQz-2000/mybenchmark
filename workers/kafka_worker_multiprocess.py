"""
Kafka Worker with Multi-Process Execution

æ¯ä¸ª Producer/Consumer ä»»åŠ¡è¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ï¼ŒçœŸå®æ¨¡æ‹Ÿå¤š agent åœºæ™¯ã€‚
è¿™ä¸ªå®ç°å®Œå…¨å¯¹åº” Java OMB çš„å¤šçº¿ç¨‹æ¨¡å‹ï¼Œä½†ä½¿ç”¨ Python å¤šè¿›ç¨‹ç»•è¿‡ GILã€‚
"""

import time
import asyncio
from typing import Dict, List, Any, Optional

from benchmark.core.worker import BaseWorker, ProducerTask, ConsumerTask
from benchmark.core.results import WorkerResult
from benchmark.core.config import DriverConfig
from benchmark.worker.process_executor import ProcessExecutor
from benchmark.drivers.kafka import KafkaDriver
from benchmark.utils.logging import LoggerMixin


class KafkaWorkerMultiProcess(BaseWorker):
    """
    Kafka Worker - Multi-Process ç‰ˆæœ¬

    æ¯ä¸ª producer/consumer ä»»åŠ¡è¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ï¼Œå®Œå…¨æ¨¡æ‹ŸçœŸå®çš„å¤š agent è´Ÿè½½ã€‚

    æ¶æ„ï¼š
    - å•ä¸ª Worker è¿›ç¨‹ï¼ˆFastAPI æœåŠ¡å™¨ï¼‰
    - N ä¸ª Producer å­è¿›ç¨‹ï¼ˆæ¯ä¸ªä»»åŠ¡ä¸€ä¸ªè¿›ç¨‹ï¼‰
    - M ä¸ª Consumer å­è¿›ç¨‹ï¼ˆæ¯ä¸ªä»»åŠ¡ä¸€ä¸ªè¿›ç¨‹ï¼‰

    å¯¹åº” Java OMB:
    - å•ä¸ª JVM è¿›ç¨‹ â†’ å•ä¸ª Worker è¿›ç¨‹
    - N ä¸ªçº¿ç¨‹ â†’ N ä¸ªå­è¿›ç¨‹
    - å¤šçº¿ç¨‹å¹¶å‘ â†’ å¤šè¿›ç¨‹å¹¶å‘
    """

    def __init__(
        self,
        worker_id: str,
        driver_config: DriverConfig
    ):
        """
        åˆå§‹åŒ– Kafka Worker

        Args:
            worker_id: Worker å”¯ä¸€æ ‡è¯†
            driver_config: Kafka é©±åŠ¨é…ç½®
        """
        super().__init__(worker_id)
        self.driver_config = driver_config
        self.client_type = "confluent-kafka"
        self._driver: Optional[KafkaDriver] = None
        self._process_executor: Optional[ProcessExecutor] = None

    async def start(self) -> None:
        """å¯åŠ¨ Worker"""
        await super().start()

        # åˆå§‹åŒ– Driverï¼ˆç”¨äº topic ç®¡ç†ç­‰ï¼‰
        self._driver = KafkaDriver(self.driver_config)
        await self._driver.initialize()

        # åˆ›å»ºè¿›ç¨‹æ‰§è¡Œå™¨
        self._process_executor = ProcessExecutor(self.worker_id)

        self.logger.info(
            f"âœ… Kafka Worker {self.worker_id} å·²å¯åŠ¨ (Multi-Process æ¨¡å¼)"
        )

    async def stop(self) -> None:
        """åœæ­¢ Worker"""
        # æ¸…ç†è¿›ç¨‹æ‰§è¡Œå™¨
        if self._process_executor:
            self._process_executor.cleanup()

        # æ¸…ç† Driver
        if self._driver:
            await self._driver.cleanup()

        await super().stop()

        self.logger.info(f"ğŸ›‘ Kafka Worker {self.worker_id} å·²åœæ­¢")

    async def run_producer_tasks(
        self,
        tasks: List[ProducerTask]
    ) -> None:
        """
        å¯åŠ¨å¤šä¸ª producer ä»»åŠ¡ (Java OMB style)

        æ¯ä¸ªä»»åŠ¡è¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ï¼ŒæŒç»­è¿è¡Œç›´åˆ°æ”¶åˆ° stop ä¿¡å·ã€‚
        æ­¤æ–¹æ³•å¯åŠ¨ä»»åŠ¡åç«‹å³è¿”å›ã€‚

        Args:
            tasks: Producer ä»»åŠ¡åˆ—è¡¨
        """
        self.logger.info(
            f"ğŸ“¤ æ”¶åˆ° {len(tasks)} ä¸ª Producer ä»»åŠ¡ï¼Œ"
            f"æ¯ä¸ªä»»åŠ¡å°†è¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ (æŒç»­æ¨¡å¼)..."
        )

        # ä½¿ç”¨è¿›ç¨‹æ‰§è¡Œå™¨å¯åŠ¨æ‰€æœ‰ä»»åŠ¡ï¼ˆä¸ç­‰å¾…å®Œæˆï¼‰
        await self._process_executor.execute_producer_tasks(
            tasks,
            self.driver_config
        )

        self.logger.info(f"âœ… æ‰€æœ‰ {len(tasks)} ä¸ª Producer ä»»åŠ¡å·²å¯åŠ¨")

    async def run_consumer_tasks(
        self,
        tasks: List[ConsumerTask]
    ) -> None:
        """
        å¯åŠ¨å¤šä¸ª consumer ä»»åŠ¡ (Java OMB style)

        æ¯ä¸ªä»»åŠ¡è¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ï¼ŒæŒç»­è¿è¡Œç›´åˆ°æ”¶åˆ° stop ä¿¡å·ã€‚
        æ­¤æ–¹æ³•å¯åŠ¨ä»»åŠ¡åç«‹å³è¿”å›ã€‚

        Args:
            tasks: Consumer ä»»åŠ¡åˆ—è¡¨
        """
        self.logger.info(
            f"ğŸ“¥ æ”¶åˆ° {len(tasks)} ä¸ª Consumer ä»»åŠ¡ï¼Œ"
            f"æ¯ä¸ªä»»åŠ¡å°†è¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ (æŒç»­æ¨¡å¼)..."
        )

        # ä½¿ç”¨è¿›ç¨‹æ‰§è¡Œå™¨å¯åŠ¨æ‰€æœ‰ä»»åŠ¡ï¼ˆä¸ç­‰å¾…å®Œæˆï¼‰
        await self._process_executor.execute_consumer_tasks(
            tasks,
            self.driver_config
        )

        self.logger.info(f"âœ… æ‰€æœ‰ {len(tasks)} ä¸ª Consumer ä»»åŠ¡å·²å¯åŠ¨")

    async def stop_all_tasks(self):
        """
        Stop all running tasks - Java OMB style

        Triggers stop signal for all producer and consumer processes.
        """
        self.logger.info("ğŸ›‘ Stopping all running tasks...")
        if self._process_executor:
            await self._process_executor.stop_all()
            self.logger.info("âœ… Stop signal sent to all tasks")

    async def wait_for_completion(self) -> List[WorkerResult]:
        """
        Wait for all tasks to complete and collect results.

        Should be called after stop_all_tasks().
        Returns results from all processes.
        """
        self.logger.info("â³ Waiting for all tasks to complete...")
        if not self._process_executor:
            return []

        # Get raw process results
        process_results = await self._process_executor.wait_for_completion()

        # Convert to WorkerResults
        worker_results = []
        for pr in process_results:
            wr = self._process_executor._convert_to_worker_result(pr)
            worker_results.append(wr)

        # Statistics
        total_messages_sent = sum(r.throughput.total_messages for r in worker_results if r.task_type == 'producer')
        total_messages_received = sum(r.throughput.total_messages for r in worker_results if r.task_type == 'consumer')

        self.logger.info(
            f"âœ… All tasks completed: "
            f"Sent {total_messages_sent}, Received {total_messages_received}"
        )

        return worker_results

    async def _execute_producer_task(self, task: ProducerTask) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ª producer ä»»åŠ¡ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰

        æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•ä¸åº”è¯¥è¢«ç›´æ¥è°ƒç”¨ï¼Œå› ä¸ºæˆ‘ä»¬è¦†ç›–äº† run_producer_tasksã€‚
        ä¿ç•™å®ƒæ˜¯ä¸ºäº†å…¼å®¹ BaseWorker æ¥å£ã€‚
        """
        raise NotImplementedError(
            "KafkaWorkerMultiProcess ä½¿ç”¨ run_producer_tasksï¼Œä¸åº”è°ƒç”¨æ­¤æ–¹æ³•"
        )

    async def _execute_consumer_task(self, task: ConsumerTask) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ª consumer ä»»åŠ¡ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰

        æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•ä¸åº”è¯¥è¢«ç›´æ¥è°ƒç”¨ï¼Œå› ä¸ºæˆ‘ä»¬è¦†ç›–äº† run_consumer_tasksã€‚
        ä¿ç•™å®ƒæ˜¯ä¸ºäº†å…¼å®¹ BaseWorker æ¥å£ã€‚
        """
        raise NotImplementedError(
            "KafkaWorkerMultiProcess ä½¿ç”¨ run_consumer_tasksï¼Œä¸åº”è°ƒç”¨æ­¤æ–¹æ³•"
        )

    def get_client_info(self) -> Dict[str, Any]:
        """è·å–å®¢æˆ·ç«¯ä¿¡æ¯"""
        info = {
            'worker_id': self.worker_id,
            'client_type': self.client_type,
            'driver_name': self.driver_config.name if self.driver_config else 'unknown',
            'execution_mode': 'multi-process',
            'description': 'Each producer/consumer runs in independent process'
        }

        if self._driver:
            info.update(self._driver.get_client_info())

        return info


# ============================================================================
# Worker å¯åŠ¨è„šæœ¬
# ============================================================================

if __name__ == "__main__":
    import argparse
    import sys
    from pathlib import Path

    # Add project root to path
    project_root = Path(__file__).parent.parent
    sys.path.insert(0, str(project_root))

    from benchmark.api.worker_api import run_worker_server
    from benchmark.core.config import ConfigLoader, DriverConfig

    parser = argparse.ArgumentParser(
        description='Kafka Worker (Multi-Process Mode)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:

# å¯åŠ¨ Worker (è‡ªåŠ¨ä½¿ç”¨å¤šè¿›ç¨‹æ¨¡å¼)
python workers/kafka_worker_multiprocess.py \\
    --worker-id worker-1 \\
    --port 8001 \\
    --driver-config configs/kafka-digital-twin.yaml

# æµ‹è¯• 10 ä¸ª producer (æ¯ä¸ªç‹¬ç«‹è¿›ç¨‹)
py-omb-coordinator \\
    --workload workloads/test-10-producers.yaml \\
    --driver configs/kafka-digital-twin.yaml \\
    --workers http://localhost:8001

ç‰¹ç‚¹:
- æ¯ä¸ª producer/consumer è¿è¡Œåœ¨ç‹¬ç«‹è¿›ç¨‹
- çœŸå®æ¨¡æ‹Ÿå¤š agent è´Ÿè½½åœºæ™¯
- å®Œå…¨ç»•è¿‡ GILï¼Œå……åˆ†åˆ©ç”¨å¤šæ ¸
- å¯¹åº” Java OMB çš„å¤šçº¿ç¨‹æ¨¡å‹
        """
    )

    parser.add_argument('--port', type=int, default=8001, help='æœåŠ¡ç«¯å£')
    parser.add_argument('--host', default='0.0.0.0', help='ç»‘å®šåœ°å€')
    parser.add_argument('--worker-id', default='multiprocess-worker-1', help='Worker ID')
    parser.add_argument('--driver-config', required=True, help='Driver é…ç½®æ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # åŠ è½½ driver é…ç½®
    driver_config = ConfigLoader.load_driver(args.driver_config)

    # åˆ›å»º worker å®ä¾‹
    worker = KafkaWorkerMultiProcess(
        worker_id=args.worker_id,
        driver_config=driver_config
    )

    print("=" * 80)
    print("ğŸš€ Kafka Worker (Multi-Process Mode)")
    print("=" * 80)
    print(f"   Worker ID: {args.worker_id}")
    print(f"   Client: Confluent Kafka")
    print(f"   Execution: Multi-Process (æ¯ä¸ªä»»åŠ¡ç‹¬ç«‹è¿›ç¨‹)")
    print(f"   Port: {args.port}")
    print(f"   Health URL: http://{args.host}:{args.port}/health")
    print("=" * 80)
    print()
    print("âœ¨ ç‰¹ç‚¹:")
    print("   - æ¯ä¸ª producer/consumer ç‹¬ç«‹è¿›ç¨‹")
    print("   - çœŸå®æ¨¡æ‹Ÿå¤š agent è´Ÿè½½")
    print("   - ç»•è¿‡ GILï¼Œå……åˆ†åˆ©ç”¨å¤šæ ¸")
    print("   - æµ‹è¯•ç»“æœå‡†ç¡®å¯é ")
    print("=" * 80)
    print()

    # å¯åŠ¨æœåŠ¡å™¨
    asyncio.run(run_worker_server(worker, host=args.host, port=args.port))
